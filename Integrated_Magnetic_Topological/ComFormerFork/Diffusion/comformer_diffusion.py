import torch
import torch_scatter
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
from Diffusion.guassian_diffusion import (
    GaussianDiffusion, ModelMeanType, ModelVarType, LossType
)

from models.TI_conformer import eComformerConfig, eComformer

betas = torch.linspace(0.0001, 0.02, steps=1000).numpy()
lattice_diff = GaussianDiffusion(
    betas=betas,
    model_mean_type=ModelMeanType.EPSILON,
    model_var_type=ModelVarType.FIXED_SMALL,
    loss_type=LossType.MSE,
)

betas = torch.linspace(0.0001, 0.02, steps=1000).numpy()
lattice_diff = GaussianDiffusion(
    betas=betas,
    model_mean_type=ModelMeanType.EPSILON,
    model_var_type=ModelVarType.FIXED_SMALL,
    loss_type=LossType.MSE,
)

def make_d3pm_transition_matrices(T, K, Œ≤_start=0.001, Œ≤_end=0.1):
    # Q_t = (1‚àíŒ≤_t)¬∑I + (Œ≤_t/K)¬∑1¬∑1^T
    betas = torch.linspace(Œ≤_start, Œ≤_end, T)
    I = torch.eye(K)
    ones = torch.ones(K, K)
    Q = [(1 - Œ≤)*I + (Œ≤/K)*ones for Œ≤ in betas]
    return torch.stack(Q)  # shape (T, K, K)

K = 5 # num atom types in dataset
T = 1000 # num diffusion steps
species_Q = make_d3pm_transition_matrices(T, K)

def make_wrapped_normal_sigmas(T, sigma_min=1e-4, sigma_max=2.0, schedule="geometric"):
    """
    Build a schedule of T noise‚Äêscales for wrapped‚Äênormal diffusion.
    sigma_min = œÉ‚ÇÅ, sigma_max = œÉ_T.
    """
    if schedule == "linear":
        sigmas = np.linspace(sigma_min, sigma_max, T)
    elif schedule == "geometric":
        # geometric progression from sigma_min to sigma_max
        sigmas = np.exp(
            np.linspace(np.log(sigma_min), np.log(sigma_max), T)
        )
    else:
        raise ValueError(f"Unknown schedule {schedule}")
    return torch.from_numpy(sigmas).float()  # shape (T,)

coord_sigmas = make_wrapped_normal_sigmas(
    T=T,
    sigma_min=1e-3,
    sigma_max=2.0,
    schedule="geometric",
)


class JointDiffusion:
    def __init__(self, lattice_diff, coord_sigmas, species_Q):
        self.lattice = lattice_diff
        self.coord_sigmas = coord_sigmas
        self.species_Q = species_Q

    def q_sample_all(self, L0, F0, A0, t):
        """
        Diffuse each modality at time-step t:
          L0: (B,3,3) lattice
          F0: (B,N,3) fractional coords
          A0: (B,N) integer species labels
          t:  (B,) time indices
        Returns noisy (Lt, Ft, At) plus the coord noise for loss.
        """
        # 1) lattice
        Lt = self.lattice.q_sample(L0, t.cpu().numpy())

        # 2) coords
        œÉt = self.coord_sigmas[t]                 # (B,)
        noiseF = torch.randn_like(F0)
        Ft = F0 + œÉt.view(-1,1,1) * noiseF         # broadcast to (B,N,3)

        # 3) species
        Qt = self.species_Q[t]                    # (B,K,K)
        one_hot_A0 = F.one_hot(A0, K).float()      # (B,N,K)
        probs = one_hot_A0 @ Qt                    # (B,N,K)
        At = torch.multinomial(probs.view(-1, K), 1).view_as(A0)

        return Lt, Ft, At, noiseF

    # def loss(self, model, L0, F0, A0, t):
    #     Lt, Ft, At, noiseF = self.q_sample_all(L0, F0, A0, t)
        
    #     epsL_hat, scoreF_hat, logitsA = model(Lt, Ft, At, t)

    #     # lattice Œµ‚Äêprediction target
    #     Œ±_bar = torch.from_numpy(self.lattice.alphas_cumprod).to(L0.device)
    #     œÉ_bar = torch.from_numpy(self.lattice.sqrt_one_minus_alphas_cumprod).to(L0.device)
    #     epsL_target = ((Lt - Œ±_bar[t].view(-1,1,1)*L0) /
    #                    œÉ_bar[t].view(-1,1,1))

    #     # coord score‚Äêmatching target: ‚àá_Ft log ùí©(Ft;F0,œÉ_t^2I) = ‚àínoiseF/œÉ_t
    #     œÉt = self.coord_sigmas[t].view(-1,1,1)
    #     scoreF_target = -noiseF / œÉt

    #     # species cross‚Äêentropy
    #     loss_L = F.mse_loss(epsL_hat, epsL_target)
    #     loss_F = F.mse_loss(scoreF_hat, scoreF_target)
    #     loss_A = F.cross_entropy(logitsA.view(-1, K), A0.view(-1))

    #     return loss_L + loss_F + loss_A

    # In JointDiffusion class:
# def loss(self, model, L0, F0, A0, t): # Original
# Needs to become something like:
    def loss(self, model, L0, F0, A0, edge_index_0, edge_attr_0, batch_idx_0, t):
        Lt_batch, Ft_batch, At_batch, noiseF_batch = self.q_sample_all(L0, F0, A0, t)
       
        epsL_hat, scoreF_hat, logitsA = model(Lt_batch, Ft_batch, At_batch,
                                            edge_index_0, edge_attr_0, batch_idx_0, t)

        # lattice Œµ‚Äêprediction target
        # Ensure L0 and Lt_batch are properly aligned for batch ops
        Œ±_bar = torch.from_numpy(self.lattice.alphas_cumprod).to(L0.device)[t] # (B,)
        œÉ_bar = torch.from_numpy(self.lattice.sqrt_one_minus_alphas_cumprod).to(L0.device)[t] # (B,)
        # Expand for (B,3,3) operations
        epsL_target = ((Lt_batch - Œ±_bar.view(-1,1,1)*L0) /
                    œÉ_bar.view(-1,1,1))

        # coord score‚Äêmatching target: ‚àá_Ft log ùí©(Ft;F0,œÉ_t^2I) = ‚àínoiseF/œÉ_t
        # œÉt comes from self.coord_sigmas[t] which should be (B,)
        # noiseF_batch is (total_nodes,3)
        # œÉt needs to be expanded for nodes
        
        œÉt_expanded = self.coord_sigmas.to(F0.device)[t][batch_idx_0].view(-1,1) # (total_nodes, 1)
        # if Ft is (B,N,3), then œÉt.view(-1,1,1) is correct. If Ft is (total_nodes,3), adapt œÉt indexing.
        # Original code for Ft used view(-1,1,1) which implies Ft was (B,N,3) in q_sample_all.
        # If Ft_batch is (total_nodes, 3), then œÉt needs to be indexed by t and then by batch_idx_0
        # to align with each node.
        # Assuming Ft_batch from q_sample_all is (B, N_max, 3) if padded, or you handle variable N carefully.
        # Let's assume Ft and noiseF are (B,N,3) as in the original snippet's `q_sample_all` for Ft.
        # Then œÉt.view(-1,1,1) is correct for element-wise ops if œÉt is (B,).

        # Corrected œÉt application for scoreF_target, assuming F0 and noiseF are (B,N,3)
        # and t is (B,)
        œÉt_per_sample = self.coord_sigmas.to(F0.device)[t] # Shape (B,)
        scoreF_target = -noiseF_batch / œÉt_per_sample.view(-1,1,1) # Broadcasts (B,) to (B,N,3)

        # species cross‚Äêentropy
        # logitsA: (total_nodes, K), A0_batch: (total_nodes,)
        loss_L = F.mse_loss(epsL_hat, epsL_target)
        loss_F = F.mse_loss(scoreF_hat, scoreF_target) # scoreF_hat should be (total_nodes, 3) or (B,N,3)
        loss_A = F.cross_entropy(logitsA.view(-1, K), A0.view(-1)) # A0 here should be the batched, flattened A0 corresponding to logitsA

        return loss_L + loss_F + loss_A

#joint = JointDiffusion(lattice_diff, coord_sigmas, species_Q)

class JointDiffusionTransformer(torch.nn.Module):
    def __init__(self, num_species: int, 
                 conv_config: eComformerConfig = eComformerConfig(name = "eComformer"),
    hidden_dim: int = 256):
        super().__init__()

        self.comformer = eComformer(conv_config)
        self.epsL_head = nn.Linear(conv_config.node_features, 9)
        self.scoreF_head = nn.Linear(conv_config.node_features, 3)
        self.species_head = nn.Linear(conv_config.node_features, num_species)

        self.time_embed = nn.Embedding(1000, conv_config.node_features)


    def forward(self, Lt, Ft, At, edge_index, edge_attr, batch, t):
        B = Lt.size(0)
        
        atom_embed = F.one_hot(At, num_classes=self.species_head.out_features).float()

        coord_embed = nn.Linear(3, atom_embed.size(1)).to(Ft.device)(Ft)

        # 3) time embedding (expand per node)
        time_vec = self.time_embed(t)                # (B, F)
        time_vec = time_vec[batch]                   # (B_total_nodes, F)

        # combine
        x = atom_embed + coord_embed + time_vec      # (B_total_nodes, F)

        # if you want, you can also inject a graph‚Äêlevel "lattice embedding" into each node:
        L_flat = Lt.view(B, 9)
        L_embed = nn.Linear(9, x.size(1)).to(Lt.device)(L_flat)   # (B,F)
        x = x + L_embed[batch]

        # --- B) run ComformerConv layers ---
        # comformer expects a PyG‚Äêstyle tuple (data, ldata, lattice)
        # Here `data` is (x, edge_index, edge_attr) and ignore lattice‚Äêbased equivariant update:
        node_feats = self.comformer((x, edge_index, edge_attr))

        # --- C) project into each head ---
        # 1) lattice Œµ (pool per‚Äêgraph then predict 3√ó3 noise)
        #    note: flatten back to (B,3,3)
        pooled = torch_scatter.scatter_mean(node_feats, batch, dim=0)  # (B, F)
        epsL_hat = self.epsL_head(pooled).view(B, 3, 3)

        # 2) coord score: (B_total_nodes,3)
        scoreF_hat = self.scoreF_head(node_feats)

        # 3) species logits: (B_total_nodes, K)
        logitsA = self.species_head(node_feats)

        return epsL_hat, scoreF_hat, logitsA