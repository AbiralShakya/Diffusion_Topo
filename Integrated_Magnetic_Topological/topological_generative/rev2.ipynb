{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import logging\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CDVAE_TI_Generator:\n",
    "    \"\"\"\n",
    "    Crystal Diffusion Variational Autoencoder (CDVAE) with Reinforcement Learning\n",
    "    for targeted generation of Topological Insulator materials.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize CDVAE model components\n",
    "        self.initialize_models()\n",
    "        \n",
    "        # Set up optimizers\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Initialize results tracking\n",
    "        self.results = {\n",
    "            'rewards': [],\n",
    "            'z_gap': [],\n",
    "            'topological_indices': [],\n",
    "            'formation_energies': [],\n",
    "            'best_structures': [],\n",
    "            'best_rewards': [],\n",
    "        }\n",
    "        \n",
    "        # Initialize replay buffer for experience replay\n",
    "        self.replay_buffer = ReplayBuffer(config['buffer_size'])\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize CDVAE encoder, decoder and policy networks.\"\"\"\n",
    "        # Import specific model classes\n",
    "        try:\n",
    "            from cdvae.pl_modules.decoder import GemNetTDecoder\n",
    "            from cdvae.common.data_utils import ATOM_TYPES\n",
    "        except ImportError:\n",
    "            logger.error(\"Failed to import CDVAE modules. Please ensure CDVAE is installed correctly.\")\n",
    "            raise\n",
    "            \n",
    "        # Get dimensions and parameters from config\n",
    "        self.latent_dim = self.config['latent_dim']\n",
    "        self.n_elements = len(self.config['elements']) if 'elements' in self.config else len(ATOM_TYPES)\n",
    "        \n",
    "        #TODO: possibly write an encoder file addition to cdvae\n",
    "        # Initialize encoder (if using pre-trained weights)\n",
    "        # if self.config.get('use_encoder', False):\n",
    "        #     self.encoder = GraphEncoder(\n",
    "        #         hidden_dim=self.config['hidden_dim'],\n",
    "        #         latent_dim=self.latent_dim,\n",
    "        #         use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        #     ).to(self.device)\n",
    "            \n",
    "        #     if self.config.get('encoder_checkpoint'):\n",
    "        #         self._load_model(self.encoder, self.config['encoder_checkpoint'])\n",
    "        # else:\n",
    "        #     self.encoder = None\n",
    "\n",
    "        self.encoder = None\n",
    "            \n",
    "        # Initialize decoder\n",
    "        self.decoder = GemNetTDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.config['hidden_dim'],\n",
    "            n_elements=self.n_elements,\n",
    "            cutoff=self.config.get('cutoff', 6.0),\n",
    "            max_neighbors=self.config.get('max_neighbors', 20),\n",
    "            use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('decoder_checkpoint'):\n",
    "            self._load_model(self.decoder, self.config['decoder_checkpoint'])\n",
    "            \n",
    "        # Initialize policy network for RL\n",
    "        self.policy_net = PolicyNetwork(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('policy_hidden_dims', [256, 256]),\n",
    "            activation=self.config.get('policy_activation', 'relu')\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize critic network for actor-critic methods\n",
    "        if self.config.get('use_critic', True):\n",
    "            self.critic = CriticNetwork(\n",
    "                latent_dim=self.latent_dim,\n",
    "                hidden_dims=self.config.get('critic_hidden_dims', [256, 128]),\n",
    "                activation=self.config.get('critic_activation', 'relu')\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.critic = None\n",
    "            \n",
    "        # DFT surrogate models - predict quantum properties directly from latent space\n",
    "        self.energy_predictor = EnergyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('energy_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.topological_predictor = TopologicalPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('topo_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('surrogate_checkpoint'):\n",
    "            self._load_surrogate_models(self.config['surrogate_checkpoint'])\n",
    "        \n",
    "    def setup_optimizers(self):\n",
    "        \"\"\"Set up optimizers for different components.\"\"\"\n",
    "        # Policy optimizer\n",
    "        self.policy_optimizer = torch.optim.Adam(\n",
    "            self.policy_net.parameters(),\n",
    "            lr=self.config.get('policy_lr', 1e-4),\n",
    "            weight_decay=self.config.get('policy_weight_decay', 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Critic optimizer (if using actor-critic)\n",
    "        if self.critic is not None:\n",
    "            self.critic_optimizer = torch.optim.Adam(\n",
    "                self.critic.parameters(),\n",
    "                lr=self.config.get('critic_lr', 3e-4),\n",
    "                weight_decay=self.config.get('critic_weight_decay', 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Surrogate model optimizers for fine-tuning\n",
    "        if self.config.get('train_surrogates', False):\n",
    "            self.energy_optimizer = torch.optim.Adam(\n",
    "                self.energy_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "            self.topo_optimizer = torch.optim.Adam(\n",
    "                self.topological_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "    def _load_model(self, model, checkpoint_path):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'state_dict' in checkpoint:\n",
    "                # Handle pytorch-lightning checkpoints\n",
    "                state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items() \n",
    "                              if k.startswith('model.')}\n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "            else:\n",
    "                # Handle regular torch checkpoints\n",
    "                model.load_state_dict(checkpoint, strict=False)\n",
    "            logger.info(f\"Loaded weights from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load weights: {e}\")\n",
    "            \n",
    "    def _load_surrogate_models(self, checkpoint_path):\n",
    "        \"\"\"Load surrogate model weights.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.energy_predictor.load_state_dict(checkpoint['energy_predictor'])\n",
    "            self.topological_predictor.load_state_dict(checkpoint['topo_predictor'])\n",
    "            logger.info(f\"Loaded surrogate models from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load surrogate models: {e}\")\n",
    "            \n",
    "    def generate_structures(self, batch_size=None):\n",
    "        \"\"\"Generate crystal structures using the policy network and decoder.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.get('batch_size', 32)\n",
    "            \n",
    "        # Sample latent vectors from the policy network\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\n",
    "        \n",
    "        # Generate structures using the decoder\n",
    "        with torch.no_grad():\n",
    "            # Assuming decoder outputs a dictionary with:\n",
    "            # - frac_coords: fractional coordinates of atoms\n",
    "            # - atom_types: types of atoms (one-hot or indices)\n",
    "            # - lattice: lattice parameters for unit cells\n",
    "            generated_structures = self.decoder(z_sampled)\n",
    "            \n",
    "        return generated_structures, z_sampled, log_probs\n",
    "    \n",
    "    def evaluate_structures(self, structures, z_vectors):\n",
    "        \"\"\"Evaluate generated structures using surrogate models.\"\"\"\n",
    "        # Predict formation energies\n",
    "        with torch.no_grad():\n",
    "            energies = self.energy_predictor(z_vectors)\n",
    "            \n",
    "            # Predict topological indices (Z2 invariants, Chern numbers, etc.)\n",
    "            topo_indices = self.topological_predictor(z_vectors)\n",
    "            \n",
    "            # Calculate band gaps (can be part of the topological predictor or separate)\n",
    "            band_gaps = self.estimate_band_gap(structures, z_vectors)\n",
    "            \n",
    "        # Combine predictions into a comprehensive evaluation\n",
    "        evaluations = {\n",
    "            'formation_energies': energies.cpu().numpy(),\n",
    "            'topological_indices': topo_indices.cpu().numpy(),\n",
    "            'band_gaps': band_gaps.cpu().numpy() if isinstance(band_gaps, torch.Tensor) else band_gaps\n",
    "        }\n",
    "        \n",
    "        return evaluations\n",
    "    \n",
    "    def calculate_rewards(self, evaluations):\n",
    "        \"\"\"Calculate rewards based on desired material properties.\"\"\"\n",
    "        # Extract evaluations\n",
    "        energies = evaluations['formation_energies']\n",
    "        topo_indices = evaluations['topological_indices']\n",
    "        band_gaps = evaluations['band_gaps']\n",
    "        \n",
    "        # Convert to numpy for easier manipulation\n",
    "        if isinstance(energies, torch.Tensor):\n",
    "            energies = energies.cpu().numpy()\n",
    "        if isinstance(topo_indices, torch.Tensor):\n",
    "            topo_indices = topo_indices.cpu().numpy()\n",
    "        if isinstance(band_gaps, torch.Tensor):\n",
    "            band_gaps = band_gaps.cpu().numpy()\n",
    "            \n",
    "        # Calculate stability reward component\n",
    "        # Lower formation energy is better, but must be below threshold to be stable\n",
    "        stability_threshold = self.config.get('stability_threshold', 0.1)\n",
    "        stability_rewards = -energies * (energies < stability_threshold)\n",
    "        \n",
    "        # Calculate topological reward component\n",
    "        # For Z2 invariants, we typically want (1;000) for 3D TIs\n",
    "        # This is a simplified example - actual implementation depends on how topo_indices are represented\n",
    "        topo_rewards = np.sum(topo_indices * self.config.get('topo_weights', [2.0, 1.0, 1.0, 1.0]), axis=1)\n",
    "        \n",
    "        # Calculate band gap reward component\n",
    "        # Usually want a moderate band gap (not too small, not too large)\n",
    "        target_gap = self.config.get('target_band_gap', 0.3)  # in eV\n",
    "        gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\n",
    "        gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target_gap) / gap_tolerance, 1.0)\n",
    "        \n",
    "        # Combine reward components with configurable weights\n",
    "        w_stability = self.config.get('w_stability', 1.0)\n",
    "        w_topological = self.config.get('w_topological', 2.0)\n",
    "        w_gap = self.config.get('w_gap', 1.5)\n",
    "        \n",
    "        combined_rewards = (w_stability * stability_rewards + \n",
    "                           w_topological * topo_rewards +\n",
    "                           w_gap * gap_rewards)\n",
    "        \n",
    "        # Create rewards dictionary\n",
    "        rewards_dict = {\n",
    "            'total': combined_rewards,\n",
    "            'stability': stability_rewards,\n",
    "            'topological': topo_rewards,\n",
    "            'band_gap': gap_rewards\n",
    "        }\n",
    "        \n",
    "        return rewards_dict\n",
    "    \n",
    "    def estimate_band_gap(self, structures, z_vectors):\n",
    "        \"\"\"Estimate band gaps of structures using a surrogate model.\"\"\"\n",
    "        # This would typically be a separate model or part of topological_predictor\n",
    "        # For simplicity, we'll use a mock implementation\n",
    "        batch_size = z_vectors.shape[0]\n",
    "        \n",
    "        # Mock band gap estimation (replace with actual model)\n",
    "        # In practice, this would use a trained neural network or other predictor\n",
    "        gaps = 0.2 + 0.3 * torch.sigmoid(z_vectors[:, 0]) + 0.1 * torch.randn(batch_size).to(self.device)\n",
    "        \n",
    "        return gaps\n",
    "        \n",
    "    def reinforce_update(self, rewards, log_probs):\n",
    "        \"\"\"Update policy network using REINFORCE algorithm.\"\"\"\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device)\n",
    "        \n",
    "        # Normalize rewards\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "        \n",
    "        # Calculate policy loss\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\n",
    "        \n",
    "        # Update policy\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        # Optional gradient clipping\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            \n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item()\n",
    "        \n",
    "    def actor_critic_update(self, z_vectors, rewards, log_probs):\n",
    "        \"\"\"Update policy and critic networks using Actor-Critic algorithm.\"\"\"\n",
    "        if self.critic is None:\n",
    "            return self.reinforce_update(rewards, log_probs)\n",
    "            \n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device)\n",
    "        \n",
    "        # Get critic's value predictions\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\n",
    "        \n",
    "        # Calculate advantages\n",
    "        advantages = rewards_tensor - value_predictions.detach()\n",
    "        \n",
    "        # Calculate policy (actor) loss\n",
    "        policy_loss = -(log_probs * advantages).mean()\n",
    "        \n",
    "        # Calculate value (critic) loss\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\n",
    "        \n",
    "        # Update policy network\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        # Update critic network\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.critic.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform a single training step.\"\"\"\n",
    "        # Generate structures\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\n",
    "        \n",
    "        # Evaluate structures\n",
    "        evaluations = self.evaluate_structures(structures, z_vectors)\n",
    "        \n",
    "        # Calculate rewards\n",
    "        rewards_dict = self.calculate_rewards(evaluations)\n",
    "        total_rewards = rewards_dict['total']\n",
    "        \n",
    "        # Store experience in replay buffer\n",
    "        for i in range(len(total_rewards)):\n",
    "            self.replay_buffer.add(\n",
    "                z_vectors[i].detach().cpu().numpy(),\n",
    "                total_rewards[i],\n",
    "                log_probs[i].detach().cpu().numpy()\n",
    "            )\n",
    "        \n",
    "        # Update policy using actor-critic or REINFORCE\n",
    "        if self.critic is not None:\n",
    "            loss_info = self.actor_critic_update(z_vectors, total_rewards, log_probs)\n",
    "            policy_loss = loss_info[0]\n",
    "        else:\n",
    "            policy_loss = self.reinforce_update(total_rewards, log_probs)\n",
    "            \n",
    "        # Track best structures\n",
    "        best_idx = np.argmax(total_rewards)\n",
    "        best_reward = total_rewards[best_idx]\n",
    "        \n",
    "        # Update current best if this is better\n",
    "        if not self.results['best_rewards'] or best_reward > max(self.results['best_rewards']):\n",
    "            self.results['best_structures'].append(structures[best_idx])\n",
    "            \n",
    "        # Store results\n",
    "        self.results['rewards'].append(np.mean(total_rewards))\n",
    "        self.results['formation_energies'].append(np.mean(evaluations['formation_energies']))\n",
    "        self.results['topological_indices'].append(np.mean(evaluations['topological_indices']))\n",
    "        self.results['best_rewards'].append(best_reward)\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(total_rewards),\n",
    "            'max_reward': np.max(total_rewards),\n",
    "            'mean_energy': np.mean(evaluations['formation_energies']),\n",
    "            'policy_loss': policy_loss\n",
    "        }\n",
    "    \n",
    "    def train(self, num_iterations=None):\n",
    "        \"\"\"Train the model for the specified number of iterations.\"\"\"\n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.config.get('num_iterations', 500)\n",
    "            \n",
    "        logger.info(f\"Starting training for {num_iterations} iterations\")\n",
    "        \n",
    "        for iteration in tqdm(range(num_iterations)):\n",
    "            # Perform a training step\n",
    "            step_results = self.train_step()\n",
    "            \n",
    "            # Log progress periodically\n",
    "            if iteration % self.config.get('log_frequency', 10) == 0:\n",
    "                logger.info(\n",
    "                    f\"Iteration {iteration} | \"\n",
    "                    f\"Mean Reward: {step_results['mean_reward']:.4f} | \"\n",
    "                    f\"Max Reward: {step_results['max_reward']:.4f} | \"\n",
    "                    f\"Mean Energy: {step_results['mean_energy']:.4f} | \"\n",
    "                    f\"Policy Loss: {step_results['policy_loss']:.4f}\"\n",
    "                )\n",
    "                \n",
    "            # Save checkpoints periodically\n",
    "            if iteration % self.config.get('save_frequency', 100) == 0 and iteration > 0:\n",
    "                self.save_checkpoint(f\"checkpoint_iter_{iteration}.pt\")\n",
    "                \n",
    "        logger.info(\"Training completed\")\n",
    "        self.save_checkpoint(\"final_checkpoint.pt\")\n",
    "        self.save_results(\"training_results.pkl\")\n",
    "        \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint_dir = self.config.get('checkpoint_dir', './checkpoints')\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'policy_state_dict': self.policy_net.state_dict(),\n",
    "            'policy_optimizer': self.policy_optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'iteration': len(self.results['rewards'])\n",
    "        }\n",
    "        \n",
    "        if self.critic is not None:\n",
    "            checkpoint['critic_state_dict'] = self.critic.state_dict()\n",
    "            checkpoint['critic_optimizer'] = self.critic_optimizer.state_dict()\n",
    "            \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        \n",
    "    def save_results(self, filename):\n",
    "        \"\"\"Save training results.\"\"\"\n",
    "        results_dir = self.config.get('results_dir', './results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        results_path = os.path.join(results_dir, filename)\n",
    "        \n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(self.results, f)\n",
    "            \n",
    "        logger.info(f\"Saved results to {results_path}\")\n",
    "        \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])\n",
    "        self.policy_optimizer.load_state_dict(checkpoint['policy_optimizer'])\n",
    "        \n",
    "        if self.critic is not None and 'critic_state_dict' in checkpoint:\n",
    "            self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "            self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "            \n",
    "        logger.info(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "        return checkpoint.get('iteration', 0)\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for RL-based latent space exploration.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 256], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer for mean\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "        # Learnable log std for exploration\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z_noise):\n",
    "        \"\"\"\n",
    "        Forward pass through the policy network.\n",
    "        \n",
    "        Args:\n",
    "            z_noise: Random noise tensor of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            z_sampled: Sampled latent vectors\n",
    "            log_probs: Log probabilities of the sampled vectors\n",
    "        \"\"\"\n",
    "        x = self.fc_layers(z_noise)\n",
    "        mu = self.fc_mu(x)\n",
    "        \n",
    "        # Get standard deviation from learnable parameter\n",
    "        std = torch.exp(self.log_std.clamp(-20, 2))  # Clamp for stability\n",
    "        \n",
    "        # Create normal distribution\n",
    "        dist = Normal(mu, std)\n",
    "        \n",
    "        # Sample using reparameterization trick\n",
    "        z_sampled = dist.rsample()\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        log_probs = dist.log_prob(z_sampled).sum(dim=-1)\n",
    "        \n",
    "        return z_sampled, log_probs\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"Critic network for actor-critic method.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 128], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value output\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the critic network.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent vector of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            value: Predicted value of the state\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class EnergyPredictor(nn.Module):\n",
    "    \"\"\"Surrogate model to predict formation energy from latent space.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value for formation energy\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict formation energy from latent vector.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class TopologicalPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Surrogate model to predict topological invariants (Z2, Chern number) \n",
    "    from latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64], num_invariants=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - multiple values for topological invariants\n",
    "        # For 3D topological insulators, typically 4 Z2 invariants (ν₀;ν₁ν₂ν₃)\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.invariant_head = nn.Linear(input_dim, num_invariants)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict topological invariants from latent vector.\"\"\"\n",
    "        features = self.feature_extractor(z)\n",
    "        # Apply sigmoid to constrain outputs between 0 and 1\n",
    "        # In practice, these would be discretized to 0 or 1 when interpreting\n",
    "        invariants = torch.sigmoid(self.invariant_head(features))\n",
    "        return invariants\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer for more stable training.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size=10000):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def add(self, z, reward, log_prob):\n",
    "        \"\"\"Add experience to buffer.\"\"\"\n",
    "        if len(self.buffer) < self.max_size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (z, reward, log_prob)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        z, rewards, log_probs = map(np.array, zip(*batch))\n",
    "        return z, rewards, log_probs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size.\"\"\"\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example configuration\n",
    "def get_default_config():\n",
    "    \"\"\"Get default configuration for CDVAE + RL training.\"\"\"\n",
    "    return {\n",
    "        # Model dimensions\n",
    "        \"latent_dim\": 64,\n",
    "        \"hidden_dim\": 128,\n",
    "        \n",
    "        # Elements to consider\n",
    "        \"elements\": [\"Si\", \"Ge\", \"Sn\", \"Pb\", \"Bi\", \"Sb\", \"Te\", \"Se\", \"O\"],\n",
    "        \n",
    "        # Training parameters\n",
    "        \"batch_size\": 32,\n",
    "        \"num_iterations\": 1000,\n",
    "        \"policy_lr\": 1e-4,\n",
    "        \"critic_lr\": 3e-4,\n",
    "        \"surrogate_lr\": 1e-4,\n",
    "        \n",
    "        # RL parameters\n",
    "        \"use_critic\": True,  # Use actor-critic instead of REINFORCE\n",
    "        \"clip_grad\": True,\n",
    "        \"max_grad_norm\": 1.0,\n",
    "        \"buffer_size\": 5000,  # Replay buffer size\n",
    "        \n",
    "        # Reward components\n",
    "        \"stability_threshold\": 0.1,\n",
    "        \"target_band_gap\": 0.3,  # Target band gap in eV\n",
    "        \"gap_tolerance\": 0.2,    # Acceptable deviation from target\n",
    "        \"topo_weights\": [2.0, 1.0, 1.0, 1.0],  # Weights for Z2 invariants\n",
    "        \n",
    "        # Reward weights\n",
    "        \"w_stability\": 1.0,\n",
    "        \"w_topological\": 2.0,\n",
    "        \"w_gap\": 1.5,\n",
    "        \n",
    "        # Logging and checkpoints\n",
    "        \"log_frequency\": 10,\n",
    "        \"save_frequency\": 100,\n",
    "        \"checkpoint_dir\": \"./checkpoints\",\n",
    "        \"results_dir\": \"./results\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 12:01:09,502 - INFO - Using device: cpu\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "dlopen(/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_scatter/_scatter_cpu.so, 0x0006): Symbol not found: __ZN2at4_ops16div__Tensor_mode4callERNS_6TensorERKS2_NSt3__18optionalIN3c1017basic_string_viewIcEEEE\n  Referenced from: <4A3195B8-9E71-3AE7-AE80-DBA66ADAC535> /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_scatter/_scatter_cpu.so\n  Expected in:     <DA215AD3-6EAE-3755-B6A5-A8EB4EF952B0> /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/lib/libtorch_cpu.dylib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m config \u001b[38;5;241m=\u001b[39m get_default_config()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create training framework\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m ti_generator \u001b[38;5;241m=\u001b[39m \u001b[43mCDVAE_TI_Generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     19\u001b[0m ti_generator\u001b[38;5;241m.\u001b[39mtrain(num_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m, in \u001b[0;36mCDVAE_TI_Generator.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     25\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Initialize CDVAE model components\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Set up optimizers\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_optimizers()\n",
      "Cell \u001b[0;32mIn[1], line 50\u001b[0m, in \u001b[0;36mCDVAE_TI_Generator.initialize_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Import specific model classes\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcdvae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpl_modules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GemNetTDecoder\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcdvae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ATOM_TYPES\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cdvae/pl_modules/decoder.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcdvae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpl_modules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MAX_ATOMIC_NUM\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcdvae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpl_modules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GemNetT\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_mlp\u001b[39m(in_dim, hidden_dim, fc_num_layers, out_dim):\n\u001b[1;32m     10\u001b[0m     mods \u001b[38;5;241m=\u001b[39m [nn\u001b[38;5;241m.\u001b[39mLinear(in_dim, hidden_dim), nn\u001b[38;5;241m.\u001b[39mReLU()]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cdvae/pl_modules/gemnet/gemnet.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_scatter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scatter\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_sparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseTensor\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcdvae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     get_pbc_distances, radius_graph_pbc, frac_to_cart_coords)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_scatter/__init__.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m spec \u001b[38;5;241m=\u001b[39m cuda_spec \u001b[38;5;129;01mor\u001b[39;00m cpu_spec\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBUILD_DOCS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibrary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mosp\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_ops.py:1357\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1352\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m-> 1357\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ctypes/__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_scatter/_scatter_cpu.so, 0x0006): Symbol not found: __ZN2at4_ops16div__Tensor_mode4callERNS_6TensorERKS2_NSt3__18optionalIN3c1017basic_string_viewIcEEEE\n  Referenced from: <4A3195B8-9E71-3AE7-AE80-DBA66ADAC535> /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_scatter/_scatter_cpu.so\n  Expected in:     <DA215AD3-6EAE-3755-B6A5-A8EB4EF952B0> /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/lib/libtorch_cpu.dylib"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import random\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Get default configuration\n",
    "    config = get_default_config()\n",
    "    \n",
    "    # Create training framework\n",
    "    ti_generator = CDVAE_TI_Generator(config)\n",
    "    \n",
    "    # Train the model\n",
    "    ti_generator.train(num_iterations=500)\n",
    "    \n",
    "    # Plot training results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot rewards\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(ti_generator.results['rewards'])\n",
    "    plt.title('Average Reward')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Reward')\n",
    "    \n",
    "    # Plot formation energies\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(ti_generator.results['formation_energies'])\n",
    "    plt.title('Average Formation Energy')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Energy (eV)')\n",
    "    \n",
    "    # Plot topological indices\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(ti_generator.results['topological_indices'])\n",
    "    plt.title('Average Topological Index')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Index Value')\n",
    "    \n",
    "    # Plot best rewards\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(ti_generator.results['best_rewards'])\n",
    "    plt.title('Best Reward')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Reward')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_results.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate some final structures\n",
    "    structures, _, _ = ti_generator.generate_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/abiralshakya/Library/Python/3.12/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/sb/srkfc7tj3319314qk68v5cch0000gn/T/ipykernel_4835/2440548420.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/__init__.py\", line 1471, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 17:19:32,548 - INFO - Using device: cpu\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._C._dynamo.guards'; 'torch._C._dynamo' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 687\u001b[0m\n\u001b[1;32m    684\u001b[0m config \u001b[38;5;241m=\u001b[39m get_default_config()\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# Create generator\u001b[39;00m\n\u001b[0;32m--> 687\u001b[0m ti_generator \u001b[38;5;241m=\u001b[39m \u001b[43mTopologicalInsulatorGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m    690\u001b[0m results \u001b[38;5;241m=\u001b[39m ti_generator\u001b[38;5;241m.\u001b[39mtrain(num_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 117\u001b[0m, in \u001b[0;36mTopologicalInsulatorGenerator.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_models()\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Setup optimizers\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Results tracking\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 178\u001b[0m, in \u001b[0;36mTopologicalInsulatorGenerator.setup_optimizers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Setup optimizers for all trainable components.\"\"\"\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Policy optimizer\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpolicy_lr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Optional critic optimizer\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/optimizer.py:278\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_compile.py:22\u001b[0m, in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_dynamo/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mguards\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalStateGuard\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._C._dynamo.guards'; 'torch._C._dynamo' is not a package"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.distributions import Normal\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SimplifiedDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified decoder that generates crystal structures directly from latent vectors.\n",
    "    Instead of relying on complex GemNetT architecture, we use a simpler MLP-based model.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim, hidden_dim=128, max_atoms=32, n_elements=10):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_atoms = max_atoms\n",
    "        self.n_elements = n_elements\n",
    "        \n",
    "        # MLP for decoding\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Output heads\n",
    "        # - Fractional coordinates: 3 values per atom (x,y,z)\n",
    "        # - Atom types: one-hot encoding for each atom\n",
    "        # - Existence flags: binary value indicating if atom exists\n",
    "        # - Lattice parameters: 6 values (a, b, c, alpha, beta, gamma)\n",
    "        self.coords_head = nn.Linear(hidden_dim * 2, max_atoms * 3)\n",
    "        self.atom_types_head = nn.Linear(hidden_dim * 2, max_atoms * n_elements)\n",
    "        self.exists_head = nn.Linear(hidden_dim * 2, max_atoms)\n",
    "        self.lattice_head = nn.Linear(hidden_dim * 2, 6)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Decode latent vectors into crystal structures.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent vectors [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing crystal structure components:\n",
    "            - frac_coords: fractional coordinates [batch_size, max_atoms, 3]\n",
    "            - atom_types: one-hot encoded atom types [batch_size, max_atoms, n_elements]\n",
    "            - atom_mask: existence mask [batch_size, max_atoms]\n",
    "            - lattice: lattice parameters [batch_size, 6]\n",
    "        \"\"\"\n",
    "        batch_size = z.shape[0]\n",
    "        \n",
    "        # Pass through MLP\n",
    "        h = self.mlp(z)\n",
    "        \n",
    "        # Decode coordinates\n",
    "        coords_flat = self.coords_head(h)\n",
    "        frac_coords = coords_flat.view(batch_size, self.max_atoms, 3)\n",
    "        # Constrain to unit cell (0,1)\n",
    "        frac_coords = torch.sigmoid(frac_coords)\n",
    "        \n",
    "        # Decode atom types\n",
    "        atom_types_logits = self.atom_types_head(h)\n",
    "        atom_types = atom_types_logits.view(batch_size, self.max_atoms, self.n_elements)\n",
    "        atom_types = F.softmax(atom_types, dim=-1)\n",
    "        \n",
    "        # Decode existence flags\n",
    "        exists_logits = self.exists_head(h)\n",
    "        atom_mask = torch.sigmoid(exists_logits)\n",
    "        \n",
    "        # Decode lattice parameters\n",
    "        # a, b, c: positive values in Angstrom\n",
    "        # alpha, beta, gamma: angles in degrees, constrained to reasonable ranges\n",
    "        lattice_params = self.lattice_head(h)\n",
    "        \n",
    "        # Split into cell lengths and angles\n",
    "        cell_lengths = torch.abs(lattice_params[:, :3]) + 3.0  # Min 3 Angstrom\n",
    "        cell_angles = 60 + 60 * torch.sigmoid(lattice_params[:, 3:])  # Range: 60-120 degrees\n",
    "        \n",
    "        # Combine into final lattice parameters\n",
    "        lattice = torch.cat([cell_lengths, cell_angles], dim=-1)\n",
    "        \n",
    "        return {\n",
    "            'frac_coords': frac_coords,\n",
    "            'atom_types': atom_types,\n",
    "            'atom_mask': atom_mask,\n",
    "            'lattice': lattice\n",
    "        }\n",
    "\n",
    "\n",
    "class TopologicalInsulatorGenerator:\n",
    "    \"\"\"\n",
    "    Simplified framework for generating topological insulator materials\n",
    "    using a VAE with reinforcement learning for optimization.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize models\n",
    "        self.initialize_models()\n",
    "        \n",
    "        # Setup optimizers\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Results tracking\n",
    "        self.results = defaultdict(list)\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize all model components.\"\"\"\n",
    "        # Get dimensions\n",
    "        self.latent_dim = self.config['latent_dim']\n",
    "        self.hidden_dim = self.config['hidden_dim']\n",
    "        self.n_elements = len(self.config['elements'])\n",
    "        self.max_atoms = self.config['max_atoms']\n",
    "        \n",
    "        # Initialize decoder\n",
    "        self.decoder = SimplifiedDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            max_atoms=self.max_atoms,\n",
    "            n_elements=self.n_elements\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize policy network\n",
    "        self.policy_net = PolicyNetwork(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config['policy_hidden_dims']\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize surrogate property predictors\n",
    "        self.formation_energy_net = PropertyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config['property_hidden_dims'],\n",
    "            output_dim=1,\n",
    "            name=\"Formation Energy\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.band_structure_net = PropertyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config['property_hidden_dims'],\n",
    "            output_dim=self.config['band_structure_dim'],\n",
    "            name=\"Band Structure\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.topological_net = PropertyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config['property_hidden_dims'],\n",
    "            output_dim=self.config['topo_invariant_dim'],\n",
    "            name=\"Topological Invariants\"\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Optional: initialize critic for actor-critic method\n",
    "        if self.config.get('use_critic', True):\n",
    "            self.critic = CriticNetwork(\n",
    "                latent_dim=self.latent_dim,\n",
    "                hidden_dims=self.config['critic_hidden_dims']\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.critic = None\n",
    "    \n",
    "    def setup_optimizers(self):\n",
    "        \"\"\"Setup optimizers for all trainable components.\"\"\"\n",
    "        # Policy optimizer\n",
    "        self.policy_optimizer = torch.optim.Adam(\n",
    "            self.policy_net.parameters(),\n",
    "            lr=self.config['policy_lr'],\n",
    "            weight_decay=self.config.get('weight_decay', 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Optional critic optimizer\n",
    "        if self.critic is not None:\n",
    "            self.critic_optimizer = torch.optim.Adam(\n",
    "                self.critic.parameters(),\n",
    "                lr=self.config['critic_lr'],\n",
    "                weight_decay=self.config.get('weight_decay', 1e-6)\n",
    "            )\n",
    "    \n",
    "    def generate_structures(self, batch_size=None):\n",
    "        \"\"\"Generate crystal structures from latent space samples.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config['batch_size']\n",
    "        \n",
    "        # Sample from policy network\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim).to(self.device)\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\n",
    "        \n",
    "        # Generate structures using the decoder\n",
    "        with torch.no_grad():\n",
    "            structures = self.decoder(z_sampled)\n",
    "        \n",
    "        return structures, z_sampled, log_probs\n",
    "    \n",
    "    def predict_properties(self, z_vectors):\n",
    "        \"\"\"Predict material properties from latent vectors.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Predict formation energy (lower is better for stability)\n",
    "            energy = self.formation_energy_net(z_vectors)\n",
    "            \n",
    "            # Predict band structure features\n",
    "            band_features = self.band_structure_net(z_vectors)\n",
    "            \n",
    "            # Extract band gap from band features\n",
    "            # Assuming the first element is the band gap\n",
    "            band_gap = band_features[:, 0:1]\n",
    "            \n",
    "            # Predict topological invariants (Z2, Chern numbers)\n",
    "            topo_invariants = self.topological_net(z_vectors)\n",
    "            # Apply sigmoid to constrain between 0 and 1\n",
    "            topo_invariants = torch.sigmoid(topo_invariants)\n",
    "        \n",
    "        return {\n",
    "            'formation_energy': energy.squeeze(),\n",
    "            'band_gap': band_gap.squeeze(),\n",
    "            'topo_invariants': topo_invariants\n",
    "        }\n",
    "    \n",
    "    def calculate_rewards(self, properties):\n",
    "        \"\"\"Calculate rewards based on material properties.\"\"\"\n",
    "        # Extract properties\n",
    "        energy = properties['formation_energy']\n",
    "        band_gap = properties['band_gap']\n",
    "        topo_invariants = properties['topo_invariants']\n",
    "        \n",
    "        # Convert to numpy for easier manipulation\n",
    "        if isinstance(energy, torch.Tensor):\n",
    "            energy = energy.cpu().numpy()\n",
    "        if isinstance(band_gap, torch.Tensor):\n",
    "            band_gap = band_gap.cpu().numpy()\n",
    "        if isinstance(topo_invariants, torch.Tensor):\n",
    "            topo_invariants = topo_invariants.cpu().numpy()\n",
    "        \n",
    "        # 1. Stability reward - negative formation energy with threshold\n",
    "        stability_threshold = self.config.get('stability_threshold', 0.2)\n",
    "        stability_reward = -np.clip(energy, -1.0, 1.0) * (energy < stability_threshold)\n",
    "        \n",
    "        # 2. Band gap reward - aim for target band gap\n",
    "        target_gap = self.config.get('target_band_gap', 0.3)  # in eV\n",
    "        gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\n",
    "        gap_reward = 1.0 - np.minimum(np.abs(band_gap - target_gap) / gap_tolerance, 1.0)\n",
    "        \n",
    "        # 3. Topological reward - prefer non-trivial topological insulators\n",
    "        # For Z2 invariants, we typically want (1;000) for strong 3D TIs\n",
    "        # Assuming first invariant is the strong Z2 index (ν₀)\n",
    "        strong_z2_idx = 0\n",
    "        topo_reward = topo_invariants[:, strong_z2_idx]\n",
    "        \n",
    "        # Add additional weight to other invariants if desired\n",
    "        if topo_invariants.shape[1] > 1:\n",
    "            weak_indices = np.mean(topo_invariants[:, 1:], axis=1) \n",
    "            # Typically want (1;000) so penalize non-zero weak indices slightly\n",
    "            topo_reward = topo_reward * (1.0 - 0.2 * weak_indices)\n",
    "        \n",
    "        # Combine rewards with configurable weights\n",
    "        w_stability = self.config.get('w_stability', 1.0)\n",
    "        w_gap = self.config.get('w_gap', 1.5)\n",
    "        w_topo = self.config.get('w_topo', 2.0)\n",
    "        \n",
    "        total_reward = (\n",
    "            w_stability * stability_reward +\n",
    "            w_gap * gap_reward +\n",
    "            w_topo * topo_reward\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'total': total_reward,\n",
    "            'stability': stability_reward,\n",
    "            'band_gap': gap_reward,\n",
    "            'topological': topo_reward\n",
    "        }\n",
    "    \n",
    "    def update_policy_reinforce(self, rewards, log_probs):\n",
    "        \"\"\"Update policy using REINFORCE algorithm.\"\"\"\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device)\n",
    "        \n",
    "        # Normalize rewards\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "        \n",
    "        # Calculate policy loss\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\n",
    "        \n",
    "        # Update policy\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        # Optional gradient clipping\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            \n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item()\n",
    "    \n",
    "    def update_policy_actor_critic(self, z_vectors, rewards):\n",
    "        \"\"\"Update policy using Actor-Critic algorithm.\"\"\"\n",
    "        if self.critic is None:\n",
    "            return None, None\n",
    "            \n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device)\n",
    "        \n",
    "        # Get critic's value predictions\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\n",
    "        \n",
    "        # Calculate advantages\n",
    "        advantages = rewards_tensor - value_predictions.detach()\n",
    "        \n",
    "        # Get latest policy log probabilities\n",
    "        _, log_probs = self.policy_net(z_vectors)\n",
    "        \n",
    "        # Calculate policy (actor) loss\n",
    "        policy_loss = -(log_probs * advantages).mean()\n",
    "        \n",
    "        # Calculate value (critic) loss\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\n",
    "        \n",
    "        # Update policy network\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        # Update critic network\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform a single training step.\"\"\"\n",
    "        # Generate structures\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\n",
    "        \n",
    "        # Predict properties\n",
    "        properties = self.predict_properties(z_vectors)\n",
    "        \n",
    "        # Calculate rewards\n",
    "        rewards_dict = self.calculate_rewards(properties)\n",
    "        total_rewards = rewards_dict['total']\n",
    "        \n",
    "        # Update policy\n",
    "        if self.critic is not None:\n",
    "            actor_loss, critic_loss = self.update_policy_actor_critic(z_vectors, total_rewards)\n",
    "            loss_info = {'actor_loss': actor_loss, 'critic_loss': critic_loss}\n",
    "        else:\n",
    "            policy_loss = self.update_policy_reinforce(total_rewards, log_probs)\n",
    "            loss_info = {'policy_loss': policy_loss}\n",
    "        \n",
    "        # Track best structures\n",
    "        best_idx = np.argmax(total_rewards)\n",
    "        best_reward = total_rewards[best_idx]\n",
    "        best_structure = {k: v[best_idx].cpu().detach().numpy() if isinstance(v, torch.Tensor) else v[best_idx] \n",
    "                         for k, v in structures.items()}\n",
    "        \n",
    "        # Update results\n",
    "        self.results['rewards'].append(np.mean(total_rewards))\n",
    "        self.results['max_rewards'].append(best_reward)\n",
    "        self.results['formation_energy'].append(np.mean(properties['formation_energy'].cpu().numpy()))\n",
    "        self.results['band_gap'].append(np.mean(properties['band_gap'].cpu().numpy()))\n",
    "        self.results['topo_score'].append(np.mean(properties['topo_invariants'].cpu().numpy()[:, 0]))\n",
    "        \n",
    "        if not self.results.get('best_reward', []) or best_reward > max(self.results.get('best_reward', [0])):\n",
    "            self.results['best_structure'] = best_structure\n",
    "            self.results['best_reward'] = best_reward\n",
    "            self.results['best_iteration'] = len(self.results['rewards']) - 1\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(total_rewards),\n",
    "            'max_reward': best_reward,\n",
    "            'mean_energy': np.mean(properties['formation_energy'].cpu().numpy()),\n",
    "            'loss_info': loss_info\n",
    "        }\n",
    "    \n",
    "    def train(self, num_iterations=None):\n",
    "        \"\"\"Train the model for specified iterations.\"\"\"\n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.config.get('num_iterations', 1000)\n",
    "        \n",
    "        logger.info(f\"Starting training for {num_iterations} iterations\")\n",
    "        \n",
    "        # Training loop\n",
    "        for iter_idx in tqdm(range(num_iterations)):\n",
    "            # Perform training step\n",
    "            step_info = self.train_step()\n",
    "            \n",
    "            # Log progress\n",
    "            if iter_idx % self.config.get('log_freq', 10) == 0:\n",
    "                loss_str = \"\"\n",
    "                if 'policy_loss' in step_info['loss_info']:\n",
    "                    loss_str = f\"Policy Loss: {step_info['loss_info']['policy_loss']:.4f}\"\n",
    "                elif 'actor_loss' in step_info['loss_info']:\n",
    "                    loss_str = (f\"Actor Loss: {step_info['loss_info']['actor_loss']:.4f}, \"\n",
    "                               f\"Critic Loss: {step_info['loss_info']['critic_loss']:.4f}\")\n",
    "                \n",
    "                logger.info(\n",
    "                    f\"Iter {iter_idx}/{num_iterations} | \"\n",
    "                    f\"Mean Reward: {step_info['mean_reward']:.4f} | \"\n",
    "                    f\"Max Reward: {step_info['max_reward']:.4f} | \"\n",
    "                    f\"Mean Energy: {step_info['mean_energy']:.4f} | \"\n",
    "                    f\"{loss_str}\"\n",
    "                )\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if iter_idx > 0 and iter_idx % self.config.get('save_freq', 100) == 0:\n",
    "                self.save_checkpoint(f\"checkpoint_iter_{iter_idx}.pt\")\n",
    "        \n",
    "        # Save final model\n",
    "        logger.info(\"Training completed\")\n",
    "        self.save_checkpoint(\"final_model.pt\")\n",
    "        self.save_results()\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint_dir = self.config.get('checkpoint_dir', './checkpoints')\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'policy_state_dict': self.policy_net.state_dict(),\n",
    "            'decoder_state_dict': self.decoder.state_dict(),\n",
    "            'config': self.config,\n",
    "            'iteration': len(self.results['rewards']),\n",
    "        }\n",
    "        \n",
    "        if self.critic is not None:\n",
    "            checkpoint['critic_state_dict'] = self.critic.state_dict()\n",
    "        \n",
    "        torch.save(checkpoint, os.path.join(checkpoint_dir, filename))\n",
    "        logger.info(f\"Saved checkpoint to {os.path.join(checkpoint_dir, filename)}\")\n",
    "    \n",
    "    def save_results(self):\n",
    "        \"\"\"Save training results and plots.\"\"\"\n",
    "        results_dir = self.config.get('results_dir', './results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        # Save metrics history\n",
    "        np.save(os.path.join(results_dir, 'training_metrics.npy'), dict(self.results))\n",
    "        \n",
    "        # Create and save plots\n",
    "        self.plot_training_results(os.path.join(results_dir, 'training_plots.png'))\n",
    "        \n",
    "        logger.info(f\"Saved results to {results_dir}\")\n",
    "    \n",
    "    def plot_training_results(self, filename):\n",
    "        \"\"\"Create plots of training metrics.\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # Plot average reward\n",
    "        axes[0, 0].plot(self.results['rewards'])\n",
    "        axes[0, 0].set_title('Average Reward')\n",
    "        axes[0, 0].set_xlabel('Iteration')\n",
    "        axes[0, 0].set_ylabel('Reward')\n",
    "        \n",
    "        # Plot formation energy\n",
    "        axes[0, 1].plot(self.results['formation_energy'])\n",
    "        axes[0, 1].set_title('Average Formation Energy')\n",
    "        axes[0, 1].set_xlabel('Iteration')\n",
    "        axes[0, 1].set_ylabel('Energy (eV)')\n",
    "        \n",
    "        # Plot band gap\n",
    "        axes[1, 0].plot(self.results['band_gap'])\n",
    "        axes[1, 0].set_title('Average Band Gap')\n",
    "        axes[1, 0].set_xlabel('Iteration')\n",
    "        axes[1, 0].set_ylabel('Band Gap (eV)')\n",
    "        \n",
    "        # Plot topological score\n",
    "        axes[1, 1].plot(self.results['topo_score'])\n",
    "        axes[1, 1].set_title('Average Topological Score')\n",
    "        axes[1, 1].set_xlabel('Iteration')\n",
    "        axes[1, 1].set_ylabel('Z2 Index (ν₀)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for RL-based latent space exploration.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 256]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer for mean\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "        # Learnable log std for exploration\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z_noise):\n",
    "        \"\"\"Forward pass through the policy network.\"\"\"\n",
    "        x = self.fc_layers(z_noise)\n",
    "        mu = self.fc_mu(x)\n",
    "        \n",
    "        # Get standard deviation from learnable parameter\n",
    "        std = torch.exp(self.log_std.clamp(-20, 2))  # Clamp for stability\n",
    "        \n",
    "        # Create normal distribution\n",
    "        dist = Normal(mu, std)\n",
    "        \n",
    "        # Sample using reparameterization trick\n",
    "        z_sampled = dist.rsample()\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        log_probs = dist.log_prob(z_sampled).sum(dim=-1)\n",
    "        \n",
    "        return z_sampled, log_probs\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"Critic network for actor-critic method.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 128]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value output\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"Forward pass through the critic network.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class PropertyPredictor(nn.Module):\n",
    "    \"\"\"Neural network for predicting material properties from latent space.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64], output_dim=1, name=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.name = name\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(input_dim, output_dim))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict property from latent vector.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "# Default configuration\n",
    "def get_default_config():\n",
    "    return {\n",
    "        # Model dimensions\n",
    "        'latent_dim': 32,\n",
    "        'hidden_dim': 128,\n",
    "        'max_atoms': 24,\n",
    "        \n",
    "        # Elements to consider - common in topological insulators\n",
    "        'elements': ['Bi', 'Sb', 'Te', 'Se', 'Sn', 'Ge', 'Pb', 'O', 'S'],\n",
    "        \n",
    "        # Network architectures\n",
    "        'policy_hidden_dims': [256, 256],\n",
    "        'critic_hidden_dims': [256, 128],\n",
    "        'property_hidden_dims': [128, 64],\n",
    "        \n",
    "        # Property prediction dimensions\n",
    "        'band_structure_dim': 5,  # Band gap + other band structure features\n",
    "        'topo_invariant_dim': 4,  # Z2 invariants (ν₀;ν₁ν₂ν₃)\n",
    "        \n",
    "        # Training parameters\n",
    "        'batch_size': 32,\n",
    "        'num_iterations': 500,\n",
    "        'policy_lr': 1e-4,\n",
    "        'critic_lr': 3e-4,\n",
    "        'weight_decay': 1e-6,\n",
    "        'use_critic': True,\n",
    "        'clip_grad': True,\n",
    "        'max_grad_norm': 1.0,\n",
    "        \n",
    "        # Reward components\n",
    "        'stability_threshold': 0.2,\n",
    "        'target_band_gap': 0.3,  # Target band gap in eV\n",
    "        'gap_tolerance': 0.2,    # Acceptable deviation from target\n",
    "        \n",
    "        # Reward weights\n",
    "        'w_stability': 1.0,\n",
    "        'w_gap': 1.5,\n",
    "        'w_topo': 2.0,\n",
    "        \n",
    "        # Logging and checkpoints\n",
    "        'log_freq': 10,\n",
    "        'save_freq': 100,\n",
    "        'checkpoint_dir': './checkpoints',\n",
    "        'results_dir': './results'\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import random\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Get configuration\n",
    "    config = get_default_config()\n",
    "    \n",
    "    # Create generator\n",
    "    ti_generator = TopologicalInsulatorGenerator(config)\n",
    "    \n",
    "    # Train model\n",
    "    results = ti_generator.train(num_iterations=500)\n",
    "    \n",
    "    # Generate and evaluate final structures\n",
    "    final_structures, z_vectors, _ = ti_generator.generate_structures(batch_size=10)\n",
    "    properties = ti_generator.predict_properties(z_vectors)\n",
    "    rewards = ti_generator.calculate_rewards(properties)\n",
    "    \n",
    "    # Print best structure information\n",
    "    best_idx = np.argmax(rewards['total'])\n",
    "    print(\"\\nBest Generated Structure:\")\n",
    "    print(f\"- Formation Energy: {properties['formation_energy'][best_idx].item():.4f} eV\")\n",
    "    print(f\"- Band Gap: {properties['band_gap'][best_idx].item():.4f} eV\")\n",
    "    print(f\"- Z2 Invariants: {properties['topo_invariants'][best_idx].cpu().numpy()}\")\n",
    "    print(f\"- Total Reward: {rewards['total'][best_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.fake_quantize_per_tensor_affine>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
