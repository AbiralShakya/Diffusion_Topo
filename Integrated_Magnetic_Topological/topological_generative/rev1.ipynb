{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cdvae.pl_modules.gemnet.layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcdvae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpl_modules\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcdvae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpl_modules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecoder\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cdvae/pl_modules/decoder.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcdvae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpl_modules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MAX_ATOMIC_NUM\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcdvae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpl_modules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemnet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgemnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GemNetT\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_mlp\u001b[39m(in_dim, hidden_dim, fc_num_layers, out_dim):\n\u001b[1;32m     10\u001b[0m     mods \u001b[38;5;241m=\u001b[39m [nn\u001b[38;5;241m.\u001b[39mLinear(in_dim, hidden_dim), nn\u001b[38;5;241m.\u001b[39mReLU()]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/cdvae/pl_modules/gemnet/gemnet.py:19\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_sparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseTensor\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcdvae\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     get_pbc_distances, radius_graph_pbc, frac_to_cart_coords)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01matom_update_block\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputBlock\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EfficientInteractionDownProjection\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cdvae.pl_modules.gemnet.layers'"
     ]
    }
   ],
   "source": [
    "import cdvae.pl_modules\n",
    "import cdvae.pl_modules.decoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cdvae\n",
    "from cdvae.pl_modules.decoder import GemNetTDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "0.6.18\n"
     ]
    }
   ],
   "source": [
    "import torch_scatter\n",
    "print(torch_scatter.__version__)\n",
    "import torch_sparse\n",
    "print(torch_sparse.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentPolicyNet(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim)\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))  # Learnable log std\n",
    "\n",
    "    def forward(self, z_noise):\n",
    "        mu = self.fc(z_noise)\n",
    "        std = torch.exp(self.log_std)\n",
    "        dist = torch.distributions.Normal(mu, std)\n",
    "        z_sampled = dist.rsample()  # Reparameterized sampling\n",
    "        return z_sampled, dist.log_prob(z_sampled).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce_update(policy_net, optimizer, rewards, log_probs):\n",
    "    rewards = torch.tensor(rewards)\n",
    "    rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)  # Normalize\n",
    "    loss = -(log_probs * rewards).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_formation_energy(structure):\n",
    "    # Placeholder for formation energy estimation\n",
    "    return torch.randn(1).item()  # Replace with actual implementation\n",
    "\n",
    "def predict_magnetic_ordering(structure):\n",
    "    # Placeholder for magnetic ordering prediction\n",
    "    return torch.sigmoid(torch.randn(1)).item()  # Replace with actual implementation\n",
    "\n",
    "decoder = GemNetTDecoder(latent_dim=latent_dim, n_elements=10)  # Example: Adjust n_elements\n",
    "\n",
    "def decoder(z):\n",
    "    # Use the CDVAE decoder to generate structures\n",
    "    generated_structure = decoder(z) # Assuming decoder takes a latent vector z\n",
    "    return [generated_structure for _ in range(batch_size)]\n",
    "\n",
    "def reward_function(structure):\n",
    "    # Custom logic based on simulated structure\n",
    "    energy = estimate_formation_energy(structure)\n",
    "    magnetic_score = predict_magnetic_ordering(structure)\n",
    "\n",
    "    reward = -energy + 2.0 * magnetic_score  # Tunable trade-off\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_steps = 100\n",
    "batch_size = 32\n",
    "latent_dim = 16\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Initialize policy network and optimizer\n",
    "policy_net = LatentPolicyNet(latent_dim)\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "\n",
    "for step in range(num_steps):\n",
    "    z_noise = torch.randn(batch_size, latent_dim)\n",
    "    z_sampled, log_probs = policy_net(z_noise)\n",
    "\n",
    "    # Decode structure from CDVAE decoder\n",
    "    generated_structures = decoder(z_sampled)\n",
    "\n",
    "    # Score each generated structure\n",
    "    rewards = []\n",
    "    for structure in generated_structures:\n",
    "        reward = reward_function(structure)\n",
    "        rewards.append(reward)\n",
    "\n",
    "    # Update policy using REINFORCE\n",
    "    loss = reinforce_update(policy_net, optimizer, rewards, log_probs)\n",
    "\n",
    "    print(f\"Step {step} | Avg Reward: {sum(rewards)/len(rewards):.3f} | Policy Loss: {loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
