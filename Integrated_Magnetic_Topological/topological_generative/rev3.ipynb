{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\\n",
    "import torch.nn as nn\\n",
    "import torch.nn.functional as F\\n",
    "import numpy as np\\n",
    "from torch.distributions import Normal, kl_divergence\\n",
    "import logging\\n",
    "import time\\n",
    "from tqdm import tqdm\\n",
    "import pickle\\n",
    "import os\\n",
    "import random\\n",
    "\\n",
    "import sys\\n",
    "\\n",
    "\\n",
    "sys.path.insert(0, '/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/cdvae')\\n",
    "import cdvae\\n",
    "# from cdvae.pl_modules.model import CDVAE\\n",
    "# from cdvae.common.data_utils import get_train_val_test_test_loaders\\n",
    "# from cdvae.common.data_utils import get_train_val_test_loaders\\n",
    "# from cdvae.pl_data.dataset import CDVAEDataset\\n",
    "\\n",
    "# Set up logging\\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\\n",
    "logger = logging.getLogger(__name__)\\n",
    "\\n",
    "class CDVAE_TI_Generator:\\n",
    "    \"\"\"\n",
    "    Crystal Diffusion Variational Autoencoder (CDVAE) with Reinforcement Learning\n",
    "    for targeted generation of Topological Insulator materials.\n",
    "    \"\"\"\\n",
    "    def __init__(self, config):\\n",
    "        self.config = config\\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\n",
    "        self.dtype = torch.float32 #set default tensor type to float32\\n",
    "        logger.info(f\"Using device: {self.device}\")\\n",
    "        \\n",
    "        # Initialize CDVAE model components\\n",
    "        self.initialize_models()\\n",
    "        \\n",
    "        # Set up optimizers\\n",
    "        self.setup_optimizers()\\n",
    "        \\n",
    "        # Initialize results tracking\\n",
    "        self.results = {\\n",
    "            'rewards': [],\\n",
    "            'z_gap': [],\\n",
    "            'topological_indices': [],\\n",
    "            'formation_energies': [],\\n",
    "            'best_structures': [],\\n",
    "            'best_rewards': [],\\n",
    "        }\\n",
    "        \\n",
    "        # Initialize replay buffer for experience replay\\n",
    "        self.replay_buffer = ReplayBuffer(config['buffer_size'])\\n",
    "        \\n",
    "    def initialize_models(self):\\n",
    "        \"\"\"Initialize CDVAE encoder, decoder and policy networks.\"\"\"\\n",
    "        # Import specific model classes\\n",
    "        try:\\n",
    "            from cdvae.pl_modules.decoder import GemNetTDecoder\\n",
    "            from cdvae.common.data_utils import StandardScalerTorch\\n",
    "            from cdvae.common.data_utils import ATOM_TYPES\\n",
    "     \\n",
    "        except ImportError:\\n",
    "            logger.error(\"Failed to import CDVAE modules. Please ensure CDVAE is installed correctly.\")\\n",
    "            raise\\n",
    "            \\n",
    "        # Get dimensions and parameters from config\\n",
    "        self.latent_dim = self.config['latent_dim']\\n",
    "        self.n_elements = len(self.config['elements']) if 'elements' in self.config else len(ATOM_TYPES.get())\\n",
    "        \\n",
    "        #TODO: possibly write an encoder file addition to cdvae\\n",
    "        # Initialize encoder (if using pre-trained weights)\\n",
    "        # if self.config.get('use_encoder', False):\\n",
    "        #     self.encoder = GraphEncoder(\\n",
    "        #         hidden_dim=self.config['hidden_dim'],\\n",
    "        #         latent_dim=self.latent_dim,\\n",
    "        #         use_layer_norm=self.config.get('use_layer_norm', True)\\n",
    "        #     ).to(self.device)\\n",
    "            \\n",
    "        #     if self.config.get('encoder_checkpoint'):\\n",
    "        #         self._load_model(self.encoder, self.config['encoder_checkpoint'])\\n",
    "        # else:\\n",
    "        #     self.encoder = None\\n",
    "\\n",
    "        self.encoder = None\\n",
    "            \\n",
    "        # Initialize decoder\\n",
    "        self.decoder = GemNetTDecoder(\\n",
    "            latent_dim=self.latent_dim,\\n",
    "            hidden_dim=self.config['hidden_dim'],\\n",
    "            #cutoff=self.config.get('cutoff', 6.0),\\n",
    "            max_neighbors=self.config.get('max_neighbors', 20),\\n",
    "            #use_layer_norm=self.config.get('use_layer_norm', True)\\n",
    "        ).to(self.device)\\n",
    "        \\n",
    "        if self.config.get('decoder_checkpoint'):\\n",
    "            self._load_model(self.decoder, self.config['decoder_checkpoint'])\\n",
    "\\n",
    "        import inspect\\n",
    "        print(\"Decoder signature:\", inspect.signature(self.decoder.forward))\\n",
    "            \\n",
    "        # Initialize policy network for RL\\n",
    "        self.policy_net = PolicyNetwork(\\n",
    "            latent_dim=self.latent_dim,\\n",
    "            hidden_dims=self.config.get('policy_hidden_dims', [256, 256]),\\n",
    "            activation=self.config.get('policy_activation', 'relu')\\n",
    "        ).to(self.device)\\n",
    "        \\n",
    "        # Initialize critic network for actor-critic methods\\n",
    "        if self.config.get('use_critic', True):\\n",
    "            self.critic = CriticNetwork(\\n",
    "                latent_dim=self.latent_dim,\\n",
    "                hidden_dims=self.config.get('critic_hidden_dims', [256, 128]),\\n",
    "                activation=self.config.get('critic_activation', 'relu')\\n",
    "            ).to(self.device)\\n",
    "        else:\\n",
    "            self.critic = None\\n",
    "            \\n",
    "        # DFT surrogate models - predict quantum properties directly from latent space\\n",
    "        self.energy_predictor = EnergyPredictor(\\n",
    "            latent_dim=self.latent_dim,\\n",
    "            hidden_dims=self.config.get('energy_predictor_dims', [128, 64])\\n",
    "        ).to(self.device)\\n",
    "        \\n",
    "        self.topological_predictor = TopologicalPredictor(\\n",
    "            latent_dim=self.latent_dim,\\n",
    "            hidden_dims=self.config.get('topo_predictor_dims', [128, 64])\\n",
    "        ).to(self.device)\\n",
    "        \\n",
    "        if self.config.get('surrogate_checkpoint'):\\n",
    "            self._load_surrogate_models(self.config['surrogate_checkpoint'])\\n",
    "        \\n",
    "    def setup_optimizers(self):\\n",
    "        \"\"\"Set up optimizers for different components.\"\"\"\\n",
    "        # Policy optimizer\\n",
    "        self.policy_optimizer = torch.optim.Adam(\\n",
    "            self.policy_net.parameters(),\\n",
    "            lr=self.config.get('policy_lr', 1e-4),\\n",
    "            weight_decay=self.config.get('policy_weight_decay', 1e-6)\\n",
    "        )\\n",
    "        \\n",
    "        # Critic optimizer (if using actor-critic)\\n",
    "        if self.critic is not None:\\n",
    "            self.critic_optimizer = torch.optim.Adam(\\n",
    "                self.critic.parameters(),\\n",
    "                lr=self.config.get('critic_lr', 3e-4),\\n",
    "                weight_decay=self.config.get('critic_weight_decay', 1e-6)\\n",
    "        )\\n",
    "        \\n",
    "        # Surrogate model optimizers for fine-tuning\\n",
    "        if self.config.get('train_surrogates', False):\\n",
    "            self.energy_optimizer = torch.optim.Adam(\\n",
    "                self.energy_predictor.parameters(),\\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\\n",
    "            )\\n",
    "            \\n",
    "            self.topo_optimizer = torch.optim.Adam(\\n",
    "                self.topological_predictor.parameters(),\\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\\n",
    "            )\\n",
    "            \\n",
    "    def _load_model(self, model, checkpoint_path):\\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\\n",
    "        try:\\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\\n",
    "            if 'state_dict' in checkpoint:\\n",
    "                # Handle pytorch-lightning checkpoints\\n",
    "                state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items() \\n",
    "                              if k.startswith('model.')}\\n",
    "                model.load_state_dict(state_dict, strict=False)\\n",
    "            else:\\n",
    "                # Handle regular torch checkpoints\\n",
    "                model.load_state_dict(checkpoint, strict=False)\\n",
    "            logger.info(f\"Loaded weights from {checkpoint_path}\")\\n",
    "        except Exception as e:\\n",
    "            logger.error(f\"Failed to load weights: {e}\")\\n",
    "            \\n",
    "    def _load_surrogate_models(self, checkpoint_path):\\n",
    "        \"\"\"Load surrogate model weights.\"\"\"\\n",
    "        try:\\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\\n",
    "            self.energy_predictor.load_state_dict(checkpoint['energy_predictor'])\\n",
    "            self.topological_predictor.load_state_dict(checkpoint['topo_predictor'])\\n",
    "            logger.info(f\"Loaded surrogate models from {checkpoint_path}\")\\n",
    "        except Exception as e:\\n",
    "            logger.error(f\"Failed to load surrogate models: {e}\")\\n",
    "    \\n",
    "    def generate_structures(self, batch_size=None):\\n",
    "        \"\"\"Generate crystal structures using the policy network and decoder.\"\"\"\\n",
    "        if batch_size is None:\\n",
    "            batch_size = self.config.get('batch_size', 32)\\n",
    "                \\n",
    "        # Sample latent vectors from the policy network\\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim, device=self.device, dtype=self.dtype)\\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\\n",
    "        \\n",
    "        # For testing, let's use a smaller batch size and fewer atoms per crystal\\n",
    "        max_atoms = 8  # Small number of atoms per crystal for testing\\n",
    "        \\n",
    "        # Create a batch where each structure has a different number of atoms\\n",
    "        num_atoms = torch.randint(2, max_atoms+1, (batch_size,), device=self.device)\\n",
    "    \\n",
    "        # Create tensors with proper dimensions\\n",
    "        total_atoms = num_atoms.sum().item()\\n",
    "        \\n",
    "        # Create a batch index (for tracking purposes, not passed to decoder)\\n",
    "        batch_idx = torch.repeat_interleave(\\n",
    "            torch.arange(batch_size, device=self.device), \\n",
    "            num_atoms\\n",
    "        )\\n",
    "        \\n",
    "        # Random fractional coordinates for each atom (values between 0 and 1)\\n",
    "        frac_coords = torch.rand(total_atoms, 3, device=self.device, dtype=self.dtype)\\n",
    "        \\n",
    "        # Random atom types\\n",
    "        atom_types = torch.randint(0, self.n_elements + 1, (total_atoms,), device=self.device)\\n",
    "        \\n",
    "        # Random unit cell parameters\\n",
    "        lengths = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 5 + 5  # Between 5-10 Å\\n",
    "        angles = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 30 + 90  # Between 90-120°\\n",
    "\\n",
    "        print(\"z_sampled.shape:\", z_sampled.shape)\\n",
    "        print(\"frac_coords.shape:\", frac_coords.shape)\\n",
    "        print(\"atom_types.shape:\", atom_types.shape,\\n",
    "            \"   max atom_types:\", atom_types.max().item(),\\n",
    "            \"   n_elements:\", self.n_elements)\\n",
    "        print(\"num_atoms.shape:\", num_atoms.shape,\\n",
    "            \"   sum num_atoms:\", num_atoms.sum().item())\\n",
    "        print(\"lengths.shape:\", lengths.shape)\\n",
    "        print(\"angles.shape:\", angles.shape)\\n",
    "\\n",
    "    \\n",
    "        # Generate structures using the decoder\\n",
    "        with torch.no_grad():\\n",
    "            try:\\n",
    "                # Remove batch_idx from the arguments - decoder doesn't expect it\\n",
    "                pred_cart_coord_diff, pred_atom_types = self.decoder(\\n",
    "                    z_sampled,\\n",
    "                    frac_coords,\\n",
    "                    atom_types,\\n",
    "                    num_atoms,\\n",
    "                    lengths,\\n",
    "                    angles\\n",
    "                )\\n",
    "                \\n",
    "                # Combine the results\\n",
    "                generated_structures = {\\n",
    "                    'batch_idx': batch_idx,  # Still store it for reference\\n",
    "                    'frac_coords': frac_coords,\\n",
    "                    'atom_types': atom_types,\\n",
    "                    'num_atoms': num_atoms,\\n",
    "                    'lengths': lengths,\\n",
    "                    'angles': angles,\\n",
    "                    'pred_cart_coord_diff': pred_cart_coord_diff,\\n",
    "                    'pred_atom_types': pred_atom_types\\n",
    "                }\\n",
    "            \\n",
    "            except Exception as e:\\n",
    "                print(f\"Error in decoder: {e}\")\\n",
    "                # Add more debug information if needed\\n",
    "                generated_structures = {\\n",
    "                    'batch_idx': batch_idx,\\n",
    "                    'frac_coords': frac_coords,\\n",
    "                    'atom_types': atom_types,\\n",
    "                    'num_atoms': num_atoms,\\n",
    "                    'lengths': lengths,\\n",
    "                    'angles': angles\\n",
    "                }\\n",
    "            \\n",
    "        return generated_structures, z_sampled, log_probs\\n",
    "    \\n",
    "    def evaluate_structures(self, structures, z_vectors):\\n",
    "        \"\"\"Evaluate generated structures using surrogate models.\"\"\"\\n",
    "        # Predict formation energies\\n",
    "        with torch.no_grad():\\n",
    "            energies = self.energy_predictor(z_vectors)\\n",
    "            \\n",
    "            # Predict topological indices (Z2 invariants, Chern numbers, etc.)\\n",
    "            topo_indices = self.topological_predictor(z_vectors)\\n",
    "            \\n",
    "            # Calculate band gaps (can be part of the topological predictor or separate)\\n",
    "            band_gaps = self.estimate_band_gap(structures, z_vectors)\\n",
    "            \\n",
    "        # Combine predictions into a comprehensive evaluation\\n",
    "        evaluations = {\\n",
    "            'formation_energies': energies.cpu().numpy(),\\n",
    "            'topological_indices': topo_indices.cpu().numpy(),\\n",
    "            'band_gaps': band_gaps.cpu().numpy() if isinstance(band_gaps, torch.Tensor) else band_gaps\\n",
    "        }\\n",
    "        \\n",
    "        return evaluations\\n",
    "    \\n",
    "    def calculate_rewards(self, evaluations):\\n",
    "        \"\"\"Calculate rewards based on desired material properties.\"\"\"\\n",
    "        # Extract evaluations\\n",
    "        energies = evaluations['formation_energies']\\n",
    "        topo_indices = evaluations['topological_indices']\\n",
    "        band_gaps = evaluations['band_gaps']\\n",
    "\\n",
    "        energies  = np.array(energies).squeeze()  \\n",
    "        band_gaps = np.array(band_gaps).squeeze()  \\n",
    "        \\n",
    "        # Convert to numpy for easier manipulation\\n",
    "        if isinstance(energies, torch.Tensor):\\n",
    "            energies = energies.cpu().numpy().squeeze()\\n",
    "        if isinstance(topo_indices, torch.Tensor):\\n",
    "            topo_indices = topo_indices.cpu().numpy()\\n",
    "        if isinstance(band_gaps, torch.Tensor):\\n",
    "            band_gaps = band_gaps.cpu().numpy().squeeze()\\n",
    "            \\n",
    "        # Calculate stability reward component\\n",
    "        # Lower formation energy is better, but must be below threshold to be stable\\n",
    "        # stability_threshold = self.config.get('stability_threshold', 0.1)\\n",
    "        # stability_rewards = -energies * (energies < stability_threshold)\\n",
    "\\n",
    "        stability_rewards = -energies * (energies < self.config['stability_threshold'])\\n",
    "        \\n",
    "        # Calculate topological reward component\\n",
    "        # For Z2 invariants, we typically want (1;000) for 3D TIs\\n",
    "        # This is a simplified example - actual implementation depends on how topo_indices are represented\\n",
    "        topo_rewards = np.sum(topo_indices * self.config.get('topo_weights'), axis=1)\\n",
    "        \\n",
    "        # Calculate band gap reward component\\n",
    "        # Usually want a moderate band gap (not too small, not too large)\\n",
    "        # target_gap = self.config.get('target_band_gap', 0.3)  # in eV\\n",
    "        # gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\\n",
    "        # gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target_gap) / gap_tolerance, 1.0)\\n",
    "\\n",
    "        target = self.config['target_band_gap']\\n",
    "        tol    = self.config['gap_tolerance']\\n",
    "        gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target) / tol, 1.0)\\n",
    "        \\n",
    "        combined_rewards = ( self.config['w_stability']   * stability_rewards\\n",
    "                       + self.config['w_topological'] * topo_rewards\\n",
    "                       + self.config['w_gap']         * gap_rewards )\\n",
    "        \\n",
    "        # Combine reward components with configurable weights\\n",
    "        # w_stability = self.config.get('w_stability', 1.0)\\n",
    "        # w_topological = self.config.get('w_topological', 2.0)\\n",
    "        # w_gap = self.config.get('w_gap', 1.5)\\n",
    "        \\n",
    "        # combined_rewards = (w_stability * stability_rewards + \\n",
    "        #                    w_topological * topo_rewards +\\n",
    "        #                    w_gap * gap_rewards)\\n",
    "        \\n",
    "        # Create rewards dictionary\\n",
    "        rewards_dict = {\\n",
    "            'total': combined_rewards,\\n",
    "            'stability': stability_rewards,\\n",
    "            'topological': topo_rewards,\\n",
    "            'band_gap': gap_rewards\\n",
    "        }\\n",
    "        \\n",
    "        return rewards_dict\\n",
    "    \\n",
    "    def estimate_band_gap(self, structures, z_vectors):\\n",
    "        \"\"\"Estimate band gaps of structures using a surrogate model.\"\"\"\\n",
    "        # This would typically be a separate model or part of topological_predictor\\n",
    "        # For simplicity, we'll use a mock implementation\\n",
    "        batch_size = z_vectors.shape[0]\\n",
    "        \\n",
    "        # Mock band gap estimation (replace with actual model)\\n",
    "        # In practice, this would use a trained neural network or other predictor\\n",
    "        gaps = 0.2 + 0.3 * torch.sigmoid(z_vectors[:, 0]) + 0.1 * torch.randn(batch_size).to(self.device)\\n",
    "        \\n",
    "        return gaps\\n",
    "    \\n",
    "    def reinforce_update(self, rewards, log_probs):\\n",
    "        \"\"\"Update policy network using REINFORCE algorithm.\"\"\"\\n",
    "        # Convert to tensor with the right dtype\\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\\n",
    "        \\n",
    "        # Normalize rewards\\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\\n",
    "        \\n",
    "        # Calculate policy loss\\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\\n",
    "        \\n",
    "        # Update policy\\n",
    "        self.policy_optimizer.zero_grad()\\n",
    "        policy_loss.backward()\\n",
    "        \\n",
    "        # Optional gradient clipping\\n",
    "        if self.config.get('clip_grad', False):\\n",
    "            torch.nn.utils.clip_grad_norm_(\\n",
    "                self.policy_net.parameters(), \\n",
    "                self.config.get('max_grad_norm', 1.0)\\n",
    "            )\\n",
    "            \\n",
    "        self.policy_optimizer.step()\\n",
    "        \\n",
    "        return policy_loss.item()\\n",
    "    \\n",
    "    def actor_critic_update(self, z_vectors, rewards, log_probs):\\n",
    "        \"\"\"Update policy and critic networks using Actor-Critic algorithm.\"\"\"\\n",
    "        if self.critic is None:\\n",
    "            return self.reinforce_update(rewards, log_probs)\\n",
    "            \\n",
    "        # Convert rewards to tensor with proper dtype\\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\\n",
    "        \\n",
    "        # Get critic's value predictions\\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\\n",
    "        \\n",
    "        # Calculate advantages\\n",
    "        advantages = rewards_tensor - value_predictions.detach()\\n",
    "        \\n",
    "        # Calculate policy (actor) loss\\n",
    "        policy_loss = -(log_probs * advantages).mean()\\n",
    "        \\n",
    "        # Calculate value (critic) loss\\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\\n",
    "        \\n",
    "        # Option 1: Combine losses and do a single backward pass\\n",
    "        total_loss = policy_loss + critic_loss\\n",
    "        \\n",
    "        # Zero all gradients\\n",
    "        self.policy_optimizer.zero_grad()\\n",
    "        self.critic_optimizer.zero_grad()\\n",
    "        \\n",
    "        # Single backward pass\\n",
    "        total_loss.backward()\\n",
    "        \\n",
    "        # Apply gradient clipping if needed\\n",
    "        if self.config.get('clip_grad', False):\\n",
    "            torch.nn.utils.clip_grad_norm_(\\n",
    "                self.policy_net.parameters(), \\n",
    "                self.config.get('max_grad_norm', 1.0)\\n",
    "            )\\n",
    "            torch.nn.utils.clip_grad_norm_(\\n",
    "                self.critic.parameters(), \\n",
    "                self.config.get('max_grad_norm', 1.0)\\n",
    "        )\\n",
    "        \\n",
    "        # Update both networks\\n",
    "        self.policy_optimizer.step()\\n",
    "        self.critic_optimizer.step()\\n",
    "        \\n",
    "        return policy_loss.item(), critic_loss.item()\\n",
    "    \\n",
    "    def train_step(self):\\n",
    "        \"\"\"Perform a single training step.\"\"\"\\n",
    "        # Generate structures\\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\\n",
    "        print(len(structures))\\n",
    "\\n",
    "        if not structures: \\n",
    "            logger.error(\"no strucutres generated in this step\")\\n",
    "            return  {'mean_reward': 0, 'max_reward': 0, 'mean_energy': 0, 'policy_loss': 0}\\n",
    "        \\n",
    "        # Evaluate structures\\n",
    "        evaluations = self.evaluate_structures(structures, z_vectors)\\n",
    "        \\n",
    "        # Calculate rewards\\n",
    "        rewards_dict = self.calculate_rewards(evaluations)\\n",
    "        total_rewards = rewards_dict['total']\\n",
    "        \\n",
    "        # Store experience in replay buffer\\n",
    "        for i in range(len(total_rewards)):\\n",
    "            self.replay_buffer.add(\\n",
    "                z_vectors[i].detach().cpu().numpy(),\\n",
    "                total_rewards[i],\\n",
    "                log_probs[i].detach().cpu().numpy()\\n",
    "        )\\n",
    "        \\n",
    "        # Update policy using actor-critic or REINFORCE\\n",
    "        if self.critic is not None:\\n",
    "            loss_info = self.actor_critic_update(z_vectors, total_rewards, log_probs)\\n",
    "            policy_loss = loss_info[0]\\n",
    "        else:\\n",
    "            policy_loss = self.reinforce_update(total_rewards, log_probs)\\n",
    "            \\n",
    "        # Track best structures\\n",
    "        best_idx = np.argmax(total_rewards)\\n",
    "\\n",
    "        if best_idx >= len(total_rewards):\\n",
    "            logger.warning(f\"best_idx {best_idx} out of bounds for total_rewards with length {len(total_rewards)}\")\\n",
    "            best_idx = len(total_rewards) # Fallback to first item\\n",
    "\\n",
    "        print(f\"Type of total_rewards: {type(total_rewards)}\")\\n",
    "        print(f\"Shape of total_rewards: {total_rewards.shape if hasattr(total_rewards, 'shape') else 'no shape attribute'}\")\\n",
    "        print(f\"Type of total_rewards[best_idx]: {type(total_rewards[best_idx])}\")\\n",
    "            \\n",
    "        # Fix: Access the scalar value directly without trying to index further\\n",
    "        #best_reward = float(total_rewards[best_idx])  # Remove the [0] indexing\\n",
    "        reward_value = total_rewards[best_idx]\\n",
    "        if isinstance(reward_value, np.ndarray):\\n",
    "            if reward_value.size == 1:\\n",
    "                best_reward = float(reward_value.item())\\n",
    "            else:\\n",
    "                # If it's an array with multiple values, take the first one if it exists\n",
    "                if reward_value.size > 0:\\n",
    "                    best_reward = float(reward_value[0])\\n",
    "                else:\\n",
    "                    best_reward = 0.0  # Use a default value if the array is empty\n",
    "        else:\\n",
    "            # If it's already a scalar type (int, float)\\n",
    "            best_reward = float(reward_value)\\n",
    "\\n",
    "        # Determine if this iteration’s best is a new overall best\\n",
    "        if len(self.results['best_rewards']) == 0:\\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 119/500 [00:00<00:02, 143.06it/s]2025-04-06 23:26:39,059 - INFO - Iteration 120 | Mean Reward: 5.1776 | Max Reward: 5.6320 | Mean Energy: 0.1892 | Policy Loss: 3.7522\n",
      "2025-04-06 23:26:39,145 - INFO - Iteration 130 | Mean Reward: 5.2703 | Max Reward: 6.2409 | Mean Energy: 0.1930 | Policy Loss: 32.1442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([26, 3])\n",
      "atom_types.shape: torch.Size([26])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 26\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([26, 3])\n",
      "atom_types.shape: torch.Size([26])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 26\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([30, 3])\n",
      "atom_types.shape: torch.Size([30])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 30\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 135/500 [00:00<00:02, 142.45it/s]2025-04-06 23:26:39,204 - INFO - Iteration 140 | Mean Reward: 5.4709 | Max Reward: 5.8629 | Mean Energy: 0.1498 | Policy Loss: -13.9368\n",
      "2025-04-06 23:26:39,266 - INFO - Iteration 150 | Mean Reward: 5.4830 | Max Reward: 6.1737 | Mean Energy: 0.2210 | Policy Loss: -11.4455\n",
      " 30%|███       | 151/500 [00:00<00:02, 145.98it/s]2025-04-06 23:26:39,334 - INFO - Iteration 160 | Mean Reward: 4.9239 | Max Reward: 5.6218 | Mean Energy: 0.1955 | Policy Loss: -88.9962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 8    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([32, 3])\n",
      "atom_types.shape: torch.Size([32])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 32\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([28, 3])\n",
      "atom_types.shape: torch.Size([28])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 28\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([12, 3])\n",
      "atom_types.shape: torch.Size([12])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 12\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 167/500 [00:01<00:02, 146.70it/s]2025-04-06 23:26:39,394 - INFO - Iteration 170 | Mean Reward: 5.8319 | Max Reward: 5.9408 | Mean Energy: 0.1782 | Policy Loss: 62.4459\n",
      "2025-04-06 23:26:39,476 - INFO - Iteration 180 | Mean Reward: 5.7373 | Max Reward: 6.0154 | Mean Energy: 0.2259 | Policy Loss: 66.9870\n",
      " 37%|███▋      | 183/500 [00:01<00:02, 145.85it/s]2025-04-06 23:26:39,539 - INFO - Iteration 190 | Mean Reward: 5.5781 | Max Reward: 5.9975 | Mean Energy: 0.2211 | Policy Loss: -5.9526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([13, 3])\n",
      "atom_types.shape: torch.Size([13])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 13\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 23:26:39,587 - INFO - Iteration 200 | Mean Reward: 5.7093 | Max Reward: 6.0162 | Mean Energy: 0.1901 | Policy Loss: -5.2434\n",
      "2025-04-06 23:26:39,591 - INFO - Saved checkpoint to ./checkpoints/checkpoint_iter_200.pt\n",
      " 40%|████      | 201/500 [00:01<00:01, 152.91it/s]2025-04-06 23:26:39,665 - INFO - Iteration 210 | Mean Reward: 5.8581 | Max Reward: 6.2391 | Mean Energy: 0.1839 | Policy Loss: 15.3575\n",
      " 43%|████▎     | 217/500 [00:01<00:01, 153.66it/s]2025-04-06 23:26:39,712 - INFO - Iteration 220 | Mean Reward: 5.3414 | Max Reward: 5.7130 | Mean Energy: 0.1292 | Policy Loss: -85.3527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([12, 3])\n",
      "atom_types.shape: torch.Size([12])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 12\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([28, 3])\n",
      "atom_types.shape: torch.Size([28])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 28\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([31, 3])\n",
      "atom_types.shape: torch.Size([31])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 31\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([13, 3])\n",
      "atom_types.shape: torch.Size([13])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 13\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([26, 3])\n",
      "atom_types.shape: torch.Size([26])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 26\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([30, 3])\n",
      "atom_types.shape: torch.Size([30])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 30\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 8    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([10, 3])\n",
      "atom_types.shape: torch.Size([10])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 10\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 23:26:39,794 - INFO - Iteration 230 | Mean Reward: 5.3944 | Max Reward: 6.1550 | Mean Energy: 0.1991 | Policy Loss: 13.3547\n",
      " 47%|████▋     | 233/500 [00:01<00:01, 151.24it/s]2025-04-06 23:26:39,856 - INFO - Iteration 240 | Mean Reward: 5.5531 | Max Reward: 6.2787 | Mean Energy: 0.1456 | Policy Loss: 3.0870\n",
      "2025-04-06 23:26:39,900 - INFO - Iteration 250 | Mean Reward: 5.1568 | Max Reward: 5.4540 | Mean Energy: 0.1625 | Policy Loss: -87.0580\n",
      " 50%|█████     | 252/500 [00:01<00:01, 161.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 8    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 23:26:40,006 - INFO - Iteration 260 | Mean Reward: 5.4691 | Max Reward: 6.0165 | Mean Energy: 0.1827 | Policy Loss: 8.5990\n",
      " 54%|█████▍    | 269/500 [00:01<00:01, 137.75it/s]2025-04-06 23:26:40,098 - INFO - Iteration 270 | Mean Reward: 5.4726 | Max Reward: 5.7916 | Mean Energy: 0.2049 | Policy Loss: 15.2624\n",
      "2025-04-06 23:26:40,172 - INFO - Iteration 280 | Mean Reward: 5.3738 | Max Reward: 6.0549 | Mean Energy: 0.1229 | Policy Loss: -50.7153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 8    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([11, 3])\n",
      "atom_types.shape: torch.Size([11])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 11\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([12, 3])\n",
      "atom_types.shape: torch.Size([12])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 12\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([30, 3])\n",
      "atom_types.shape: torch.Size([30])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 30\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([26, 3])\n",
      "atom_types.shape: torch.Size([26])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 26\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 284/500 [00:01<00:01, 131.72it/s]2025-04-06 23:26:40,246 - INFO - Iteration 290 | Mean Reward: 5.4607 | Max Reward: 6.1862 | Mean Energy: 0.2327 | Policy Loss: 0.9914\n",
      " 60%|██████    | 300/500 [00:01<00:01, 138.42it/s]2025-04-06 23:26:40,330 - INFO - Iteration 300 | Mean Reward: 5.3346 | Max Reward: 5.9100 | Mean Energy: 0.1741 | Policy Loss: 26.1835\n",
      "2025-04-06 23:26:40,334 - INFO - Saved checkpoint to ./checkpoints/checkpoint_iter_300.pt\n",
      "2025-04-06 23:26:40,380 - INFO - Iteration 310 | Mean Reward: 5.3598 | Max Reward: 5.8004 | Mean Energy: 0.2325 | Policy Loss: 26.7792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 8    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([12, 3])\n",
      "atom_types.shape: torch.Size([12])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 12\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 8    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([26, 3])\n",
      "atom_types.shape: torch.Size([26])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 26\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 316/500 [00:02<00:01, 142.73it/s]2025-04-06 23:26:40,439 - INFO - Iteration 320 | Mean Reward: 5.6123 | Max Reward: 5.8602 | Mean Energy: 0.1226 | Policy Loss: 36.6093\n",
      "2025-04-06 23:26:40,520 - INFO - Iteration 330 | Mean Reward: 5.3877 | Max Reward: 5.9344 | Mean Energy: 0.2314 | Policy Loss: -27.0765\n",
      " 66%|██████▌   | 331/500 [00:02<00:01, 138.32it/s]2025-04-06 23:26:40,577 - INFO - Iteration 340 | Mean Reward: 5.5283 | Max Reward: 5.9090 | Mean Energy: 0.3005 | Policy Loss: -55.3324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([29, 3])\n",
      "atom_types.shape: torch.Size([29])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 29\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([12, 3])\n",
      "atom_types.shape: torch.Size([12])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 12\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 8    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 346/500 [00:02<00:01, 141.19it/s]2025-04-06 23:26:40,664 - INFO - Iteration 350 | Mean Reward: 5.5603 | Max Reward: 5.8805 | Mean Energy: 0.1934 | Policy Loss: 8.0761\n",
      "2025-04-06 23:26:40,713 - INFO - Iteration 360 | Mean Reward: 5.4864 | Max Reward: 6.1687 | Mean Energy: 0.1558 | Policy Loss: -8.7150\n",
      " 73%|███████▎  | 363/500 [00:02<00:00, 142.39it/s]2025-04-06 23:26:40,808 - INFO - Iteration 370 | Mean Reward: 5.4500 | Max Reward: 6.0215 | Mean Energy: 0.1873 | Policy Loss: -57.9535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 8    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([29, 3])\n",
      "atom_types.shape: torch.Size([29])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 29\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([30, 3])\n",
      "atom_types.shape: torch.Size([30])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 30\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 378/500 [00:02<00:00, 139.15it/s]2025-04-06 23:26:40,879 - INFO - Iteration 380 | Mean Reward: 4.9356 | Max Reward: 5.4425 | Mean Energy: 0.2046 | Policy Loss: -73.1938\n",
      "2025-04-06 23:26:40,939 - INFO - Iteration 390 | Mean Reward: 5.6547 | Max Reward: 6.0154 | Mean Energy: 0.1577 | Policy Loss: 31.4462\n",
      " 79%|███████▉  | 395/500 [00:02<00:00, 146.80it/s]2025-04-06 23:26:41,011 - INFO - Iteration 400 | Mean Reward: 5.3837 | Max Reward: 6.0991 | Mean Energy: 0.1345 | Policy Loss: -14.8145\n",
      "2025-04-06 23:26:41,015 - INFO - Saved checkpoint to ./checkpoints/checkpoint_iter_400.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([13, 3])\n",
      "atom_types.shape: torch.Size([13])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 13\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([12, 3])\n",
      "atom_types.shape: torch.Size([12])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 12\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([28, 3])\n",
      "atom_types.shape: torch.Size([28])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 28\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 410/500 [00:02<00:00, 141.04it/s]2025-04-06 23:26:41,088 - INFO - Iteration 410 | Mean Reward: 5.5015 | Max Reward: 6.0820 | Mean Energy: 0.2162 | Policy Loss: 21.1853\n",
      "2025-04-06 23:26:41,133 - INFO - Iteration 420 | Mean Reward: 5.2333 | Max Reward: 6.0635 | Mean Energy: 0.1663 | Policy Loss: -74.1671\n",
      " 86%|████████▌ | 428/500 [00:02<00:00, 150.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([13, 3])\n",
      "atom_types.shape: torch.Size([13])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 13\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([13, 3])\n",
      "atom_types.shape: torch.Size([13])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 13\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([26, 3])\n",
      "atom_types.shape: torch.Size([26])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 26\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([26, 3])\n",
      "atom_types.shape: torch.Size([26])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 26\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([29, 3])\n",
      "atom_types.shape: torch.Size([29])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 29\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 23:26:41,221 - INFO - Iteration 430 | Mean Reward: 5.3713 | Max Reward: 5.7705 | Mean Energy: 0.1673 | Policy Loss: 49.8074\n",
      "2025-04-06 23:26:41,300 - INFO - Iteration 440 | Mean Reward: 5.0632 | Max Reward: 5.7770 | Mean Energy: 0.1317 | Policy Loss: -63.5696\n",
      " 89%|████████▉ | 444/500 [00:02<00:00, 138.85it/s]2025-04-06 23:26:41,339 - INFO - Iteration 450 | Mean Reward: 5.4124 | Max Reward: 5.9809 | Mean Energy: 0.2344 | Policy Loss: -53.8459\n",
      "2025-04-06 23:26:41,409 - INFO - Iteration 460 | Mean Reward: 5.7679 | Max Reward: 6.0332 | Mean Energy: 0.1704 | Policy Loss: 25.8896\n",
      " 92%|█████████▏| 462/500 [00:03<00:00, 149.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([13, 3])\n",
      "atom_types.shape: torch.Size([13])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 13\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([29, 3])\n",
      "atom_types.shape: torch.Size([29])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 29\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([12, 3])\n",
      "atom_types.shape: torch.Size([12])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 12\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([25, 3])\n",
      "atom_types.shape: torch.Size([25])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 25\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 8    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([10, 3])\n",
      "atom_types.shape: torch.Size([10])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 10\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([16, 3])\n",
      "atom_types.shape: torch.Size([16])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 16\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([27, 3])\n",
      "atom_types.shape: torch.Size([27])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 27\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 23:26:41,452 - INFO - Iteration 470 | Mean Reward: 5.4006 | Max Reward: 5.5662 | Mean Energy: 0.1711 | Policy Loss: 19.4634\n",
      " 96%|█████████▌| 480/500 [00:03<00:00, 157.26it/s]2025-04-06 23:26:41,519 - INFO - Iteration 480 | Mean Reward: 4.7322 | Max Reward: 4.8652 | Mean Energy: 0.1979 | Policy Loss: -74.3793\n",
      "2025-04-06 23:26:41,571 - INFO - Iteration 490 | Mean Reward: 5.5721 | Max Reward: 6.0914 | Mean Energy: 0.2233 | Policy Loss: -18.7111\n",
      "100%|█████████▉| 498/500 [00:03<00:00, 163.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([28, 3])\n",
      "atom_types.shape: torch.Size([28])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 28\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([19, 3])\n",
      "atom_types.shape: torch.Size([19])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 19\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([11, 3])\n",
      "atom_types.shape: torch.Size([11])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 11\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([13, 3])\n",
      "atom_types.shape: torch.Size([13])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 13\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([26, 3])\n",
      "atom_types.shape: torch.Size([26])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 26\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([24, 3])\n",
      "atom_types.shape: torch.Size([24])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 24\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([22, 3])\n",
      "atom_types.shape: torch.Size([22])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 22\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([20, 3])\n",
      "atom_types.shape: torch.Size([20])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 20\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([15, 3])\n",
      "atom_types.shape: torch.Size([15])    max atom_types: 9    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 15\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([18, 3])\n",
      "atom_types.shape: torch.Size([18])    max atom_types: 8    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 18\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([23, 3])\n",
      "atom_types.shape: torch.Size([23])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 23\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([17, 3])\n",
      "atom_types.shape: torch.Size([17])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 17\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([21, 3])\n",
      "atom_types.shape: torch.Size([21])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 21\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([31, 3])\n",
      "atom_types.shape: torch.Size([31])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 31\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([9, 3])\n",
      "atom_types.shape: torch.Size([9])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 9\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n",
      "6\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n",
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([28, 3])\n",
      "atom_types.shape: torch.Size([28])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 28\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 150.18it/s]\n",
      "2025-04-06 23:26:41,648 - INFO - Training completed\n",
      "2025-04-06 23:26:41,652 - INFO - Saved checkpoint to ./checkpoints/final_checkpoint.pt\n",
      "2025-04-06 23:26:41,655 - INFO - Saved results to ./results/training_results.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Type of total_rewards: <class 'numpy.ndarray'>\n",
      "Shape of total_rewards: (4,)\n",
      "Type of total_rewards[best_idx]: <class 'numpy.float64'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z_sampled.shape: torch.Size([4, 64])\n",
      "frac_coords.shape: torch.Size([14, 3])\n",
      "atom_types.shape: torch.Size([14])    max atom_types: 10    n_elements: 10\n",
      "num_atoms.shape: torch.Size([4])    sum num_atoms: 14\n",
      "lengths.shape: torch.Size([4, 3])\n",
      "angles.shape: torch.Size([4, 3])\n",
      "Error in decoder: index out of range in self\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    import random\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "    # Get default configuration\n",
    "    config = get_default_config()\n",
    "    \n",
    "    # Create training framework\n",
    "    # Set default tensor type\n",
    "    ti_generator = CDVAE_TI_Generator(config)\n",
    "    \n",
    "    # Train the model\n",
    "    ti_generator.train(num_iterations=500)\n",
    "    \n",
    "    # Plot training results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot rewards\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(ti_generator.results['rewards'])\n",
    "    plt.title('Average Reward')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Reward')\n",
    "    \n",
    "    # Plot formation energies\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(ti_generator.results['formation_energies'])\n",
    "    plt.title('Average Formation Energy')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Energy (eV)')\n",
    "    \n",
    "    # Plot topological indices\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(ti_generator.results['topological_indices'])\n",
    "    plt.title('Average Topological Index')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Index Value')\n",
    "    \n",
    "    # Plot best rewards\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(ti_generator.results['best_rewards'])\n",
    "    plt.title('Best Reward')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Reward')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_results.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate some final structures\n",
    "    structures, _, _ = ti_generator.generate_structures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import logging\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/cdvae')\n",
    "import cdvae\n",
    "# from cdvae.pl_modules.model import CDVAE\n",
    "# from cdvae.common.data_utils import get_train_val_test_test_loaders\n",
    "# from cdvae.common.data_utils import get_train_val_test_loaders\n",
    "# from cdvae.pl_data.dataset import CDVAEDataset\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CDVAE_TI_Generator:\n",
    "    \"\"\"\n",
    "    Crystal Diffusion Variational Autoencoder (CDVAE) with Reinforcement Learning\n",
    "    for targeted generation of Topological Insulator materials.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.float32 #set default tensor type to float32\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize CDVAE model components\n",
    "        self.initialize_models()\n",
    "        \n",
    "        # Set up optimizers\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Initialize results tracking\n",
    "        self.results = {\n",
    "            'rewards': [],\n",
    "            'z_gap': [],\n",
    "            'topological_indices': [],\n",
    "            'formation_energies': [],\n",
    "            'best_structures': [],\n",
    "            'best_rewards': [],\n",
    "        }\n",
    "        \n",
    "        # Initialize replay buffer for experience replay\n",
    "        self.replay_buffer = ReplayBuffer(config['buffer_size'])\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize CDVAE encoder, decoder and policy networks.\"\"\"\n",
    "        # Import specific model classes\n",
    "        try:\n",
    "            from cdvae.pl_modules.decoder import GemNetTDecoder\n",
    "            from cdvae.common.data_utils import StandardScalerTorch\n",
    "            from cdvae.common.data_utils import ATOM_TYPES\n",
    "     \n",
    "        except ImportError:\n",
    "            logger.error(\"Failed to import CDVAE modules. Please ensure CDVAE is installed correctly.\")\n",
    "            raise\n",
    "            \n",
    "        # Get dimensions and parameters from config\n",
    "        self.latent_dim = self.config['latent_dim']\n",
    "        self.n_elements = len(self.config['elements']) if 'elements' in self.config else len(ATOM_TYPES.get())\n",
    "        \n",
    "        #TODO: possibly write an encoder file addition to cdvae\n",
    "        # Initialize encoder (if using pre-trained weights)\n",
    "        # if self.config.get('use_encoder', False):\n",
    "        #     self.encoder = GraphEncoder(\n",
    "        #         hidden_dim=self.config['hidden_dim'],\n",
    "        #         latent_dim=self.latent_dim,\n",
    "        #         use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        #     ).to(self.device)\n",
    "            \n",
    "        #     if self.config.get('encoder_checkpoint'):\n",
    "        #         self._load_model(self.encoder, self.config['encoder_checkpoint'])\n",
    "        # else:\n",
    "        #     self.encoder = None\n",
    "\n",
    "        self.encoder = None\n",
    "            \n",
    "        # Initialize decoder\n",
    "        self.decoder = GemNetTDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.config['hidden_dim'],\n",
    "            #cutoff=self.config.get('cutoff', 6.0),\n",
    "            max_neighbors=self.config.get('max_neighbors', 20),\n",
    "            #use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('decoder_checkpoint'):\n",
    "            self._load_model(self.decoder, self.config['decoder_checkpoint'])\n",
    "\n",
    "        import inspect\n",
    "        print(\"Decoder signature:\", inspect.signature(self.decoder.forward))\n",
    "            \n",
    "        # Initialize policy network for RL\n",
    "        self.policy_net = PolicyNetwork(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('policy_hidden_dims', [256, 256]),\n",
    "            activation=self.config.get('policy_activation', 'relu')\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize critic network for actor-critic methods\n",
    "        if self.config.get('use_critic', True):\n",
    "            self.critic = CriticNetwork(\n",
    "                latent_dim=self.latent_dim,\n",
    "                hidden_dims=self.config.get('critic_hidden_dims', [256, 128]),\n",
    "                activation=self.config.get('critic_activation', 'relu')\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.critic = None\n",
    "            \n",
    "        # DFT surrogate models - predict quantum properties directly from latent space\n",
    "        self.energy_predictor = EnergyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('energy_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.topological_predictor = TopologicalPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('topo_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('surrogate_checkpoint'):\n",
    "            self._load_surrogate_models(self.config['surrogate_checkpoint'])\n",
    "        \n",
    "    def setup_optimizers(self):\n",
    "        \"\"\"Set up optimizers for different components.\"\"\"\n",
    "        # Policy optimizer\n",
    "        self.policy_optimizer = torch.optim.Adam(\n",
    "            self.policy_net.parameters(),\n",
    "            lr=self.config.get('policy_lr', 1e-4),\n",
    "            weight_decay=self.config.get('policy_weight_decay', 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Critic optimizer (if using actor-critic)\n",
    "        if self.critic is not None:\n",
    "            self.critic_optimizer = torch.optim.Adam(\n",
    "                self.critic.parameters(),\n",
    "                lr=self.config.get('critic_lr', 3e-4),\n",
    "                weight_decay=self.config.get('critic_weight_decay', 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Surrogate model optimizers for fine-tuning\n",
    "        if self.config.get('train_surrogates', False):\n",
    "            self.energy_optimizer = torch.optim.Adam(\n",
    "                self.energy_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "            self.topo_optimizer = torch.optim.Adam(\n",
    "                self.topological_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "    def _load_model(self, model, checkpoint_path):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'state_dict' in checkpoint:\n",
    "                # Handle pytorch-lightning checkpoints\n",
    "                state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items() \n",
    "                              if k.startswith('model.')}\n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "            else:\n",
    "                # Handle regular torch checkpoints\n",
    "                model.load_state_dict(checkpoint, strict=False)\n",
    "            logger.info(f\"Loaded weights from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load weights: {e}\")\n",
    "            \n",
    "    def _load_surrogate_models(self, checkpoint_path):\n",
    "        \"\"\"Load surrogate model weights.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.energy_predictor.load_state_dict(checkpoint['energy_predictor'])\n",
    "            self.topological_predictor.load_state_dict(checkpoint['topo_predictor'])\n",
    "            logger.info(f\"Loaded surrogate models from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load surrogate models: {e}\")\n",
    "    \n",
    "    def generate_structures(self, batch_size=None):\n",
    "        \"\"\"Generate crystal structures using the policy network and decoder.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.get('batch_size', 32)\n",
    "                \n",
    "        # Sample latent vectors from the policy network\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim, device=self.device, dtype=self.dtype)\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\n",
    "        \n",
    "        # For testing, let's use a smaller batch size and fewer atoms per crystal\n",
    "        max_atoms = 8  # Small number of atoms per crystal for testing\n",
    "        \n",
    "        # Create a batch where each structure has a different number of atoms\n",
    "        num_atoms = torch.randint(2, max_atoms+1, (batch_size,), device=self.device)\n",
    "    \n",
    "        # Create tensors with proper dimensions\n",
    "        total_atoms = num_atoms.sum().item()\n",
    "        \n",
    "        # Create a batch index (for tracking purposes, not passed to decoder)\n",
    "        batch_idx = torch.repeat_interleave(\n",
    "            torch.arange(batch_size, device=self.device), \n",
    "            num_atoms\n",
    "        )\n",
    "        \n",
    "        # Random fractional coordinates for each atom (values between 0 and 1)\n",
    "        frac_coords = torch.rand(total_atoms, 3, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Random atom types\n",
    "        atom_types = torch.randint(0, self.n_elements + 1, (total_atoms,), device=self.device)\n",
    "        \n",
    "        # Random unit cell parameters\n",
    "        lengths = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 5 + 5  # Between 5-10 Å\n",
    "        angles = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 30 + 90  # Between 90-120°\n",
    "\n",
    "        print(\"z_sampled.shape:\", z_sampled.shape)\n",
    "        print(\"frac_coords.shape:\", frac_coords.shape)\n",
    "        print(\"atom_types.shape:\", atom_types.shape,\n",
    "            \"   max atom_types:\", atom_types.max().item(),\n",
    "            \"   n_elements:\", self.n_elements)\n",
    "        print(\"num_atoms.shape:\", num_atoms.shape,\n",
    "            \"   sum num_atoms:\", num_atoms.sum().item())\n",
    "        print(\"lengths.shape:\", lengths.shape)\n",
    "        print(\"angles.shape:\", angles.shape)\n",
    "\n",
    "    \n",
    "        # Generate structures using the decoder\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Remove batch_idx from the arguments - decoder doesn't expect it\n",
    "                pred_cart_coord_diff, pred_atom_types = self.decoder(\n",
    "                    z_sampled,\n",
    "                    frac_coords,\n",
    "                    atom_types,\n",
    "                    num_atoms,\n",
    "                    lengths,\n",
    "                    angles\n",
    "                )\n",
    "                \n",
    "                # Combine the results\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,  # Still store it for reference\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles,\n",
    "                    'pred_cart_coord_diff': pred_cart_coord_diff,\n",
    "                    'pred_atom_types': pred_atom_types\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in decoder: {e}\")\n",
    "                # Add more debug information if needed\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles\n",
    "                }\n",
    "            \n",
    "        return generated_structures, z_sampled, log_probs\n",
    "    \n",
    "    def evaluate_structures(self, structures, z_vectors):\n",
    "        \"\"\"Evaluate generated structures using surrogate models.\"\"\"\n",
    "        # Predict formation energies\n",
    "        with torch.no_grad():\n",
    "            energies = self.energy_predictor(z_vectors)\n",
    "            \n",
    "            # Predict topological indices (Z2 invariants, Chern numbers, etc.)\n",
    "            topo_indices = self.topological_predictor(z_vectors)\n",
    "            \n",
    "            # Calculate band gaps (can be part of the topological predictor or separate)\n",
    "            band_gaps = self.estimate_band_gap(structures, z_vectors)\n",
    "            \n",
    "        # Combine predictions into a comprehensive evaluation\n",
    "        evaluations = {\n",
    "            'formation_energies': energies.cpu().numpy(),\n",
    "            'topological_indices': topo_indices.cpu().numpy(),\n",
    "            'band_gaps': band_gaps.cpu().numpy() if isinstance(band_gaps, torch.Tensor) else band_gaps\n",
    "        }\n",
    "        \n",
    "        return evaluations\n",
    "    \n",
    "    def calculate_rewards(self, evaluations):\n",
    "        \"\"\"Calculate rewards based on desired material properties.\"\"\"\n",
    "        # Extract evaluations\n",
    "        energies = evaluations['formation_energies']\n",
    "        topo_indices = evaluations['topological_indices']\n",
    "        band_gaps = evaluations['band_gaps']\n",
    "\n",
    "        energies  = np.array(energies).squeeze()  \n",
    "        band_gaps = np.array(band_gaps).squeeze()  \n",
    "        \n",
    "        # Convert to numpy for easier manipulation\n",
    "        if isinstance(energies, torch.Tensor):\n",
    "            energies = energies.cpu().numpy().squeeze()\n",
    "        if isinstance(topo_indices, torch.Tensor):\n",
    "            topo_indices = topo_indices.cpu().numpy()\n",
    "        if isinstance(band_gaps, torch.Tensor):\n",
    "            band_gaps = band_gaps.cpu().numpy().squeeze()\n",
    "            \n",
    "        # Calculate stability reward component\n",
    "        # Lower formation energy is better, but must be below threshold to be stable\n",
    "        # stability_threshold = self.config.get('stability_threshold', 0.1)\n",
    "        # stability_rewards = -energies * (energies < stability_threshold)\n",
    "\n",
    "        stability_rewards = -energies * (energies < self.config['stability_threshold'])\n",
    "        \n",
    "        # Calculate topological reward component\n",
    "        # For Z2 invariants, we typically want (1;000) for 3D TIs\n",
    "        # This is a simplified example - actual implementation depends on how topo_indices are represented\n",
    "        topo_rewards = np.sum(topo_indices * self.config.get('topo_weights'), axis=1)\n",
    "        \n",
    "        # Calculate band gap reward component\n",
    "        # Usually want a moderate band gap (not too small, not too large)\n",
    "        # target_gap = self.config.get('target_band_gap', 0.3)  # in eV\n",
    "        # gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\n",
    "        # gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target_gap) / gap_tolerance, 1.0)\n",
    "\n",
    "        target = self.config['target_band_gap']\n",
    "        tol    = self.config['gap_tolerance']\n",
    "        gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target) / tol, 1.0)\n",
    "        \n",
    "        combined_rewards = ( self.config['w_stability']   * stability_rewards\n",
    "                       + self.config['w_topological'] * topo_rewards\n",
    "                       + self.config['w_gap']         * gap_rewards )\n",
    "        \n",
    "        # Combine reward components with configurable weights\n",
    "        # w_stability = self.config.get('w_stability', 1.0)\n",
    "        # w_topological = self.config.get('w_topological', 2.0)\n",
    "        # w_gap = self.config.get('w_gap', 1.5)\n",
    "        \n",
    "        # combined_rewards = (w_stability * stability_rewards + \n",
    "        #                    w_topological * topo_rewards +\n",
    "        #                    w_gap * gap_rewards)\n",
    "        \n",
    "        # Create rewards dictionary\n",
    "        rewards_dict = {\n",
    "            'total': combined_rewards,\n",
    "            'stability': stability_rewards,\n",
    "            'topological': topo_rewards,\n",
    "            'band_gap': gap_rewards\n",
    "        }\n",
    "        \n",
    "        return rewards_dict\n",
    "    \n",
    "    def estimate_band_gap(self, structures, z_vectors):\n",
    "        \"\"\"Estimate band gaps of structures using a surrogate model.\"\"\"\n",
    "        # This would typically be a separate model or part of topological_predictor\n",
    "        # For simplicity, we'll use a mock implementation\n",
    "        batch_size = z_vectors.shape[0]\n",
    "        \n",
    "        # Mock band gap estimation (replace with actual model)\n",
    "        # In practice, this would use a trained neural network or other predictor\n",
    "        gaps = 0.2 + 0.3 * torch.sigmoid(z_vectors[:, 0]) + 0.1 * torch.randn(batch_size).to(self.device)\n",
    "        \n",
    "        return gaps\n",
    "    \n",
    "    def reinforce_update(self, rewards, log_probs):\n",
    "        \"\"\"Update policy network using REINFORCE algorithm.\"\"\"\n",
    "        # Convert to tensor with the right dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Normalize rewards\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "        \n",
    "        # Calculate policy loss\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\n",
    "        \n",
    "        # Update policy\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        # Optional gradient clipping\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            \n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item()\n",
    "    \n",
    "    def actor_critic_update(self, z_vectors, rewards, log_probs):\n",
    "        \"\"\"Update policy and critic networks using Actor-Critic algorithm.\"\"\"\n",
    "        if self.critic is None:\n",
    "            return self.reinforce_update(rewards, log_probs)\n",
    "            \n",
    "        # Convert rewards to tensor with proper dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Get critic's value predictions\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\n",
    "        \n",
    "        # Calculate advantages\n",
    "        advantages = rewards_tensor - value_predictions.detach()\n",
    "        \n",
    "        # Calculate policy (actor) loss\n",
    "        policy_loss = -(log_probs * advantages).mean()\n",
    "        \n",
    "        # Calculate value (critic) loss\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\n",
    "        \n",
    "        # Option 1: Combine losses and do a single backward pass\n",
    "        total_loss = policy_loss + critic_loss\n",
    "        \n",
    "        # Zero all gradients\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        \n",
    "        # Single backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Apply gradient clipping if needed\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.critic.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "        \n",
    "        # Update both networks\n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform a single training step.\"\"\"\n",
    "        # Generate structures\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\n",
    "        print(len(structures))\n",
    "\n",
    "        if not structures: \n",
    "            logger.error(\"no strucutres generated in this step\")\n",
    "            return  {'mean_reward': 0, 'max_reward': 0, 'mean_energy': 0, 'policy_loss': 0}\n",
    "        \n",
    "        # Evaluate structures\n",
    "        evaluations = self.evaluate_structures(structures, z_vectors)\n",
    "        \n",
    "        # Calculate rewards\n",
    "        rewards_dict = self.calculate_rewards(evaluations)\n",
    "        total_rewards = rewards_dict['total']\n",
    "        \n",
    "        # Store experience in replay buffer\n",
    "        for i in range(len(total_rewards)):\n",
    "            self.replay_buffer.add(\n",
    "                z_vectors[i].detach().cpu().numpy(),\n",
    "                total_rewards[i],\n",
    "                log_probs[i].detach().cpu().numpy()\n",
    "            )\n",
    "        \n",
    "        # Update policy using actor-critic or REINFORCE\n",
    "        if self.critic is not None:\n",
    "            loss_info = self.actor_critic_update(z_vectors, total_rewards, log_probs)\n",
    "            policy_loss = loss_info[0]\n",
    "        else:\n",
    "            policy_loss = self.reinforce_update(total_rewards, log_probs)\n",
    "            \n",
    "        # Track best structures\n",
    "        best_idx = np.argmax(total_rewards)\n",
    "\n",
    "        if best_idx >= len(total_rewards):\n",
    "            logger.warning(f\"best_idx {best_idx} out of bounds for total_rewards with length {len(total_rewards)}\")\n",
    "            best_idx = len(total_rewards) # Fallback to first item\n",
    "\n",
    "        print(f\"Type of total_rewards: {type(total_rewards)}\")\n",
    "        print(f\"Shape of total_rewards: {total_rewards.shape if hasattr(total_rewards, 'shape') else 'no shape attribute'}\")\n",
    "        print(f\"Type of total_rewards[best_idx]: {type(total_rewards[best_idx])}\")\n",
    "            \n",
    "        # Fix: Access the scalar value directly without trying to index further\n",
    "        #best_reward = float(total_rewards[best_idx])  # Remove the [0] indexing\n",
    "        reward_value = total_rewards[best_idx]\n",
    "        if isinstance(reward_value, np.ndarray):\n",
    "            if reward_value.size == 1:\n",
    "                best_reward = float(reward_value.item())\n",
    "            else:\n",
    "                # If it's an array with multiple values, take the first one\n",
    "                best_reward = float(reward_value[0])\n",
    "        else:\n",
    "            # If it's already a scalar type (int, float)\n",
    "            best_reward = float(reward_value)\n",
    "\n",
    "        # Determine if this iteration’s best is a new overall best\n",
    "        if len(self.results['best_rewards']) == 0:\n",
    "            is_new_best = True\n",
    "        else:\n",
    "            prev_best = max(self.results['best_rewards'])\n",
    "            # force a Python bool\n",
    "            is_new_best = bool(best_reward > prev_best)\n",
    "\n",
    "        if is_new_best:\n",
    "            best_struct = {\n",
    "                'frac_coords': structures['frac_coords'][best_idx],\n",
    "                'atom_types':  structures['atom_types'][best_idx],\n",
    "                'num_atoms':   structures['num_atoms'][best_idx],\n",
    "                'lengths':     structures['lengths'][best_idx],\n",
    "                'angles':      structures['angles'][best_idx],\n",
    "            }\n",
    "            # optional fields\n",
    "            pccd = structures.get('pred_cart_coord_diff', None)\n",
    "            if pccd is not None:\n",
    "                best_struct['pred_cart_coord_diff'] = pccd[best_idx]\n",
    "            pact = structures.get('pred_atom_types', None)\n",
    "            if pact is not None:\n",
    "                best_struct['pred_atom_types'] = pact[best_idx]\n",
    "\n",
    "            self.results['best_structures'].append(best_struct)\n",
    "\n",
    "        # Store results\n",
    "        self.results['rewards'].append(np.mean(total_rewards))\n",
    "        self.results['formation_energies'].append(np.mean(evaluations['formation_energies']))\n",
    "        self.results['topological_indices'].append(np.mean(evaluations['topological_indices']))\n",
    "        self.results['best_rewards'].append(best_reward)\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(total_rewards),\n",
    "            'max_reward': np.max(total_rewards),\n",
    "            'mean_energy': np.mean(evaluations['formation_energies']),\n",
    "            'policy_loss': policy_loss\n",
    "        }\n",
    "    \n",
    "    def train(self, num_iterations=None):\n",
    "        \"\"\"Train the model for the specified number of iterations.\"\"\"\n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.config.get('num_iterations', 500)\n",
    "            \n",
    "        logger.info(f\"Starting training for {num_iterations} iterations\")\n",
    "        \n",
    "        for iteration in tqdm(range(num_iterations)):\n",
    "            # Perform a training step\n",
    "            step_results = self.train_step()\n",
    "            \n",
    "            # Log progress periodically\n",
    "            if iteration % self.config.get('log_frequency', 10) == 0:\n",
    "                logger.info(\n",
    "                    f\"Iteration {iteration} | \"\n",
    "                    f\"Mean Reward: {step_results['mean_reward']:.4f} | \"\n",
    "                    f\"Max Reward: {step_results['max_reward']:.4f} | \"\n",
    "                    f\"Mean Energy: {step_results['mean_energy']:.4f} | \"\n",
    "                    f\"Policy Loss: {step_results['policy_loss']:.4f}\"\n",
    "                )\n",
    "                \n",
    "            # Save checkpoints periodically\n",
    "            if iteration % self.config.get('save_frequency', 100) == 0 and iteration > 0:\n",
    "                self.save_checkpoint(f\"checkpoint_iter_{iteration}.pt\")\n",
    "                \n",
    "        logger.info(\"Training completed\")\n",
    "        self.save_checkpoint(\"final_checkpoint.pt\")\n",
    "        self.save_results(\"training_results.pkl\")\n",
    "        \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint_dir = self.config.get('checkpoint_dir', './checkpoints')\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'policy_state_dict': self.policy_net.state_dict(),\n",
    "            'policy_optimizer': self.policy_optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'iteration': len(self.results['rewards'])\n",
    "        }\n",
    "        \n",
    "        if self.critic is not None:\n",
    "            checkpoint['critic_state_dict'] = self.critic.state_dict()\n",
    "            checkpoint['critic_optimizer'] = self.critic_optimizer.state_dict()\n",
    "            \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        \n",
    "    def save_results(self, filename):\n",
    "        \"\"\"Save training results.\"\"\"\n",
    "        results_dir = self.config.get('results_dir', './results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        results_path = os.path.join(results_dir, filename)\n",
    "        \n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(self.results, f)\n",
    "            \n",
    "        logger.info(f\"Saved results to {results_path}\")\n",
    "        \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])\n",
    "        self.policy_optimizer.load_state_dict(checkpoint['policy_optimizer'])\n",
    "        \n",
    "        if self.critic is not None and 'critic_state_dict' in checkpoint:\n",
    "            self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "            self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "            \n",
    "        logger.info(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "        return checkpoint.get('iteration', 0)\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for RL-based latent space exploration.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 256], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer for mean\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "        # Learnable log std for exploration\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # def _initialize_weights(self):\n",
    "    #     \"\"\"Initialize network weights.\"\"\"\n",
    "    #     for m in self.modules():\n",
    "    #         if isinstance(m, nn.Linear):\n",
    "    #             nn.init.xavier_normal_(m.weight)\n",
    "    #             if m.bias is not None:\n",
    "    #                 nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "                \n",
    "                # Ensure dtype is correct\n",
    "                m.weight.data = m.weight.data.to(dtype=torch.float32)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = m.bias.data.to(dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, z_noise):\n",
    "        \"\"\"\n",
    "        Forward pass through the policy network.\n",
    "        \n",
    "        Args:\n",
    "            z_noise: Random noise tensor of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            z_sampled: Sampled latent vectors\n",
    "            log_probs: Log probabilities of the sampled vectors\n",
    "        \"\"\"\n",
    "        x = self.fc_layers(z_noise)\n",
    "        mu = self.fc_mu(x)\n",
    "        \n",
    "        # Get standard deviation from learnable parameter\n",
    "        std = torch.exp(self.log_std.clamp(-20, 2))  # Clamp for stability\n",
    "        \n",
    "        # Create normal distribution\n",
    "        dist = Normal(mu, std)\n",
    "        \n",
    "        # Sample using reparameterization trick\n",
    "        z_sampled = dist.rsample()\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        log_probs = dist.log_prob(z_sampled).sum(dim=-1)\n",
    "        \n",
    "        return z_sampled, log_probs\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"Critic network for actor-critic method.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 128], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value output\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the critic network.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent vector of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            value: Predicted value of the state\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class EnergyPredictor(nn.Module):\n",
    "    \"\"\"Surrogate model to predict formation energy from latent space.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value for formation energy\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict formation energy from latent vector.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class TopologicalPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Surrogate model to predict topological invariants (Z2, Chern number) \n",
    "    from latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64], num_invariants=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - multiple values for topological invariants\n",
    "        # For 3D topological insulators, typically 4 Z2 invariants (ν₀;ν₁ν₂ν₃)\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.invariant_head = nn.Linear(input_dim, num_invariants)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict topological invariants from latent vector.\"\"\"\n",
    "        features = self.feature_extractor(z)\n",
    "        # Apply sigmoid to constrain outputs between 0 and 1\n",
    "        # In practice, these would be discretized to 0 or 1 when interpreting\n",
    "        invariants = torch.sigmoid(self.invariant_head(features))\n",
    "        return invariants\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer for more stable training.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size=10000):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def add(self, z, reward, log_prob):\n",
    "        \"\"\"Add experience to buffer.\"\"\"\n",
    "        if len(self.buffer) < self.max_size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (z, reward, log_prob)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        z, rewards, log_probs = map(np.array, zip(*batch))\n",
    "        return z, rewards, log_probs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size.\"\"\"\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import logging\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/cdvae')\n",
    "import cdvae\n",
    "# from cdvae.pl_modules.model import CDVAE\n",
    "# from cdvae.common.data_utils import get_train_val_test_test_loaders\n",
    "# from cdvae.common.data_utils import get_train_val_test_loaders\n",
    "# from cdvae.pl_data.dataset import CDVAEDataset\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CDVAE_TI_Generator:\n",
    "    \"\"\"\n",
    "    Crystal Diffusion Variational Autoencoder (CDVAE) with Reinforcement Learning\n",
    "    for targeted generation of Topological Insulator materials.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.float32 #set default tensor type to float32\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize CDVAE model components\n",
    "        self.initialize_models()\n",
    "        \n",
    "        # Set up optimizers\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Initialize results tracking\n",
    "        self.results = {\n",
    "            'rewards': [],\n",
    "            'z_gap': [],\n",
    "            'topological_indices': [],\n",
    "            'formation_energies': [],\n",
    "            'best_structures': [],\n",
    "            'best_rewards': [],\n",
    "        }\n",
    "        \n",
    "        # Initialize replay buffer for experience replay\n",
    "        self.replay_buffer = ReplayBuffer(config['buffer_size'])\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize CDVAE encoder, decoder and policy networks.\"\"\"\n",
    "        # Import specific model classes\n",
    "        try:\n",
    "            from cdvae.pl_modules.decoder import GemNetTDecoder\n",
    "            from cdvae.common.data_utils import StandardScalerTorch\n",
    "            from cdvae.common.data_utils import ATOM_TYPES\n",
    "     \n",
    "        except ImportError:\n",
    "            logger.error(\"Failed to import CDVAE modules. Please ensure CDVAE is installed correctly.\")\n",
    "            raise\n",
    "            \n",
    "        # Get dimensions and parameters from config\n",
    "        self.latent_dim = self.config['latent_dim']\n",
    "        self.n_elements = len(self.config['elements']) if 'elements' in self.config else len(ATOM_TYPES.get())\n",
    "        \n",
    "        #TODO: possibly write an encoder file addition to cdvae\n",
    "        # Initialize encoder (if using pre-trained weights)\n",
    "        # if self.config.get('use_encoder', False):\n",
    "        #     self.encoder = GraphEncoder(\n",
    "        #         hidden_dim=self.config['hidden_dim'],\n",
    "        #         latent_dim=self.latent_dim,\n",
    "        #         use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        #     ).to(self.device)\n",
    "            \n",
    "        #     if self.config.get('encoder_checkpoint'):\n",
    "        #         self._load_model(self.encoder, self.config['encoder_checkpoint'])\n",
    "        # else:\n",
    "        #     self.encoder = None\n",
    "\n",
    "        self.encoder = None\n",
    "            \n",
    "        # Initialize decoder\n",
    "        self.decoder = GemNetTDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.config['hidden_dim'],\n",
    "            #cutoff=self.config.get('cutoff', 6.0),\n",
    "            max_neighbors=self.config.get('max_neighbors', 20),\n",
    "            #use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('decoder_checkpoint'):\n",
    "            self._load_model(self.decoder, self.config['decoder_checkpoint'])\n",
    "\n",
    "        import inspect\n",
    "        print(\"Decoder signature:\", inspect.signature(self.decoder.forward))\n",
    "            \n",
    "        # Initialize policy network for RL\n",
    "        self.policy_net = PolicyNetwork(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('policy_hidden_dims', [256, 256]),\n",
    "            activation=self.config.get('policy_activation', 'relu')\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize critic network for actor-critic methods\n",
    "        if self.config.get('use_critic', True):\n",
    "            self.critic = CriticNetwork(\n",
    "                latent_dim=self.latent_dim,\n",
    "                hidden_dims=self.config.get('critic_hidden_dims', [256, 128]),\n",
    "                activation=self.config.get('critic_activation', 'relu')\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.critic = None\n",
    "            \n",
    "        # DFT surrogate models - predict quantum properties directly from latent space\n",
    "        self.energy_predictor = EnergyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('energy_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.topological_predictor = TopologicalPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('topo_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('surrogate_checkpoint'):\n",
    "            self._load_surrogate_models(self.config['surrogate_checkpoint'])\n",
    "        \n",
    "    def setup_optimizers(self):\n",
    "        \"\"\"Set up optimizers for different components.\"\"\"\n",
    "        # Policy optimizer\n",
    "        self.policy_optimizer = torch.optim.Adam(\n",
    "            self.policy_net.parameters(),\n",
    "            lr=self.config.get('policy_lr', 1e-4),\n",
    "            weight_decay=self.config.get('policy_weight_decay', 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Critic optimizer (if using actor-critic)\n",
    "        if self.critic is not None:\n",
    "            self.critic_optimizer = torch.optim.Adam(\n",
    "                self.critic.parameters(),\n",
    "                lr=self.config.get('critic_lr', 3e-4),\n",
    "                weight_decay=self.config.get('critic_weight_decay', 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Surrogate model optimizers for fine-tuning\n",
    "        if self.config.get('train_surrogates', False):\n",
    "            self.energy_optimizer = torch.optim.Adam(\n",
    "                self.energy_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "            self.topo_optimizer = torch.optim.Adam(\n",
    "                self.topological_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "    def _load_model(self, model, checkpoint_path):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'state_dict' in checkpoint:\n",
    "                # Handle pytorch-lightning checkpoints\n",
    "                state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items() \n",
    "                              if k.startswith('model.')}\n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "            else:\n",
    "                # Handle regular torch checkpoints\n",
    "                model.load_state_dict(checkpoint, strict=False)\n",
    "            logger.info(f\"Loaded weights from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load weights: {e}\")\n",
    "            \n",
    "    def _load_surrogate_models(self, checkpoint_path):\n",
    "        \"\"\"Load surrogate model weights.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.energy_predictor.load_state_dict(checkpoint['energy_predictor'])\n",
    "            self.topological_predictor.load_state_dict(checkpoint['topo_predictor'])\n",
    "            logger.info(f\"Loaded surrogate models from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load surrogate models: {e}\")\n",
    "    \n",
    "    def generate_structures(self, batch_size=None):\n",
    "        \"\"\"Generate crystal structures using the policy network and decoder.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.get('batch_size', 32)\n",
    "                \n",
    "        # Sample latent vectors from the policy network\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim, device=self.device, dtype=self.dtype)\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\n",
    "        \n",
    "        # For testing, let's use a smaller batch size and fewer atoms per crystal\n",
    "        max_atoms = 8  # Small number of atoms per crystal for testing\n",
    "        \n",
    "        # Create a batch where each structure has a different number of atoms\n",
    "        num_atoms = torch.randint(2, max_atoms+1, (batch_size,), device=self.device)\n",
    "    \n",
    "        # Create tensors with proper dimensions\n",
    "        total_atoms = num_atoms.sum().item()\n",
    "        \n",
    "        # Create a batch index (for tracking purposes, not passed to decoder)\n",
    "        batch_idx = torch.repeat_interleave(\n",
    "            torch.arange(batch_size, device=self.device), \n",
    "            num_atoms\n",
    "        )\n",
    "        \n",
    "        # Random fractional coordinates for each atom (values between 0 and 1)\n",
    "        frac_coords = torch.rand(total_atoms, 3, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Random atom types\n",
    "        atom_types = torch.randint(0, self.n_elements + 1, (total_atoms,), device=self.device)\n",
    "        \n",
    "        # Random unit cell parameters\n",
    "        lengths = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 5 + 5  # Between 5-10 Å\n",
    "        angles = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 30 + 90  # Between 90-120°\n",
    "\n",
    "        print(\"z_sampled.shape:\", z_sampled.shape)\n",
    "        print(\"frac_coords.shape:\", frac_coords.shape)\n",
    "        print(\"atom_types.shape:\", atom_types.shape,\n",
    "            \"   max atom_types:\", atom_types.max().item(),\n",
    "            \"   n_elements:\", self.n_elements)\n",
    "        print(\"num_atoms.shape:\", num_atoms.shape,\n",
    "            \"   sum num_atoms:\", num_atoms.sum().item())\n",
    "        print(\"lengths.shape:\", lengths.shape)\n",
    "        print(\"angles.shape:\", angles.shape)\n",
    "\n",
    "    \n",
    "        # Generate structures using the decoder\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Remove batch_idx from the arguments - decoder doesn't expect it\n",
    "                pred_cart_coord_diff, pred_atom_types = self.decoder(\n",
    "                    z_sampled,\n",
    "                    frac_coords,\n",
    "                    atom_types,\n",
    "                    num_atoms,\n",
    "                    lengths,\n",
    "                    angles\n",
    "                )\n",
    "                \n",
    "                # Combine the results\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,  # Still store it for reference\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles,\n",
    "                    'pred_cart_coord_diff': pred_cart_coord_diff,\n",
    "                    'pred_atom_types': pred_atom_types\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in decoder: {e}\")\n",
    "                # Add more debug information if needed\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles\n",
    "                }\n",
    "            \n",
    "        return generated_structures, z_sampled, log_probs\n",
    "    \n",
    "    def evaluate_structures(self, structures, z_vectors):\n",
    "        \"\"\"Evaluate generated structures using surrogate models.\"\"\"\n",
    "        # Predict formation energies\n",
    "        with torch.no_grad():\n",
    "            energies = self.energy_predictor(z_vectors)\n",
    "            \n",
    "            # Predict topological indices (Z2 invariants, Chern numbers, etc.)\n",
    "            topo_indices = self.topological_predictor(z_vectors)\n",
    "            \n",
    "            # Calculate band gaps (can be part of the topological predictor or separate)\n",
    "            band_gaps = self.estimate_band_gap(structures, z_vectors)\n",
    "            \n",
    "        # Combine predictions into a comprehensive evaluation\n",
    "        evaluations = {\n",
    "            'formation_energies': energies.cpu().numpy(),\n",
    "            'topological_indices': topo_indices.cpu().numpy(),\n",
    "            'band_gaps': band_gaps.cpu().numpy() if isinstance(band_gaps, torch.Tensor) else band_gaps\n",
    "        }\n",
    "        \n",
    "        return evaluations\n",
    "    \n",
    "    def calculate_rewards(self, evaluations):\n",
    "        \"\"\"Calculate rewards based on desired material properties.\"\"\"\n",
    "        # Extract evaluations\n",
    "        energies = evaluations['formation_energies']\n",
    "        topo_indices = evaluations['topological_indices']\n",
    "        band_gaps = evaluations['band_gaps']\n",
    "\n",
    "        energies  = np.array(energies).squeeze()  \n",
    "        band_gaps = np.array(band_gaps).squeeze()  \n",
    "        \n",
    "        # Convert to numpy for easier manipulation\n",
    "        if isinstance(energies, torch.Tensor):\n",
    "            energies = energies.cpu().numpy().squeeze()\n",
    "        if isinstance(topo_indices, torch.Tensor):\n",
    "            topo_indices = topo_indices.cpu().numpy()\n",
    "        if isinstance(band_gaps, torch.Tensor):\n",
    "            band_gaps = band_gaps.cpu().numpy().squeeze()\n",
    "            \n",
    "        # Calculate stability reward component\n",
    "        # Lower formation energy is better, but must be below threshold to be stable\n",
    "        # stability_threshold = self.config.get('stability_threshold', 0.1)\n",
    "        # stability_rewards = -energies * (energies < stability_threshold)\n",
    "\n",
    "        stability_rewards = -energies * (energies < self.config['stability_threshold'])\n",
    "        \n",
    "        # Calculate topological reward component\n",
    "        # For Z2 invariants, we typically want (1;000) for 3D TIs\n",
    "        # This is a simplified example - actual implementation depends on how topo_indices are represented\n",
    "        topo_rewards = np.sum(topo_indices * self.config.get('topo_weights'), axis=1)\n",
    "        \n",
    "        # Calculate band gap reward component\n",
    "        # Usually want a moderate band gap (not too small, not too large)\n",
    "        # target_gap = self.config.get('target_band_gap', 0.3)  # in eV\n",
    "        # gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\n",
    "        # gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target_gap) / gap_tolerance, 1.0)\n",
    "\n",
    "        target = self.config['target_band_gap']\n",
    "        tol    = self.config['gap_tolerance']\n",
    "        gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target) / tol, 1.0)\n",
    "        \n",
    "        combined_rewards = ( self.config['w_stability']   * stability_rewards\n",
    "                       + self.config['w_topological'] * topo_rewards\n",
    "                       + self.config['w_gap']         * gap_rewards )\n",
    "        \n",
    "        # Combine reward components with configurable weights\n",
    "        # w_stability = self.config.get('w_stability', 1.0)\n",
    "        # w_topological = self.config.get('w_topological', 2.0)\n",
    "        # w_gap = self.config.get('w_gap', 1.5)\n",
    "        \n",
    "        # combined_rewards = (w_stability * stability_rewards + \n",
    "        #                    w_topological * topo_rewards +\n",
    "        #                    w_gap * gap_rewards)\n",
    "        \n",
    "        # Create rewards dictionary\n",
    "        rewards_dict = {\n",
    "            'total': combined_rewards,\n",
    "            'stability': stability_rewards,\n",
    "            'topological': topo_rewards,\n",
    "            'band_gap': gap_rewards\n",
    "        }\n",
    "        \n",
    "        return rewards_dict\n",
    "    \n",
    "    def estimate_band_gap(self, structures, z_vectors):\n",
    "        \"\"\"Estimate band gaps of structures using a surrogate model.\"\"\"\n",
    "        # This would typically be a separate model or part of topological_predictor\n",
    "        # For simplicity, we'll use a mock implementation\n",
    "        batch_size = z_vectors.shape[0]\n",
    "        \n",
    "        # Mock band gap estimation (replace with actual model)\n",
    "        # In practice, this would use a trained neural network or other predictor\n",
    "        gaps = 0.2 + 0.3 * torch.sigmoid(z_vectors[:, 0]) + 0.1 * torch.randn(batch_size).to(self.device)\n",
    "        \n",
    "        return gaps\n",
    "    \n",
    "    def reinforce_update(self, rewards, log_probs):\n",
    "        \"\"\"Update policy network using REINFORCE algorithm.\"\"\"\n",
    "        # Convert to tensor with the right dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Normalize rewards\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "        \n",
    "        # Calculate policy loss\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\n",
    "        \n",
    "        # Update policy\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        # Optional gradient clipping\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            \n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item()\n",
    "    \n",
    "    def actor_critic_update(self, z_vectors, rewards, log_probs):\n",
    "        \"\"\"Update policy and critic networks using Actor-Critic algorithm.\"\"\"\n",
    "        if self.critic is None:\n",
    "            return self.reinforce_update(rewards, log_probs)\n",
    "            \n",
    "        # Convert rewards to tensor with proper dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Get critic's value predictions\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\n",
    "        \n",
    "        # Calculate advantages\n",
    "        advantages = rewards_tensor - value_predictions.detach()\n",
    "        \n",
    "        # Calculate policy (actor) loss\n",
    "        policy_loss = -(log_probs * advantages).mean()\n",
    "        \n",
    "        # Calculate value (critic) loss\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\n",
    "        \n",
    "        # Option 1: Combine losses and do a single backward pass\n",
    "        total_loss = policy_loss + critic_loss\n",
    "        \n",
    "        # Zero all gradients\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        \n",
    "        # Single backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Apply gradient clipping if needed\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.critic.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "        \n",
    "        # Update both networks\n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform a single training step.\"\"\"\n",
    "        # Generate structures\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\n",
    "        print(len(structures))\n",
    "\n",
    "        if not structures: \n",
    "            logger.error(\"no strucutres generated in this step\")\n",
    "            return  {'mean_reward': 0, 'max_reward': 0, 'mean_energy': 0, 'policy_loss': 0}\n",
    "        \n",
    "        # Evaluate structures\n",
    "        evaluations = self.evaluate_structures(structures, z_vectors)\n",
    "        \n",
    "        # Calculate rewards\n",
    "        rewards_dict = self.calculate_rewards(evaluations)\n",
    "        total_rewards = rewards_dict['total']\n",
    "        \n",
    "        # Store experience in replay buffer\n",
    "        for i in range(len(total_rewards)):\n",
    "            self.replay_buffer.add(\n",
    "                z_vectors[i].detach().cpu().numpy(),\n",
    "                total_rewards[i],\n",
    "                log_probs[i].detach().cpu().numpy()\n",
    "            )\n",
    "        \n",
    "        # Update policy using actor-critic or REINFORCE\n",
    "        if self.critic is not None:\n",
    "            loss_info = self.actor_critic_update(z_vectors, total_rewards, log_probs)\n",
    "            policy_loss = loss_info[0]\n",
    "        else:\n",
    "            policy_loss = self.reinforce_update(total_rewards, log_probs)\n",
    "            \n",
    "        # Track best structures\n",
    "        best_idx = np.argmax(total_rewards)\n",
    "\n",
    "        if best_idx >= len(total_rewards):\n",
    "            logger.warning(f\"best_idx {best_idx} out of bounds for total_rewards with length {len(total_rewards)}\")\n",
    "            best_idx = len(total_rewards) # Fallback to first item\n",
    "\n",
    "        print(f\"Type of total_rewards: {type(total_rewards)}\")\n",
    "        print(f\"Shape of total_rewards: {total_rewards.shape if hasattr(total_rewards, 'shape') else 'no shape attribute'}\")\n",
    "        print(f\"Type of total_rewards[best_idx]: {type(total_rewards[best_idx])}\")\n",
    "            \n",
    "        # Fix: Access the scalar value directly without trying to index further\n",
    "        #best_reward = float(total_rewards[best_idx])  # Remove the [0] indexing\n",
    "        reward_value = total_rewards[best_idx]\n",
    "        if isinstance(reward_value, np.ndarray):\n",
    "            if reward_value.size == 1:\n",
    "                best_reward = float(reward_value.item())\n",
    "            else:\n",
    "                # If it's an array with multiple values, take the first one\n",
    "                best_reward = float(reward_value[0])\n",
    "        else:\n",
    "            # If it's already a scalar type (int, float)\n",
    "            best_reward = float(reward_value)\n",
    "\n",
    "        # Determine if this iteration’s best is a new overall best\n",
    "        if len(self.results['best_rewards']) == 0:\n",
    "            is_new_best = True\n",
    "        else:\n",
    "            prev_best = max(self.results['best_rewards'])\n",
    "            # force a Python bool\n",
    "            is_new_best = bool(best_reward > prev_best)\n",
    "\n",
    "        if is_new_best:\n",
    "            best_struct = {\n",
    "                'frac_coords': structures['frac_coords'][best_idx],\n",
    "                'atom_types':  structures['atom_types'][best_idx],\n",
    "                'num_atoms':   structures['num_atoms'][best_idx],\n",
    "                'lengths':     structures['lengths'][best_idx],\n",
    "                'angles':      structures['angles'][best_idx],\n",
    "            }\n",
    "            # optional fields\n",
    "            pccd = structures.get('pred_cart_coord_diff', None)\n",
    "            if pccd is not None:\n",
    "                best_struct['pred_cart_coord_diff'] = pccd[best_idx]\n",
    "            pact = structures.get('pred_atom_types', None)\n",
    "            if pact is not None:\n",
    "                best_struct['pred_atom_types'] = pact[best_idx]\n",
    "\n",
    "            self.results['best_structures'].append(best_struct)\n",
    "\n",
    "        # Store results\n",
    "        self.results['rewards'].append(np.mean(total_rewards))\n",
    "        self.results['formation_energies'].append(np.mean(evaluations['formation_energies']))\n",
    "        self.results['topological_indices'].append(np.mean(evaluations['topological_indices']))\n",
    "        self.results['best_rewards'].append(best_reward)\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(total_rewards),\n",
    "            'max_reward': np.max(total_rewards),\n",
    "            'mean_energy': np.mean(evaluations['formation_energies']),\n",
    "            'policy_loss': policy_loss\n",
    "        }\n",
    "    \n",
    "    def train(self, num_iterations=None):\n",
    "        \"\"\"Train the model for the specified number of iterations.\"\"\"\n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.config.get('num_iterations', 500)\n",
    "            \n",
    "        logger.info(f\"Starting training for {num_iterations} iterations\")\n",
    "        \n",
    "        for iteration in tqdm(range(num_iterations)):\n",
    "            # Perform a training step\n",
    "            step_results = self.train_step()\n",
    "            \n",
    "            # Log progress periodically\n",
    "            if iteration % self.config.get('log_frequency', 10) == 0:\n",
    "                logger.info(\n",
    "                    f\"Iteration {iteration} | \"\n",
    "                    f\"Mean Reward: {step_results['mean_reward']:.4f} | \"\n",
    "                    f\"Max Reward: {step_results['max_reward']:.4f} | \"\n",
    "                    f\"Mean Energy: {step_results['mean_energy']:.4f} | \"\n",
    "                    f\"Policy Loss: {step_results['policy_loss']:.4f}\"\n",
    "                )\n",
    "                \n",
    "            # Save checkpoints periodically\n",
    "            if iteration % self.config.get('save_frequency', 100) == 0 and iteration > 0:\n",
    "                self.save_checkpoint(f\"checkpoint_iter_{iteration}.pt\")\n",
    "                \n",
    "        logger.info(\"Training completed\")\n",
    "        self.save_checkpoint(\"final_checkpoint.pt\")\n",
    "        self.save_results(\"training_results.pkl\")\n",
    "        \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint_dir = self.config.get('checkpoint_dir', './checkpoints')\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'policy_state_dict': self.policy_net.state_dict(),\n",
    "            'policy_optimizer': self.policy_optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'iteration': len(self.results['rewards'])\n",
    "        }\n",
    "        \n",
    "        if self.critic is not None:\n",
    "            checkpoint['critic_state_dict'] = self.critic.state_dict()\n",
    "            checkpoint['critic_optimizer'] = self.critic_optimizer.state_dict()\n",
    "            \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        \n",
    "    def save_results(self, filename):\n",
    "        \"\"\"Save training results.\"\"\"\n",
    "        results_dir = self.config.get('results_dir', './results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        results_path = os.path.join(results_dir, filename)\n",
    "        \n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(self.results, f)\n",
    "            \n",
    "        logger.info(f\"Saved results to {results_path}\")\n",
    "        \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])\n",
    "        self.policy_optimizer.load_state_dict(checkpoint['policy_optimizer'])\n",
    "        \n",
    "        if self.critic is not None and 'critic_state_dict' in checkpoint:\n",
    "            self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "            self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "            \n",
    "        logger.info(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "        return checkpoint.get('iteration', 0)\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for RL-based latent space exploration.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 256], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer for mean\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "        # Learnable log std for exploration\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # def _initialize_weights(self):\n",
    "    #     \"\"\"Initialize network weights.\"\"\"\n",
    "    #     for m in self.modules():\n",
    "    #         if isinstance(m, nn.Linear):\n",
    "    #             nn.init.xavier_normal_(m.weight)\n",
    "    #             if m.bias is not None:\n",
    "    #                 nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "                \n",
    "                # Ensure dtype is correct\n",
    "                m.weight.data = m.weight.data.to(dtype=torch.float32)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = m.bias.data.to(dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, z_noise):\n",
    "        \"\"\"\n",
    "        Forward pass through the policy network.\n",
    "        \n",
    "        Args:\n",
    "            z_noise: Random noise tensor of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            z_sampled: Sampled latent vectors\n",
    "            log_probs: Log probabilities of the sampled vectors\n",
    "        \"\"\"\n",
    "        x = self.fc_layers(z_noise)\n",
    "        mu = self.fc_mu(x)\n",
    "        \n",
    "        # Get standard deviation from learnable parameter\n",
    "        std = torch.exp(self.log_std.clamp(-20, 2))  # Clamp for stability\n",
    "        \n",
    "        # Create normal distribution\n",
    "        dist = Normal(mu, std)\n",
    "        \n",
    "        # Sample using reparameterization trick\n",
    "        z_sampled = dist.rsample()\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        log_probs = dist.log_prob(z_sampled).sum(dim=-1)\n",
    "        \n",
    "        return z_sampled, log_probs\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"Critic network for actor-critic method.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 128], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value output\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the critic network.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent vector of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            value: Predicted value of the state\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class EnergyPredictor(nn.Module):\n",
    "    \"\"\"Surrogate model to predict formation energy from latent space.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value for formation energy\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict formation energy from latent vector.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class TopologicalPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Surrogate model to predict topological invariants (Z2, Chern number) \n",
    "    from latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64], num_invariants=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - multiple values for topological invariants\n",
    "        # For 3D topological insulators, typically 4 Z2 invariants (ν₀;ν₁ν₂ν₃)\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.invariant_head = nn.Linear(input_dim, num_invariants)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict topological invariants from latent vector.\"\"\"\n",
    "        features = self.feature_extractor(z)\n",
    "        # Apply sigmoid to constrain outputs between 0 and 1\n",
    "        # In practice, these would be discretized to 0 or 1 when interpreting\n",
    "        invariants = torch.sigmoid(self.invariant_head(features))\n",
    "        return invariants\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer for more stable training.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size=10000):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def add(self, z, reward, log_prob):\n",
    "        \"\"\"Add experience to buffer.\"\"\"\n",
    "        if len(self.buffer) < self.max_size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (z, reward, log_prob)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        z, rewards, log_probs = map(np.array, zip(*batch))\n",
    "        return z, rewards, log_probs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size.\"\"\"\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import logging\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/cdvae')\n",
    "import cdvae\n",
    "# from cdvae.pl_modules.model import CDVAE\n",
    "# from cdvae.common.data_utils import get_train_val_test_test_loaders\n",
    "# from cdvae.common.data_utils import get_train_val_test_loaders\n",
    "# from cdvae.pl_data.dataset import CDVAEDataset\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CDVAE_TI_Generator:\n",
    "    \"\"\"\n",
    "    Crystal Diffusion Variational Autoencoder (CDVAE) with Reinforcement Learning\n",
    "    for targeted generation of Topological Insulator materials.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.float32 #set default tensor type to float32\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize CDVAE model components\n",
    "        self.initialize_models()\n",
    "        \n",
    "        # Set up optimizers\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Initialize results tracking\n",
    "        self.results = {\n",
    "            'rewards': [],\n",
    "            'z_gap': [],\n",
    "            'topological_indices': [],\n",
    "            'formation_energies': [],\n",
    "            'best_structures': [],\n",
    "            'best_rewards': [],\n",
    "        }\n",
    "        \n",
    "        # Initialize replay buffer for experience replay\n",
    "        self.replay_buffer = ReplayBuffer(config['buffer_size'])\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize CDVAE encoder, decoder and policy networks.\"\"\"\n",
    "        # Import specific model classes\n",
    "        try:\n",
    "            from cdvae.pl_modules.decoder import GemNetTDecoder\n",
    "            from cdvae.common.data_utils import StandardScalerTorch\n",
    "            from cdvae.common.data_utils import ATOM_TYPES\n",
    "     \n",
    "        except ImportError:\n",
    "            logger.error(\"Failed to import CDVAE modules. Please ensure CDVAE is installed correctly.\")\n",
    "            raise\n",
    "            \n",
    "        # Get dimensions and parameters from config\n",
    "        self.latent_dim = self.config['latent_dim']\n",
    "        self.n_elements = len(self.config['elements']) if 'elements' in self.config else len(ATOM_TYPES.get())\n",
    "        \n",
    "        #TODO: possibly write an encoder file addition to cdvae\n",
    "        # Initialize encoder (if using pre-trained weights)\n",
    "        # if self.config.get('use_encoder', False):\n",
    "        #     self.encoder = GraphEncoder(\n",
    "        #         hidden_dim=self.config['hidden_dim'],\n",
    "        #         latent_dim=self.latent_dim,\n",
    "        #         use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        #     ).to(self.device)\n",
    "            \n",
    "        #     if self.config.get('encoder_checkpoint'):\n",
    "        #         self._load_model(self.encoder, self.config['encoder_checkpoint'])\n",
    "        # else:\n",
    "        #     self.encoder = None\n",
    "\n",
    "        self.encoder = None\n",
    "            \n",
    "        # Initialize decoder\n",
    "        self.decoder = GemNetTDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.config['hidden_dim'],\n",
    "            #cutoff=self.config.get('cutoff', 6.0),\n",
    "            max_neighbors=self.config.get('max_neighbors', 20),\n",
    "            #use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('decoder_checkpoint'):\n",
    "            self._load_model(self.decoder, self.config['decoder_checkpoint'])\n",
    "\n",
    "        import inspect\n",
    "        print(\"Decoder signature:\", inspect.signature(self.decoder.forward))\n",
    "            \n",
    "        # Initialize policy network for RL\n",
    "        self.policy_net = PolicyNetwork(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('policy_hidden_dims', [256, 256]),\n",
    "            activation=self.config.get('policy_activation', 'relu')\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize critic network for actor-critic methods\n",
    "        if self.config.get('use_critic', True):\n",
    "            self.critic = CriticNetwork(\n",
    "                latent_dim=self.latent_dim,\n",
    "                hidden_dims=self.config.get('critic_hidden_dims', [256, 128]),\n",
    "                activation=self.config.get('critic_activation', 'relu')\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.critic = None\n",
    "            \n",
    "        # DFT surrogate models - predict quantum properties directly from latent space\n",
    "        self.energy_predictor = EnergyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('energy_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.topological_predictor = TopologicalPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('topo_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('surrogate_checkpoint'):\n",
    "            self._load_surrogate_models(self.config['surrogate_checkpoint'])\n",
    "        \n",
    "    def setup_optimizers(self):\n",
    "        \"\"\"Set up optimizers for different components.\"\"\"\n",
    "        # Policy optimizer\n",
    "        self.policy_optimizer = torch.optim.Adam(\n",
    "            self.policy_net.parameters(),\n",
    "            lr=self.config.get('policy_lr', 1e-4),\n",
    "            weight_decay=self.config.get('policy_weight_decay', 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Critic optimizer (if using actor-critic)\n",
    "        if self.critic is not None:\n",
    "            self.critic_optimizer = torch.optim.Adam(\n",
    "                self.critic.parameters(),\n",
    "                lr=self.config.get('critic_lr', 3e-4),\n",
    "                weight_decay=self.config.get('critic_weight_decay', 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Surrogate model optimizers for fine-tuning\n",
    "        if self.config.get('train_surrogates', False):\n",
    "            self.energy_optimizer = torch.optim.Adam(\n",
    "                self.energy_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "            self.topo_optimizer = torch.optim.Adam(\n",
    "                self.topological_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "    def _load_model(self, model, checkpoint_path):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'state_dict' in checkpoint:\n",
    "                # Handle pytorch-lightning checkpoints\n",
    "                state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items() \n",
    "                              if k.startswith('model.')}\n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "            else:\n",
    "                # Handle regular torch checkpoints\n",
    "                model.load_state_dict(checkpoint, strict=False)\n",
    "            logger.info(f\"Loaded weights from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load weights: {e}\")\n",
    "            \n",
    "    def _load_surrogate_models(self, checkpoint_path):\n",
    "        \"\"\"Load surrogate model weights.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.energy_predictor.load_state_dict(checkpoint['energy_predictor'])\n",
    "            self.topological_predictor.load_state_dict(checkpoint['topo_predictor'])\n",
    "            logger.info(f\"Loaded surrogate models from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load surrogate models: {e}\")\n",
    "    \n",
    "    def generate_structures(self, batch_size=None):\n",
    "        \"\"\"Generate crystal structures using the policy network and decoder.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.get('batch_size', 32)\n",
    "                \n",
    "        # Sample latent vectors from the policy network\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim, device=self.device, dtype=self.dtype)\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\n",
    "        \n",
    "        # For testing, let's use a smaller batch size and fewer atoms per crystal\n",
    "        max_atoms = 8  # Small number of atoms per crystal for testing\n",
    "        \n",
    "        # Create a batch where each structure has a different number of atoms\n",
    "        num_atoms = torch.randint(2, max_atoms+1, (batch_size,), device=self.device)\n",
    "    \n",
    "        # Create tensors with proper dimensions\n",
    "        total_atoms = num_atoms.sum().item()\n",
    "        \n",
    "        # Create a batch index (for tracking purposes, not passed to decoder)\n",
    "        batch_idx = torch.repeat_interleave(\n",
    "            torch.arange(batch_size, device=self.device), \n",
    "            num_atoms\n",
    "        )\n",
    "        \n",
    "        # Random fractional coordinates for each atom (values between 0 and 1)\n",
    "        frac_coords = torch.rand(total_atoms, 3, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Random atom types\n",
    "        atom_types = torch.randint(0, self.n_elements + 1, (total_atoms,), device=self.device)\n",
    "        \n",
    "        # Random unit cell parameters\n",
    "        lengths = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 5 + 5  # Between 5-10 Å\n",
    "        angles = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 30 + 90  # Between 90-120°\n",
    "\n",
    "        print(\"z_sampled.shape:\", z_sampled.shape)\n",
    "        print(\"frac_coords.shape:\", frac_coords.shape)\n",
    "        print(\"atom_types.shape:\", atom_types.shape,\n",
    "            \"   max atom_types:\", atom_types.max().item(),\n",
    "            \"   n_elements:\", self.n_elements)\n",
    "        print(\"num_atoms.shape:\", num_atoms.shape,\n",
    "            \"   sum num_atoms:\", num_atoms.sum().item())\n",
    "        print(\"lengths.shape:\", lengths.shape)\n",
    "        print(\"angles.shape:\", angles.shape)\n",
    "\n",
    "    \n",
    "        # Generate structures using the decoder\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Remove batch_idx from the arguments - decoder doesn't expect it\n",
    "                pred_cart_coord_diff, pred_atom_types = self.decoder(\n",
    "                    z_sampled,\n",
    "                    frac_coords,\n",
    "                    atom_types,\n",
    "                    num_atoms,\n",
    "                    lengths,\n",
    "                    angles\n",
    "                )\n",
    "                \n",
    "                # Combine the results\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,  # Still store it for reference\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles,\n",
    "                    'pred_cart_coord_diff': pred_cart_coord_diff,\n",
    "                    'pred_atom_types': pred_atom_types\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in decoder: {e}\")\n",
    "                # Add more debug information if needed\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles\n",
    "                }\n",
    "            \n",
    "        return generated_structures, z_sampled, log_probs\n",
    "    \n",
    "    def evaluate_structures(self, structures, z_vectors):\n",
    "        \"\"\"Evaluate generated structures using surrogate models.\"\"\"\n",
    "        # Predict formation energies\n",
    "        with torch.no_grad():\n",
    "            energies = self.energy_predictor(z_vectors)\n",
    "            \n",
    "            # Predict topological indices (Z2 invariants, Chern numbers, etc.)\n",
    "            topo_indices = self.topological_predictor(z_vectors)\n",
    "            \n",
    "            # Calculate band gaps (can be part of the topological predictor or separate)\n",
    "            band_gaps = self.estimate_band_gap(structures, z_vectors)\n",
    "            \n",
    "        # Combine predictions into a comprehensive evaluation\n",
    "        evaluations = {\n",
    "            'formation_energies': energies.cpu().numpy(),\n",
    "            'topological_indices': topo_indices.cpu().numpy(),\n",
    "            'band_gaps': band_gaps.cpu().numpy() if isinstance(band_gaps, torch.Tensor) else band_gaps\n",
    "        }\n",
    "        \n",
    "        return evaluations\n",
    "    \n",
    "    def calculate_rewards(self, evaluations):\n",
    "        \"\"\"Calculate rewards based on desired material properties.\"\"\"\n",
    "        # Extract evaluations\n",
    "        energies = evaluations['formation_energies']\n",
    "        topo_indices = evaluations['topological_indices']\n",
    "        band_gaps = evaluations['band_gaps']\n",
    "\n",
    "        energies  = np.array(energies).squeeze()  \n",
    "        band_gaps = np.array(band_gaps).squeeze()  \n",
    "        \n",
    "        # Convert to numpy for easier manipulation\n",
    "        if isinstance(energies, torch.Tensor):\n",
    "            energies = energies.cpu().numpy().squeeze()\n",
    "        if isinstance(topo_indices, torch.Tensor):\n",
    "            topo_indices = topo_indices.cpu().numpy()\n",
    "        if isinstance(band_gaps, torch.Tensor):\n",
    "            band_gaps = band_gaps.cpu().numpy().squeeze()\n",
    "            \n",
    "        # Calculate stability reward component\n",
    "        # Lower formation energy is better, but must be below threshold to be stable\n",
    "        # stability_threshold = self.config.get('stability_threshold', 0.1)\n",
    "        # stability_rewards = -energies * (energies < stability_threshold)\n",
    "\n",
    "        stability_rewards = -energies * (energies < self.config['stability_threshold'])\n",
    "        \n",
    "        # Calculate topological reward component\n",
    "        # For Z2 invariants, we typically want (1;000) for 3D TIs\n",
    "        # This is a simplified example - actual implementation depends on how topo_indices are represented\n",
    "        topo_rewards = np.sum(topo_indices * self.config.get('topo_weights'), axis=1)\n",
    "        \n",
    "        # Calculate band gap reward component\n",
    "        # Usually want a moderate band gap (not too small, not too large)\n",
    "        # target_gap = self.config.get('target_band_gap', 0.3)  # in eV\n",
    "        # gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\n",
    "        # gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target_gap) / gap_tolerance, 1.0)\n",
    "\n",
    "        target = self.config['target_band_gap']\n",
    "        tol    = self.config['gap_tolerance']\n",
    "        gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target) / tol, 1.0)\n",
    "        \n",
    "        combined_rewards = ( self.config['w_stability']   * stability_rewards\n",
    "                       + self.config['w_topological'] * topo_rewards\n",
    "                       + self.config['w_gap']         * gap_rewards )\n",
    "        \n",
    "        # Combine reward components with configurable weights\n",
    "        # w_stability = self.config.get('w_stability', 1.0)\n",
    "        # w_topological = self.config.get('w_topological', 2.0)\n",
    "        # w_gap = self.config.get('w_gap', 1.5)\n",
    "        \n",
    "        # combined_rewards = (w_stability * stability_rewards + \n",
    "        #                    w_topological * topo_rewards +\n",
    "        #                    w_gap * gap_rewards)\n",
    "        \n",
    "        # Create rewards dictionary\n",
    "        rewards_dict = {\n",
    "            'total': combined_rewards,\n",
    "            'stability': stability_rewards,\n",
    "            'topological': topo_rewards,\n",
    "            'band_gap': gap_rewards\n",
    "        }\n",
    "        \n",
    "        return rewards_dict\n",
    "    \n",
    "    def estimate_band_gap(self, structures, z_vectors):\n",
    "        \"\"\"Estimate band gaps of structures using a surrogate model.\"\"\"\n",
    "        # This would typically be a separate model or part of topological_predictor\n",
    "        # For simplicity, we'll use a mock implementation\n",
    "        batch_size = z_vectors.shape[0]\n",
    "        \n",
    "        # Mock band gap estimation (replace with actual model)\n",
    "        # In practice, this would use a trained neural network or other predictor\n",
    "        gaps = 0.2 + 0.3 * torch.sigmoid(z_vectors[:, 0]) + 0.1 * torch.randn(batch_size).to(self.device)\n",
    "        \n",
    "        return gaps\n",
    "    \n",
    "    def reinforce_update(self, rewards, log_probs):\n",
    "        \"\"\"Update policy network using REINFORCE algorithm.\"\"\"\n",
    "        # Convert to tensor with the right dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Normalize rewards\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "        \n",
    "        # Calculate policy loss\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\n",
    "        \n",
    "        # Update policy\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        # Optional gradient clipping\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            \n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item()\n",
    "    \n",
    "    def actor_critic_update(self, z_vectors, rewards, log_probs):\n",
    "        \"\"\"Update policy and critic networks using Actor-Critic algorithm.\"\"\"\n",
    "        if self.critic is None:\n",
    "            return self.reinforce_update(rewards, log_probs)\n",
    "            \n",
    "        # Convert rewards to tensor with proper dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Get critic's value predictions\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\n",
    "        \n",
    "        # Calculate advantages\n",
    "        advantages = rewards_tensor - value_predictions.detach()\n",
    "        \n",
    "        # Calculate policy (actor) loss\n",
    "        policy_loss = -(log_probs * advantages).mean()\n",
    "        \n",
    "        # Calculate value (critic) loss\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\n",
    "        \n",
    "        # Option 1: Combine losses and do a single backward pass\n",
    "        total_loss = policy_loss + critic_loss\n",
    "        \n",
    "        # Zero all gradients\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        \n",
    "        # Single backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Apply gradient clipping if needed\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.critic.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "        \n",
    "        # Update both networks\n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform a single training step.\"\"\"\n",
    "        # Generate structures\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\n",
    "        print(len(structures))\n",
    "\n",
    "        if not structures: \n",
    "            logger.error(\"no strucutres generated in this step\")\n",
    "            return  {'mean_reward': 0, 'max_reward': 0, 'mean_energy': 0, 'policy_loss': 0}\n",
    "        \n",
    "        # Evaluate structures\n",
    "        evaluations = self.evaluate_structures(structures, z_vectors)\n",
    "        \n",
    "        # Calculate rewards\n",
    "        rewards_dict = self.calculate_rewards(evaluations)\n",
    "        total_rewards = rewards_dict['total']\n",
    "        \n",
    "        # Store experience in replay buffer\n",
    "        for i in range(len(total_rewards)):\n",
    "            self.replay_buffer.add(\n",
    "                z_vectors[i].detach().cpu().numpy(),\n",
    "                total_rewards[i],\n",
    "                log_probs[i].detach().cpu().numpy()\n",
    "            )\n",
    "        \n",
    "        # Update policy using actor-critic or REINFORCE\n",
    "        if self.critic is not None:\n",
    "            loss_info = self.actor_critic_update(z_vectors, total_rewards, log_probs)\n",
    "            policy_loss = loss_info[0]\n",
    "        else:\n",
    "            policy_loss = self.reinforce_update(total_rewards, log_probs)\n",
    "            \n",
    "        # Track best structures\n",
    "        best_idx = np.argmax(total_rewards)\n",
    "\n",
    "        if best_idx >= len(total_rewards):\n",
    "            logger.warning(f\"best_idx {best_idx} out of bounds for total_rewards with length {len(total_rewards)}\")\n",
    "            best_idx = len(total_rewards) # Fallback to first item\n",
    "\n",
    "        print(f\"Type of total_rewards: {type(total_rewards)}\")\n",
    "        print(f\"Shape of total_rewards: {total_rewards.shape if hasattr(total_rewards, 'shape') else 'no shape attribute'}\")\n",
    "        print(f\"Type of total_rewards[best_idx]: {type(total_rewards[best_idx])}\")\n",
    "            \n",
    "        # Fix: Access the scalar value directly without trying to index further\n",
    "        #best_reward = float(total_rewards[best_idx])  # Remove the [0] indexing\n",
    "        reward_value = total_rewards[best_idx]\n",
    "        if isinstance(reward_value, np.ndarray):\n",
    "            if reward_value.size == 1:\n",
    "                best_reward = float(reward_value.item())\n",
    "            else:\n",
    "                # If it's an array with multiple values, take the first one\n",
    "                best_reward = float(reward_value[0])\n",
    "        else:\n",
    "            # If it's already a scalar type (int, float)\n",
    "            best_reward = float(reward_value)\n",
    "\n",
    "        # Determine if this iteration’s best is a new overall best\n",
    "        if len(self.results['best_rewards']) == 0:\n",
    "            is_new_best = True\n",
    "        else:\n",
    "            prev_best = max(self.results['best_rewards'])\n",
    "            # force a Python bool\n",
    "            is_new_best = bool(best_reward > prev_best)\n",
    "\n",
    "        if is_new_best:\n",
    "            best_struct = {\n",
    "                'frac_coords': structures['frac_coords'][best_idx],\n",
    "                'atom_types':  structures['atom_types'][best_idx],\n",
    "                'num_atoms':   structures['num_atoms'][best_idx],\n",
    "                'lengths':     structures['lengths'][best_idx],\n",
    "                'angles':      structures['angles'][best_idx],\n",
    "            }\n",
    "            # optional fields\n",
    "            pccd = structures.get('pred_cart_coord_diff', None)\n",
    "            if pccd is not None:\n",
    "                best_struct['pred_cart_coord_diff'] = pccd[best_idx]\n",
    "            pact = structures.get('pred_atom_types', None)\n",
    "            if pact is not None:\n",
    "                best_struct['pred_atom_types'] = pact[best_idx]\n",
    "\n",
    "            self.results['best_structures'].append(best_struct)\n",
    "\n",
    "        # Store results\n",
    "        self.results['rewards'].append(np.mean(total_rewards))\n",
    "        self.results['formation_energies'].append(np.mean(evaluations['formation_energies']))\n",
    "        self.results['topological_indices'].append(np.mean(evaluations['topological_indices']))\n",
    "        self.results['best_rewards'].append(best_reward)\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(total_rewards),\n",
    "            'max_reward': np.max(total_rewards),\n",
    "            'mean_energy': np.mean(evaluations['formation_energies']),\n",
    "            'policy_loss': policy_loss\n",
    "        }\n",
    "    \n",
    "    def train(self, num_iterations=None):\n",
    "        \"\"\"Train the model for the specified number of iterations.\"\"\"\n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.config.get('num_iterations', 500)\n",
    "            \n",
    "        logger.info(f\"Starting training for {num_iterations} iterations\")\n",
    "        \n",
    "        for iteration in tqdm(range(num_iterations)):\n",
    "            # Perform a training step\n",
    "            step_results = self.train_step()\n",
    "            \n",
    "            # Log progress periodically\n",
    "            if iteration % self.config.get('log_frequency', 10) == 0:\n",
    "                logger.info(\n",
    "                    f\"Iteration {iteration} | \"\n",
    "                    f\"Mean Reward: {step_results['mean_reward']:.4f} | \"\n",
    "                    f\"Max Reward: {step_results['max_reward']:.4f} | \"\n",
    "                    f\"Mean Energy: {step_results['mean_energy']:.4f} | \"\n",
    "                    f\"Policy Loss: {step_results['policy_loss']:.4f}\"\n",
    "                )\n",
    "                \n",
    "            # Save checkpoints periodically\n",
    "            if iteration % self.config.get('save_frequency', 100) == 0 and iteration > 0:\n",
    "                self.save_checkpoint(f\"checkpoint_iter_{iteration}.pt\")\n",
    "                \n",
    "        logger.info(\"Training completed\")\n",
    "        self.save_checkpoint(\"final_checkpoint.pt\")\n",
    "        self.save_results(\"training_results.pkl\")\n",
    "        \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint_dir = self.config.get('checkpoint_dir', './checkpoints')\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'policy_state_dict': self.policy_net.state_dict(),\n",
    "            'policy_optimizer': self.policy_optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'iteration': len(self.results['rewards'])\n",
    "        }\n",
    "        \n",
    "        if self.critic is not None:\n",
    "            checkpoint['critic_state_dict'] = self.critic.state_dict()\n",
    "            checkpoint['critic_optimizer'] = self.critic_optimizer.state_dict()\n",
    "            \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        \n",
    "    def save_results(self, filename):\n",
    "        \"\"\"Save training results.\"\"\"\n",
    "        results_dir = self.config.get('results_dir', './results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        results_path = os.path.join(results_dir, filename)\n",
    "        \n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(self.results, f)\n",
    "            \n",
    "        logger.info(f\"Saved results to {results_path}\")\n",
    "        \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])\n",
    "        self.policy_optimizer.load_state_dict(checkpoint['policy_optimizer'])\n",
    "        \n",
    "        if self.critic is not None and 'critic_state_dict' in checkpoint:\n",
    "            self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "            self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "            \n",
    "        logger.info(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "        return checkpoint.get('iteration', 0)\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for RL-based latent space exploration.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 256], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer for mean\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "        # Learnable log std for exploration\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # def _initialize_weights(self):\n",
    "    #     \"\"\"Initialize network weights.\"\"\"\n",
    "    #     for m in self.modules():\n",
    "    #         if isinstance(m, nn.Linear):\n",
    "    #             nn.init.xavier_normal_(m.weight)\n",
    "    #             if m.bias is not None:\n",
    "    #                 nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "                \n",
    "                # Ensure dtype is correct\n",
    "                m.weight.data = m.weight.data.to(dtype=torch.float32)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = m.bias.data.to(dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, z_noise):\n",
    "        \"\"\"\n",
    "        Forward pass through the policy network.\n",
    "        \n",
    "        Args:\n",
    "            z_noise: Random noise tensor of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            z_sampled: Sampled latent vectors\n",
    "            log_probs: Log probabilities of the sampled vectors\n",
    "        \"\"\"\n",
    "        x = self.fc_layers(z_noise)\n",
    "        mu = self.fc_mu(x)\n",
    "        \n",
    "        # Get standard deviation from learnable parameter\n",
    "        std = torch.exp(self.log_std.clamp(-20, 2))  # Clamp for stability\n",
    "        \n",
    "        # Create normal distribution\n",
    "        dist = Normal(mu, std)\n",
    "        \n",
    "        # Sample using reparameterization trick\n",
    "        z_sampled = dist.rsample()\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        log_probs = dist.log_prob(z_sampled).sum(dim=-1)\n",
    "        \n",
    "        return z_sampled, log_probs\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"Critic network for actor-critic method.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 128], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value output\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the critic network.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent vector of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            value: Predicted value of the state\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class EnergyPredictor(nn.Module):\n",
    "    \"\"\"Surrogate model to predict formation energy from latent space.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value for formation energy\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict formation energy from latent vector.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class TopologicalPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Surrogate model to predict topological invariants (Z2, Chern number) \n",
    "    from latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64], num_invariants=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - multiple values for topological invariants\n",
    "        # For 3D topological insulators, typically 4 Z2 invariants (ν₀;ν₁ν₂ν₃)\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.invariant_head = nn.Linear(input_dim, num_invariants)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict topological invariants from latent vector.\"\"\"\n",
    "        features = self.feature_extractor(z)\n",
    "        # Apply sigmoid to constrain outputs between 0 and 1\n",
    "        # In practice, these would be discretized to 0 or 1 when interpreting\n",
    "        invariants = torch.sigmoid(self.invariant_head(features))\n",
    "        return invariants\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer for more stable training.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size=10000):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def add(self, z, reward, log_prob):\n",
    "        \"\"\"Add experience to buffer.\"\"\"\n",
    "        if len(self.buffer) < self.max_size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (z, reward, log_prob)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        z, rewards, log_probs = map(np.array, zip(*batch))\n",
    "        return z, rewards, log_probs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size.\"\"\"\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import logging\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/cdvae')\n",
    "import cdvae\n",
    "# from cdvae.pl_modules.model import CDVAE\n",
    "# from cdvae.common.data_utils import get_train_val_test_test_loaders\n",
    "# from cdvae.common.data_utils import get_train_val_test_loaders\n",
    "# from cdvae.pl_data.dataset import CDVAEDataset\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CDVAE_TI_Generator:\n",
    "    \"\"\"\n",
    "    Crystal Diffusion Variational Autoencoder (CDVAE) with Reinforcement Learning\n",
    "    for targeted generation of Topological Insulator materials.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.float32 #set default tensor type to float32\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize CDVAE model components\n",
    "        self.initialize_models()\n",
    "        \n",
    "        # Set up optimizers\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Initialize results tracking\n",
    "        self.results = {\n",
    "            'rewards': [],\n",
    "            'z_gap': [],\n",
    "            'topological_indices': [],\n",
    "            'formation_energies': [],\n",
    "            'best_structures': [],\n",
    "            'best_rewards': [],\n",
    "        }\n",
    "        \n",
    "        # Initialize replay buffer for experience replay\n",
    "        self.replay_buffer = ReplayBuffer(config['buffer_size'])\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize CDVAE encoder, decoder and policy networks.\"\"\"\n",
    "        # Import specific model classes\n",
    "        try:\n",
    "            from cdvae.pl_modules.decoder import GemNetTDecoder\n",
    "            from cdvae.common.data_utils import StandardScalerTorch\n",
    "            from cdvae.common.data_utils import ATOM_TYPES\n",
    "     \n",
    "        except ImportError:\n",
    "            logger.error(\"Failed to import CDVAE modules. Please ensure CDVAE is installed correctly.\")\n",
    "            raise\n",
    "            \n",
    "        # Get dimensions and parameters from config\n",
    "        self.latent_dim = self.config['latent_dim']\n",
    "        self.n_elements = len(self.config['elements']) if 'elements' in self.config else len(ATOM_TYPES.get())\n",
    "        \n",
    "        #TODO: possibly write an encoder file addition to cdvae\n",
    "        # Initialize encoder (if using pre-trained weights)\n",
    "        # if self.config.get('use_encoder', False):\n",
    "        #     self.encoder = GraphEncoder(\n",
    "        #         hidden_dim=self.config['hidden_dim'],\n",
    "        #         latent_dim=self.latent_dim,\n",
    "        #         use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        #     ).to(self.device)\n",
    "            \n",
    "        #     if self.config.get('encoder_checkpoint'):\n",
    "        #         self._load_model(self.encoder, self.config['encoder_checkpoint'])\n",
    "        # else:\n",
    "        #     self.encoder = None\n",
    "\n",
    "        self.encoder = None\n",
    "            \n",
    "        # Initialize decoder\n",
    "        self.decoder = GemNetTDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.config['hidden_dim'],\n",
    "            #cutoff=self.config.get('cutoff', 6.0),\n",
    "            max_neighbors=self.config.get('max_neighbors', 20),\n",
    "            #use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('decoder_checkpoint'):\n",
    "            self._load_model(self.decoder, self.config['decoder_checkpoint'])\n",
    "\n",
    "        import inspect\n",
    "        print(\"Decoder signature:\", inspect.signature(self.decoder.forward))\n",
    "            \n",
    "        # Initialize policy network for RL\n",
    "        self.policy_net = PolicyNetwork(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('policy_hidden_dims', [256, 256]),\n",
    "            activation=self.config.get('policy_activation', 'relu')\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize critic network for actor-critic methods\n",
    "        if self.config.get('use_critic', True):\n",
    "            self.critic = CriticNetwork(\n",
    "                latent_dim=self.latent_dim,\n",
    "                hidden_dims=self.config.get('critic_hidden_dims', [256, 128]),\n",
    "                activation=self.config.get('critic_activation', 'relu')\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.critic = None\n",
    "            \n",
    "        # DFT surrogate models - predict quantum properties directly from latent space\n",
    "        self.energy_predictor = EnergyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('energy_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.topological_predictor = TopologicalPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('topo_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('surrogate_checkpoint'):\n",
    "            self._load_surrogate_models(self.config['surrogate_checkpoint'])\n",
    "        \n",
    "    def setup_optimizers(self):\n",
    "        \"\"\"Set up optimizers for different components.\"\"\"\n",
    "        # Policy optimizer\n",
    "        self.policy_optimizer = torch.optim.Adam(\n",
    "            self.policy_net.parameters(),\n",
    "            lr=self.config.get('policy_lr', 1e-4),\n",
    "            weight_decay=self.config.get('policy_weight_decay', 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Critic optimizer (if using actor-critic)\n",
    "        if self.critic is not None:\n",
    "            self.critic_optimizer = torch.optim.Adam(\n",
    "                self.critic.parameters(),\n",
    "                lr=self.config.get('critic_lr', 3e-4),\n",
    "                weight_decay=self.config.get('critic_weight_decay', 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Surrogate model optimizers for fine-tuning\n",
    "        if self.config.get('train_surrogates', False):\n",
    "            self.energy_optimizer = torch.optim.Adam(\n",
    "                self.energy_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "            self.topo_optimizer = torch.optim.Adam(\n",
    "                self.topological_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "    def _load_model(self, model, checkpoint_path):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'state_dict' in checkpoint:\n",
    "                # Handle pytorch-lightning checkpoints\n",
    "                state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items() \n",
    "                              if k.startswith('model.')}\n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "            else:\n",
    "                # Handle regular torch checkpoints\n",
    "                model.load_state_dict(checkpoint, strict=False)\n",
    "            logger.info(f\"Loaded weights from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load weights: {e}\")\n",
    "            \n",
    "    def _load_surrogate_models(self, checkpoint_path):\n",
    "        \"\"\"Load surrogate model weights.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.energy_predictor.load_state_dict(checkpoint['energy_predictor'])\n",
    "            self.topological_predictor.load_state_dict(checkpoint['topo_predictor'])\n",
    "            logger.info(f\"Loaded surrogate models from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load surrogate models: {e}\")\n",
    "    \n",
    "    def generate_structures(self, batch_size=None):\n",
    "        \"\"\"Generate crystal structures using the policy network and decoder.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.get('batch_size', 32)\n",
    "                \n",
    "        # Sample latent vectors from the policy network\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim, device=self.device, dtype=self.dtype)\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\n",
    "        \n",
    "        # For testing, let's use a smaller batch size and fewer atoms per crystal\n",
    "        max_atoms = 8  # Small number of atoms per crystal for testing\n",
    "        \n",
    "        # Create a batch where each structure has a different number of atoms\n",
    "        num_atoms = torch.randint(2, max_atoms+1, (batch_size,), device=self.device)\n",
    "    \n",
    "        # Create tensors with proper dimensions\n",
    "        total_atoms = num_atoms.sum().item()\n",
    "        \n",
    "        # Create a batch index (for tracking purposes, not passed to decoder)\n",
    "        batch_idx = torch.repeat_interleave(\n",
    "            torch.arange(batch_size, device=self.device), \n",
    "            num_atoms\n",
    "        )\n",
    "        \n",
    "        # Random fractional coordinates for each atom (values between 0 and 1)\n",
    "        frac_coords = torch.rand(total_atoms, 3, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Random atom types\n",
    "        atom_types = torch.randint(0, self.n_elements + 1, (total_atoms,), device=self.device)\n",
    "        \n",
    "        # Random unit cell parameters\n",
    "        lengths = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 5 + 5  # Between 5-10 Å\n",
    "        angles = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 30 + 90  # Between 90-120°\n",
    "\n",
    "        print(\"z_sampled.shape:\", z_sampled.shape)\n",
    "        print(\"frac_coords.shape:\", frac_coords.shape)\n",
    "        print(\"atom_types.shape:\", atom_types.shape,\n",
    "            \"   max atom_types:\", atom_types.max().item(),\n",
    "            \"   n_elements:\", self.n_elements)\n",
    "        print(\"num_atoms.shape:\", num_atoms.shape,\n",
    "            \"   sum num_atoms:\", num_atoms.sum().item())\n",
    "        print(\"lengths.shape:\", lengths.shape)\n",
    "        print(\"angles.shape:\", angles.shape)\n",
    "\n",
    "    \n",
    "        # Generate structures using the decoder\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Remove batch_idx from the arguments - decoder doesn't expect it\n",
    "                pred_cart_coord_diff, pred_atom_types = self.decoder(\n",
    "                    z_sampled,\n",
    "                    frac_coords,\n",
    "                    atom_types,\n",
    "                    num_atoms,\n",
    "                    lengths,\n",
    "                    angles\n",
    "                )\n",
    "                \n",
    "                # Combine the results\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,  # Still store it for reference\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles,\n",
    "                    'pred_cart_coord_diff': pred_cart_coord_diff,\n",
    "                    'pred_atom_types': pred_atom_types\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in decoder: {e}\")\n",
    "                # Add more debug information if needed\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles\n",
    "                }\n",
    "            \n",
    "        return generated_structures, z_sampled, log_probs\n",
    "    \n",
    "    def evaluate_structures(self, structures, z_vectors):\n",
    "        \"\"\"Evaluate generated structures using surrogate models.\"\"\"\n",
    "        # Predict formation energies\n",
    "        with torch.no_grad():\n",
    "            energies = self.energy_predictor(z_vectors)\n",
    "            \n",
    "            # Predict topological indices (Z2 invariants, Chern numbers, etc.)\n",
    "            topo_indices = self.topological_predictor(z_vectors)\n",
    "            \n",
    "            # Calculate band gaps (can be part of the topological predictor or separate)\n",
    "            band_gaps = self.estimate_band_gap(structures, z_vectors)\n",
    "            \n",
    "        # Combine predictions into a comprehensive evaluation\n",
    "        evaluations = {\n",
    "            'formation_energies': energies.cpu().numpy(),\n",
    "            'topological_indices': topo_indices.cpu().numpy(),\n",
    "            'band_gaps': band_gaps.cpu().numpy() if isinstance(band_gaps, torch.Tensor) else band_gaps\n",
    "        }\n",
    "        \n",
    "        return evaluations\n",
    "    \n",
    "    def calculate_rewards(self, evaluations):\n",
    "        \"\"\"Calculate rewards based on desired material properties.\"\"\"\n",
    "        # Extract evaluations\n",
    "        energies = evaluations['formation_energies']\n",
    "        topo_indices = evaluations['topological_indices']\n",
    "        band_gaps = evaluations['band_gaps']\n",
    "\n",
    "        energies  = np.array(energies).squeeze()  \n",
    "        band_gaps = np.array(band_gaps).squeeze()  \n",
    "        \n",
    "        # Convert to numpy for easier manipulation\n",
    "        if isinstance(energies, torch.Tensor):\n",
    "            energies = energies.cpu().numpy().squeeze()\n",
    "        if isinstance(topo_indices, torch.Tensor):\n",
    "            topo_indices = topo_indices.cpu().numpy()\n",
    "        if isinstance(band_gaps, torch.Tensor):\n",
    "            band_gaps = band_gaps.cpu().numpy().squeeze()\n",
    "            \n",
    "        # Calculate stability reward component\n",
    "        # Lower formation energy is better, but must be below threshold to be stable\n",
    "        # stability_threshold = self.config.get('stability_threshold', 0.1)\n",
    "        # stability_rewards = -energies * (energies < stability_threshold)\n",
    "\n",
    "        stability_rewards = -energies * (energies < self.config['stability_threshold'])\n",
    "        \n",
    "        # Calculate topological reward component\n",
    "        # For Z2 invariants, we typically want (1;000) for 3D TIs\n",
    "        # This is a simplified example - actual implementation depends on how topo_indices are represented\n",
    "        topo_rewards = np.sum(topo_indices * self.config.get('topo_weights'), axis=1)\n",
    "        \n",
    "        # Calculate band gap reward component\n",
    "        # Usually want a moderate band gap (not too small, not too large)\n",
    "        # target_gap = self.config.get('target_band_gap', 0.3)  # in eV\n",
    "        # gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\n",
    "        # gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target_gap) / gap_tolerance, 1.0)\n",
    "\n",
    "        target = self.config['target_band_gap']\n",
    "        tol    = self.config['gap_tolerance']\n",
    "        gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target) / tol, 1.0)\n",
    "        \n",
    "        combined_rewards = ( self.config['w_stability']   * stability_rewards\n",
    "                       + self.config['w_topological'] * topo_rewards\n",
    "                       + self.config['w_gap']         * gap_rewards )\n",
    "        \n",
    "        # Combine reward components with configurable weights\n",
    "        # w_stability = self.config.get('w_stability', 1.0)\n",
    "        # w_topological = self.config.get('w_topological', 2.0)\n",
    "        # w_gap = self.config.get('w_gap', 1.5)\n",
    "        \n",
    "        # combined_rewards = (w_stability * stability_rewards + \n",
    "        #                    w_topological * topo_rewards +\n",
    "        #                    w_gap * gap_rewards)\n",
    "        \n",
    "        # Create rewards dictionary\n",
    "        rewards_dict = {\n",
    "            'total': combined_rewards,\n",
    "            'stability': stability_rewards,\n",
    "            'topological': topo_rewards,\n",
    "            'band_gap': gap_rewards\n",
    "        }\n",
    "        \n",
    "        return rewards_dict\n",
    "    \n",
    "    def estimate_band_gap(self, structures, z_vectors):\n",
    "        \"\"\"Estimate band gaps of structures using a surrogate model.\"\"\"\n",
    "        # This would typically be a separate model or part of topological_predictor\n",
    "        # For simplicity, we'll use a mock implementation\n",
    "        batch_size = z_vectors.shape[0]\n",
    "        \n",
    "        # Mock band gap estimation (replace with actual model)\n",
    "        # In practice, this would use a trained neural network or other predictor\n",
    "        gaps = 0.2 + 0.3 * torch.sigmoid(z_vectors[:, 0]) + 0.1 * torch.randn(batch_size).to(self.device)\n",
    "        \n",
    "        return gaps\n",
    "    \n",
    "    def reinforce_update(self, rewards, log_probs):\n",
    "        \"\"\"Update policy network using REINFORCE algorithm.\"\"\"\n",
    "        # Convert to tensor with the right dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Normalize rewards\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "        \n",
    "        # Calculate policy loss\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\n",
    "        \n",
    "        # Update policy\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        # Optional gradient clipping\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            \n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item()\n",
    "    \n",
    "    def actor_critic_update(self, z_vectors, rewards, log_probs):\n",
    "        \"\"\"Update policy and critic networks using Actor-Critic algorithm.\"\"\"\n",
    "        if self.critic is None:\n",
    "            return self.reinforce_update(rewards, log_probs)\n",
    "            \n",
    "        # Convert rewards to tensor with proper dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Get critic's value predictions\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\n",
    "        \n",
    "        # Calculate advantages\n",
    "        advantages = rewards_tensor - value_predictions.detach()\n",
    "        \n",
    "        # Calculate policy (actor) loss\n",
    "        policy_loss = -(log_probs * advantages).mean()\n",
    "        \n",
    "        # Calculate value (critic) loss\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\n",
    "        \n",
    "        # Option 1: Combine losses and do a single backward pass\n",
    "        total_loss = policy_loss + critic_loss\n",
    "        \n",
    "        # Zero all gradients\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        \n",
    "        # Single backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Apply gradient clipping if needed\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.critic.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "        \n",
    "        # Update both networks\n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform a single training step.\"\"\"\n",
    "        # Generate structures\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\n",
    "        print(len(structures))\n",
    "\n",
    "        if not structures: \n",
    "            logger.error(\"no strucutres generated in this step\")\n",
    "            return  {'mean_reward': 0, 'max_reward': 0, 'mean_energy': 0, 'policy_loss': 0}\n",
    "        \n",
    "        # Evaluate structures\n",
    "        evaluations = self.evaluate_structures(structures, z_vectors)\n",
    "        \n",
    "        # Calculate rewards\n",
    "        rewards_dict = self.calculate_rewards(evaluations)\n",
    "        total_rewards = rewards_dict['total']\n",
    "        \n",
    "        # Store experience in replay buffer\n",
    "        for i in range(len(total_rewards)):\n",
    "            self.replay_buffer.add(\n",
    "                z_vectors[i].detach().cpu().numpy(),\n",
    "                total_rewards[i],\n",
    "                log_probs[i].detach().cpu().numpy()\n",
    "            )\n",
    "        \n",
    "        # Update policy using actor-critic or REINFORCE\n",
    "        if self.critic is not None:\n",
    "            loss_info = self.actor_critic_update(z_vectors, total_rewards, log_probs)\n",
    "            policy_loss = loss_info[0]\n",
    "        else:\n",
    "            policy_loss = self.reinforce_update(total_rewards, log_probs)\n",
    "            \n",
    "        # Track best structures\n",
    "        best_idx = np.argmax(total_rewards)\n",
    "\n",
    "        if best_idx >= len(total_rewards):\n",
    "            logger.warning(f\"best_idx {best_idx} out of bounds for total_rewards with length {len(total_rewards)}\")\n",
    "            best_idx = len(total_rewards) # Fallback to first item\n",
    "\n",
    "        print(f\"Type of total_rewards: {type(total_rewards)}\")\n",
    "        print(f\"Shape of total_rewards: {total_rewards.shape if hasattr(total_rewards, 'shape') else 'no shape attribute'}\")\n",
    "        print(f\"Type of total_rewards[best_idx]: {type(total_rewards[best_idx])}\")\n",
    "            \n",
    "        # Fix: Access the scalar value directly without trying to index further\n",
    "        #best_reward = float(total_rewards[best_idx])  # Remove the [0] indexing\n",
    "        reward_value = total_rewards[best_idx]\n",
    "        if isinstance(reward_value, np.ndarray):\n",
    "            if reward_value.size == 1:\n",
    "                best_reward = float(reward_value.item())\n",
    "            else:\n",
    "                # If it's an array with multiple values, take the first one\n",
    "                best_reward = float(reward_value[0])\n",
    "        else:\n",
    "            # If it's already a scalar type (int, float)\n",
    "            best_reward = float(reward_value)\n",
    "\n",
    "        # Determine if this iteration’s best is a new overall best\n",
    "        if len(self.results['best_rewards']) == 0:\n",
    "            is_new_best = True\n",
    "        else:\n",
    "            prev_best = max(self.results['best_rewards'])\n",
    "            # force a Python bool\n",
    "            is_new_best = bool(best_reward > prev_best)\n",
    "\n",
    "        if is_new_best:\n",
    "            best_struct = {\n",
    "                'frac_coords': structures['frac_coords'][best_idx],\n",
    "                'atom_types':  structures['atom_types'][best_idx],\n",
    "                'num_atoms':   structures['num_atoms'][best_idx],\n",
    "                'lengths':     structures['lengths'][best_idx],\n",
    "                'angles':      structures['angles'][best_idx],\n",
    "            }\n",
    "            # optional fields\n",
    "            pccd = structures.get('pred_cart_coord_diff', None)\n",
    "            if pccd is not None:\n",
    "                best_struct['pred_cart_coord_diff'] = pccd[best_idx]\n",
    "            pact = structures.get('pred_atom_types', None)\n",
    "            if pact is not None:\n",
    "                best_struct['pred_atom_types'] = pact[best_idx]\n",
    "\n",
    "            self.results['best_structures'].append(best_struct)\n",
    "\n",
    "        # Store results\n",
    "        self.results['rewards'].append(np.mean(total_rewards))\n",
    "        self.results['formation_energies'].append(np.mean(evaluations['formation_energies']))\n",
    "        self.results['topological_indices'].append(np.mean(evaluations['topological_indices']))\n",
    "        self.results['best_rewards'].append(best_reward)\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(total_rewards),\n",
    "            'max_reward': np.max(total_rewards),\n",
    "            'mean_energy': np.mean(evaluations['formation_energies']),\n",
    "            'policy_loss': policy_loss\n",
    "        }\n",
    "    \n",
    "    def train(self, num_iterations=None):\n",
    "        \"\"\"Train the model for the specified number of iterations.\"\"\"\n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.config.get('num_iterations', 500)\n",
    "            \n",
    "        logger.info(f\"Starting training for {num_iterations} iterations\")\n",
    "        \n",
    "        for iteration in tqdm(range(num_iterations)):\n",
    "            # Perform a training step\n",
    "            step_results = self.train_step()\n",
    "            \n",
    "            # Log progress periodically\n",
    "            if iteration % self.config.get('log_frequency', 10) == 0:\n",
    "                logger.info(\n",
    "                    f\"Iteration {iteration} | \"\n",
    "                    f\"Mean Reward: {step_results['mean_reward']:.4f} | \"\n",
    "                    f\"Max Reward: {step_results['max_reward']:.4f} | \"\n",
    "                    f\"Mean Energy: {step_results['mean_energy']:.4f} | \"\n",
    "                    f\"Policy Loss: {step_results['policy_loss']:.4f}\"\n",
    "                )\n",
    "                \n",
    "            # Save checkpoints periodically\n",
    "            if iteration % self.config.get('save_frequency', 100) == 0 and iteration > 0:\n",
    "                self.save_checkpoint(f\"checkpoint_iter_{iteration}.pt\")\n",
    "                \n",
    "        logger.info(\"Training completed\")\n",
    "        self.save_checkpoint(\"final_checkpoint.pt\")\n",
    "        self.save_results(\"training_results.pkl\")\n",
    "        \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint_dir = self.config.get('checkpoint_dir', './checkpoints')\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'policy_state_dict': self.policy_net.state_dict(),\n",
    "            'policy_optimizer': self.policy_optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'iteration': len(self.results['rewards'])\n",
    "        }\n",
    "        \n",
    "        if self.critic is not None:\n",
    "            checkpoint['critic_state_dict'] = self.critic.state_dict()\n",
    "            checkpoint['critic_optimizer'] = self.critic_optimizer.state_dict()\n",
    "            \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        \n",
    "    def save_results(self, filename):\n",
    "        \"\"\"Save training results.\"\"\"\n",
    "        results_dir = self.config.get('results_dir', './results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        results_path = os.path.join(results_dir, filename)\n",
    "        \n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(self.results, f)\n",
    "            \n",
    "        logger.info(f\"Saved results to {results_path}\")\n",
    "        \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])\n",
    "        self.policy_optimizer.load_state_dict(checkpoint['policy_optimizer'])\n",
    "        \n",
    "        if self.critic is not None and 'critic_state_dict' in checkpoint:\n",
    "            self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "            self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "            \n",
    "        logger.info(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "        return checkpoint.get('iteration', 0)\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for RL-based latent space exploration.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 256], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer for mean\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "        # Learnable log std for exploration\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # def _initialize_weights(self):\n",
    "    #     \"\"\"Initialize network weights.\"\"\"\n",
    "    #     for m in self.modules():\n",
    "    #         if isinstance(m, nn.Linear):\n",
    "    #             nn.init.xavier_normal_(m.weight)\n",
    "    #             if m.bias is not None:\n",
    "    #                 nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "                \n",
    "                # Ensure dtype is correct\n",
    "                m.weight.data = m.weight.data.to(dtype=torch.float32)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = m.bias.data.to(dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, z_noise):\n",
    "        \"\"\"\n",
    "        Forward pass through the policy network.\n",
    "        \n",
    "        Args:\n",
    "            z_noise: Random noise tensor of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            z_sampled: Sampled latent vectors\n",
    "            log_probs: Log probabilities of the sampled vectors\n",
    "        \"\"\"\n",
    "        x = self.fc_layers(z_noise)\n",
    "        mu = self.fc_mu(x)\n",
    "        \n",
    "        # Get standard deviation from learnable parameter\n",
    "        std = torch.exp(self.log_std.clamp(-20, 2))  # Clamp for stability\n",
    "        \n",
    "        # Create normal distribution\n",
    "        dist = Normal(mu, std)\n",
    "        \n",
    "        # Sample using reparameterization trick\n",
    "        z_sampled = dist.rsample()\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        log_probs = dist.log_prob(z_sampled).sum(dim=-1)\n",
    "        \n",
    "        return z_sampled, log_probs\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"Critic network for actor-critic method.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 128], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value output\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the critic network.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent vector of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            value: Predicted value of the state\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class EnergyPredictor(nn.Module):\n",
    "    \"\"\"Surrogate model to predict formation energy from latent space.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value for formation energy\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict formation energy from latent vector.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class TopologicalPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Surrogate model to predict topological invariants (Z2, Chern number) \n",
    "    from latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64], num_invariants=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - multiple values for topological invariants\n",
    "        # For 3D topological insulators, typically 4 Z2 invariants (ν₀;ν₁ν₂ν₃)\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.invariant_head = nn.Linear(input_dim, num_invariants)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict topological invariants from latent vector.\"\"\"\n",
    "        features = self.feature_extractor(z)\n",
    "        # Apply sigmoid to constrain outputs between 0 and 1\n",
    "        # In practice, these would be discretized to 0 or 1 when interpreting\n",
    "        invariants = torch.sigmoid(self.invariant_head(features))\n",
    "        return invariants\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer for more stable training.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size=10000):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def add(self, z, reward, log_prob):\n",
    "        \"\"\"Add experience to buffer.\"\"\"\n",
    "        if len(self.buffer) < self.max_size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (z, reward, log_prob)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        z, rewards, log_probs = map(np.array, zip(*batch))\n",
    "        return z, rewards, log_probs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size.\"\"\"\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import logging\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/cdvae')\n",
    "import cdvae\n",
    "# from cdvae.pl_modules.model import CDVAE\n",
    "# from cdvae.common.data_utils import get_train_val_test_test_loaders\n",
    "# from cdvae.common.data_utils import get_train_val_test_loaders\n",
    "# from cdvae.pl_data.dataset import CDVAEDataset\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CDVAE_TI_Generator:\n",
    "    \"\"\"\n",
    "    Crystal Diffusion Variational Autoencoder (CDVAE) with Reinforcement Learning\n",
    "    for targeted generation of Topological Insulator materials.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.float32 #set default tensor type to float32\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize CDVAE model components\n",
    "        self.initialize_models()\n",
    "        \n",
    "        # Set up optimizers\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Initialize results tracking\n",
    "        self.results = {\n",
    "            'rewards': [],\n",
    "            'z_gap': [],\n",
    "            'topological_indices': [],\n",
    "            'formation_energies': [],\n",
    "            'best_structures': [],\n",
    "            'best_rewards': [],\n",
    "        }\n",
    "        \n",
    "        # Initialize replay buffer for experience replay\n",
    "        self.replay_buffer = ReplayBuffer(config['buffer_size'])\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize CDVAE encoder, decoder and policy networks.\"\"\"\n",
    "        # Import specific model classes\n",
    "        try:\n",
    "            from cdvae.pl_modules.decoder import GemNetTDecoder\n",
    "            from cdvae.common.data_utils import StandardScalerTorch\n",
    "            from cdvae.common.data_utils import ATOM_TYPES\n",
    "     \n",
    "        except ImportError:\n",
    "            logger.error(\"Failed to import CDVAE modules. Please ensure CDVAE is installed correctly.\")\n",
    "            raise\n",
    "            \n",
    "        # Get dimensions and parameters from config\n",
    "        self.latent_dim = self.config['latent_dim']\n",
    "        self.n_elements = len(self.config['elements']) if 'elements' in self.config else len(ATOM_TYPES.get())\n",
    "        \n",
    "        #TODO: possibly write an encoder file addition to cdvae\n",
    "        # Initialize encoder (if using pre-trained weights)\n",
    "        # if self.config.get('use_encoder', False):\n",
    "        #     self.encoder = GraphEncoder(\n",
    "        #         hidden_dim=self.config['hidden_dim'],\n",
    "        #         latent_dim=self.latent_dim,\n",
    "        #         use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        #     ).to(self.device)\n",
    "            \n",
    "        #     if self.config.get('encoder_checkpoint'):\n",
    "        #         self._load_model(self.encoder, self.config['encoder_checkpoint'])\n",
    "        # else:\n",
    "        #     self.encoder = None\n",
    "\n",
    "        self.encoder = None\n",
    "            \n",
    "        # Initialize decoder\n",
    "        self.decoder = GemNetTDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.config['hidden_dim'],\n",
    "            #cutoff=self.config.get('cutoff', 6.0),\n",
    "            max_neighbors=self.config.get('max_neighbors', 20),\n",
    "            #use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('decoder_checkpoint'):\n",
    "            self._load_model(self.decoder, self.config['decoder_checkpoint'])\n",
    "\n",
    "        import inspect\n",
    "        print(\"Decoder signature:\", inspect.signature(self.decoder.forward))\n",
    "            \n",
    "        # Initialize policy network for RL\n",
    "        self.policy_net = PolicyNetwork(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('policy_hidden_dims', [256, 256]),\n",
    "            activation=self.config.get('policy_activation', 'relu')\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize critic network for actor-critic methods\n",
    "        if self.config.get('use_critic', True):\n",
    "            self.critic = CriticNetwork(\n",
    "                latent_dim=self.latent_dim,\n",
    "                hidden_dims=self.config.get('critic_hidden_dims', [256, 128]),\n",
    "                activation=self.config.get('critic_activation', 'relu')\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.critic = None\n",
    "            \n",
    "        # DFT surrogate models - predict quantum properties directly from latent space\n",
    "        self.energy_predictor = EnergyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('energy_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.topological_predictor = TopologicalPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('topo_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('surrogate_checkpoint'):\n",
    "            self._load_surrogate_models(self.config['surrogate_checkpoint'])\n",
    "        \n",
    "    def setup_optimizers(self):\n",
    "        \"\"\"Set up optimizers for different components.\"\"\"\n",
    "        # Policy optimizer\n",
    "        self.policy_optimizer = torch.optim.Adam(\n",
    "            self.policy_net.parameters(),\n",
    "            lr=self.config.get('policy_lr', 1e-4),\n",
    "            weight_decay=self.config.get('policy_weight_decay', 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Critic optimizer (if using actor-critic)\n",
    "        if self.critic is not None:\n",
    "            self.critic_optimizer = torch.optim.Adam(\n",
    "                self.critic.parameters(),\n",
    "                lr=self.config.get('critic_lr', 3e-4),\n",
    "                weight_decay=self.config.get('critic_weight_decay', 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Surrogate model optimizers for fine-tuning\n",
    "        if self.config.get('train_surrogates', False):\n",
    "            self.energy_optimizer = torch.optim.Adam(\n",
    "                self.energy_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "            self.topo_optimizer = torch.optim.Adam(\n",
    "                self.topological_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "    def _load_model(self, model, checkpoint_path):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'state_dict' in checkpoint:\n",
    "                # Handle pytorch-lightning checkpoints\n",
    "                state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items() \n",
    "                              if k.startswith('model.')}\n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "            else:\n",
    "                # Handle regular torch checkpoints\n",
    "                model.load_state_dict(checkpoint, strict=False)\n",
    "            logger.info(f\"Loaded weights from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load weights: {e}\")\n",
    "            \n",
    "    def _load_surrogate_models(self, checkpoint_path):\n",
    "        \"\"\"Load surrogate model weights.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.energy_predictor.load_state_dict(checkpoint['energy_predictor'])\n",
    "            self.topological_predictor.load_state_dict(checkpoint['topo_predictor'])\n",
    "            logger.info(f\"Loaded surrogate models from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load surrogate models: {e}\")\n",
    "    \n",
    "    def generate_structures(self, batch_size=None):\n",
    "        \"\"\"Generate crystal structures using the policy network and decoder.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.get('batch_size', 32)\n",
    "                \n",
    "        # Sample latent vectors from the policy network\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim, device=self.device, dtype=self.dtype)\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\n",
    "        \n",
    "        # For testing, let's use a smaller batch size and fewer atoms per crystal\n",
    "        max_atoms = 8  # Small number of atoms per crystal for testing\n",
    "        \n",
    "        # Create a batch where each structure has a different number of atoms\n",
    "        num_atoms = torch.randint(2, max_atoms+1, (batch_size,), device=self.device)\n",
    "    \n",
    "        # Create tensors with proper dimensions\n",
    "        total_atoms = num_atoms.sum().item()\n",
    "        \n",
    "        # Create a batch index (for tracking purposes, not passed to decoder)\n",
    "        batch_idx = torch.repeat_interleave(\n",
    "            torch.arange(batch_size, device=self.device), \n",
    "            num_atoms\n",
    "        )\n",
    "        \n",
    "        # Random fractional coordinates for each atom (values between 0 and 1)\n",
    "        frac_coords = torch.rand(total_atoms, 3, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Random atom types\n",
    "        atom_types = torch.randint(0, self.n_elements + 1, (total_atoms,), device=self.device)\n",
    "        \n",
    "        # Random unit cell parameters\n",
    "        lengths = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 5 + 5  # Between 5-10 Å\n",
    "        angles = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 30 + 90  # Between 90-120°\n",
    "\n",
    "        print(\"z_sampled.shape:\", z_sampled.shape)\n",
    "        print(\"frac_coords.shape:\", frac_coords.shape)\n",
    "        print(\"atom_types.shape:\", atom_types.shape,\n",
    "            \"   max atom_types:\", atom_types.max().item(),\n",
    "            \"   n_elements:\", self.n_elements)\n",
    "        print(\"num_atoms.shape:\", num_atoms.shape,\n",
    "            \"   sum num_atoms:\", num_atoms.sum().item())\n",
    "        print(\"lengths.shape:\", lengths.shape)\n",
    "        print(\"angles.shape:\", angles.shape)\n",
    "\n",
    "    \n",
    "        # Generate structures using the decoder\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Remove batch_idx from the arguments - decoder doesn't expect it\n",
    "                pred_cart_coord_diff, pred_atom_types = self.decoder(\n",
    "                    z_sampled,\n",
    "                    frac_coords,\n",
    "                    atom_types,\n",
    "                    num_atoms,\n",
    "                    lengths,\n",
    "                    angles\n",
    "                )\n",
    "                \n",
    "                # Combine the results\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,  # Still store it for reference\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles,\n",
    "                    'pred_cart_coord_diff': pred_cart_coord_diff,\n",
    "                    'pred_atom_types': pred_atom_types\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in decoder: {e}\")\n",
    "                # Add more debug information if needed\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles\n",
    "                }\n",
    "            \n",
    "        return generated_structures, z_sampled, log_probs\n",
    "    \n",
    "    def evaluate_structures(self, structures, z_vectors):\n",
    "        \"\"\"Evaluate generated structures using surrogate models.\"\"\"\n",
    "        # Predict formation energies\n",
    "        with torch.no_grad():\n",
    "            energies = self.energy_predictor(z_vectors)\n",
    "            \n",
    "            # Predict topological indices (Z2 invariants, Chern numbers, etc.)\n",
    "            topo_indices = self.topological_predictor(z_vectors)\n",
    "            \n",
    "            # Calculate band gaps (can be part of the topological predictor or separate)\n",
    "            band_gaps = self.estimate_band_gap(structures, z_vectors)\n",
    "            \n",
    "        # Combine predictions into a comprehensive evaluation\n",
    "        evaluations = {\n",
    "            'formation_energies': energies.cpu().numpy(),\n",
    "            'topological_indices': topo_indices.cpu().numpy(),\n",
    "            'band_gaps': band_gaps.cpu().numpy() if isinstance(band_gaps, torch.Tensor) else band_gaps\n",
    "        }\n",
    "        \n",
    "        return evaluations\n",
    "    \n",
    "    def calculate_rewards(self, evaluations):\n",
    "        \"\"\"Calculate rewards based on desired material properties.\"\"\"\n",
    "        # Extract evaluations\n",
    "        energies = evaluations['formation_energies']\n",
    "        topo_indices = evaluations['topological_indices']\n",
    "        band_gaps = evaluations['band_gaps']\n",
    "\n",
    "        energies  = np.array(energies).squeeze()  \n",
    "        band_gaps = np.array(band_gaps).squeeze()  \n",
    "        \n",
    "        # Convert to numpy for easier manipulation\n",
    "        if isinstance(energies, torch.Tensor):\n",
    "            energies = energies.cpu().numpy().squeeze()\n",
    "        if isinstance(topo_indices, torch.Tensor):\n",
    "            topo_indices = topo_indices.cpu().numpy()\n",
    "        if isinstance(band_gaps, torch.Tensor):\n",
    "            band_gaps = band_gaps.cpu().numpy().squeeze()\n",
    "            \n",
    "        # Calculate stability reward component\n",
    "        # Lower formation energy is better, but must be below threshold to be stable\n",
    "        # stability_threshold = self.config.get('stability_threshold', 0.1)\n",
    "        # stability_rewards = -energies * (energies < stability_threshold)\n",
    "\n",
    "        stability_rewards = -energies * (energies < self.config['stability_threshold'])\n",
    "        \n",
    "        # Calculate topological reward component\n",
    "        # For Z2 invariants, we typically want (1;000) for 3D TIs\n",
    "        # This is a simplified example - actual implementation depends on how topo_indices are represented\n",
    "        topo_rewards = np.sum(topo_indices * self.config.get('topo_weights'), axis=1)\n",
    "        \n",
    "        # Calculate band gap reward component\n",
    "        # Usually want a moderate band gap (not too small, not too large)\n",
    "        # target_gap = self.config.get('target_band_gap', 0.3)  # in eV\n",
    "        # gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\n",
    "        # gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target_gap) / gap_tolerance, 1.0)\n",
    "\n",
    "        target = self.config['target_band_gap']\n",
    "        tol    = self.config['gap_tolerance']\n",
    "        gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target) / tol, 1.0)\n",
    "        \n",
    "        combined_rewards = ( self.config['w_stability']   * stability_rewards\n",
    "                       + self.config['w_topological'] * topo_rewards\n",
    "                       + self.config['w_gap']         * gap_rewards )\n",
    "        \n",
    "        # Combine reward components with configurable weights\n",
    "        # w_stability = self.config.get('w_stability', 1.0)\n",
    "        # w_topological = self.config.get('w_topological', 2.0)\n",
    "        # w_gap = self.config.get('w_gap', 1.5)\n",
    "        \n",
    "        # combined_rewards = (w_stability * stability_rewards + \n",
    "        #                    w_topological * topo_rewards +\n",
    "        #                    w_gap * gap_rewards)\n",
    "        \n",
    "        # Create rewards dictionary\n",
    "        rewards_dict = {\n",
    "            'total': combined_rewards,\n",
    "            'stability': stability_rewards,\n",
    "            'topological': topo_rewards,\n",
    "            'band_gap': gap_rewards\n",
    "        }\n",
    "        \n",
    "        return rewards_dict\n",
    "    \n",
    "    def estimate_band_gap(self, structures, z_vectors):\n",
    "        \"\"\"Estimate band gaps of structures using a surrogate model.\"\"\"\n",
    "        # This would typically be a separate model or part of topological_predictor\n",
    "        # For simplicity, we'll use a mock implementation\n",
    "        batch_size = z_vectors.shape[0]\n",
    "        \n",
    "        # Mock band gap estimation (replace with actual model)\n",
    "        # In practice, this would use a trained neural network or other predictor\n",
    "        gaps = 0.2 + 0.3 * torch.sigmoid(z_vectors[:, 0]) + 0.1 * torch.randn(batch_size).to(self.device)\n",
    "        \n",
    "        return gaps\n",
    "    \n",
    "    def reinforce_update(self, rewards, log_probs):\n",
    "        \"\"\"Update policy network using REINFORCE algorithm.\"\"\"\n",
    "        # Convert to tensor with the right dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Normalize rewards\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "        \n",
    "        # Calculate policy loss\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\n",
    "        \n",
    "        # Update policy\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        # Optional gradient clipping\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            \n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item()\n",
    "    \n",
    "    def actor_critic_update(self, z_vectors, rewards, log_probs):\n",
    "        \"\"\"Update policy and critic networks using Actor-Critic algorithm.\"\"\"\n",
    "        if self.critic is None:\n",
    "            return self.reinforce_update(rewards, log_probs)\n",
    "            \n",
    "        # Convert rewards to tensor with proper dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Get critic's value predictions\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\n",
    "        \n",
    "        # Calculate advantages\n",
    "        advantages = rewards_tensor - value_predictions.detach()\n",
    "        \n",
    "        # Calculate policy (actor) loss\n",
    "        policy_loss = -(log_probs * advantages).mean()\n",
    "        \n",
    "        # Calculate value (critic) loss\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\n",
    "        \n",
    "        # Option 1: Combine losses and do a single backward pass\n",
    "        total_loss = policy_loss + critic_loss\n",
    "        \n",
    "        # Zero all gradients\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        \n",
    "        # Single backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Apply gradient clipping if needed\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.critic.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "        \n",
    "        # Update both networks\n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform a single training step.\"\"\"\n",
    "        # Generate structures\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\n",
    "        print(len(structures))\n",
    "\n",
    "        if not structures: \n",
    "            logger.error(\"no strucutres generated in this step\")\n",
    "            return  {'mean_reward': 0, 'max_reward': 0, 'mean_energy': 0, 'policy_loss': 0}\n",
    "        \n",
    "        # Evaluate structures\n",
    "        evaluations = self.evaluate_structures(structures, z_vectors)\n",
    "        \n",
    "        # Calculate rewards\n",
    "        rewards_dict = self.calculate_rewards(evaluations)\n",
    "        total_rewards = rewards_dict['total']\n",
    "        \n",
    "        # Store experience in replay buffer\n",
    "        for i in range(len(total_rewards)):\n",
    "            self.replay_buffer.add(\n",
    "                z_vectors[i].detach().cpu().numpy(),\n",
    "                total_rewards[i],\n",
    "                log_probs[i].detach().cpu().numpy()\n",
    "            )\n",
    "        \n",
    "        # Update policy using actor-critic or REINFORCE\n",
    "        if self.critic is not None:\n",
    "            loss_info = self.actor_critic_update(z_vectors, total_rewards, log_probs)\n",
    "            policy_loss = loss_info[0]\n",
    "        else:\n",
    "            policy_loss = self.reinforce_update(total_rewards, log_probs)\n",
    "            \n",
    "        # Track best structures\n",
    "        best_idx = np.argmax(total_rewards)\n",
    "\n",
    "        if best_idx >= len(total_rewards):\n",
    "            logger.warning(f\"best_idx {best_idx} out of bounds for total_rewards with length {len(total_rewards)}\")\n",
    "            best_idx = len(total_rewards) # Fallback to first item\n",
    "\n",
    "        print(f\"Type of total_rewards: {type(total_rewards)}\")\n",
    "        print(f\"Shape of total_rewards: {total_rewards.shape if hasattr(total_rewards, 'shape') else 'no shape attribute'}\")\n",
    "        print(f\"Type of total_rewards[best_idx]: {type(total_rewards[best_idx])}\")\n",
    "            \n",
    "        # Fix: Access the scalar value directly without trying to index further\n",
    "        #best_reward = float(total_rewards[best_idx])  # Remove the [0] indexing\n",
    "        reward_value = total_rewards[best_idx]\n",
    "        if isinstance(reward_value, np.ndarray):\n",
    "            if reward_value.size == 1:\n",
    "                best_reward = float(reward_value.item())\n",
    "            else:\n",
    "                # If it's an array with multiple values, take the first one\n",
    "                best_reward = float(reward_value[0])\n",
    "        else:\n",
    "            # If it's already a scalar type (int, float)\n",
    "            best_reward = float(reward_value)\n",
    "\n",
    "        # Determine if this iteration’s best is a new overall best\n",
    "        if len(self.results['best_rewards']) == 0:\n",
    "            is_new_best = True\n",
    "        else:\n",
    "            prev_best = max(self.results['best_rewards'])\n",
    "            # force a Python bool\n",
    "            is_new_best = bool(best_reward > prev_best)\n",
    "\n",
    "        if is_new_best:\n",
    "            best_struct = {\n",
    "                'frac_coords': structures['frac_coords'][best_idx],\n",
    "                'atom_types':  structures['atom_types'][best_idx],\n",
    "                'num_atoms':   structures['num_atoms'][best_idx],\n",
    "                'lengths':     structures['lengths'][best_idx],\n",
    "                'angles':      structures['angles'][best_idx],\n",
    "            }\n",
    "            # optional fields\n",
    "            pccd = structures.get('pred_cart_coord_diff', None)\n",
    "            if pccd is not None:\n",
    "                best_struct['pred_cart_coord_diff'] = pccd[best_idx]\n",
    "            pact = structures.get('pred_atom_types', None)\n",
    "            if pact is not None:\n",
    "                best_struct['pred_atom_types'] = pact[best_idx]\n",
    "\n",
    "            self.results['best_structures'].append(best_struct)\n",
    "\n",
    "        # Store results\n",
    "        self.results['rewards'].append(np.mean(total_rewards))\n",
    "        self.results['formation_energies'].append(np.mean(evaluations['formation_energies']))\n",
    "        self.results['topological_indices'].append(np.mean(evaluations['topological_indices']))\n",
    "        self.results['best_rewards'].append(best_reward)\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(total_rewards),\n",
    "            'max_reward': np.max(total_rewards),\n",
    "            'mean_energy': np.mean(evaluations['formation_energies']),\n",
    "            'policy_loss': policy_loss\n",
    "        }\n",
    "    \n",
    "    def train(self, num_iterations=None):\n",
    "        \"\"\"Train the model for the specified number of iterations.\"\"\"\n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.config.get('num_iterations', 500)\n",
    "            \n",
    "        logger.info(f\"Starting training for {num_iterations} iterations\")\n",
    "        \n",
    "        for iteration in tqdm(range(num_iterations)):\n",
    "            # Perform a training step\n",
    "            step_results = self.train_step()\n",
    "            \n",
    "            # Log progress periodically\n",
    "            if iteration % self.config.get('log_frequency', 10) == 0:\n",
    "                logger.info(\n",
    "                    f\"Iteration {iteration} | \"\n",
    "                    f\"Mean Reward: {step_results['mean_reward']:.4f} | \"\n",
    "                    f\"Max Reward: {step_results['max_reward']:.4f} | \"\n",
    "                    f\"Mean Energy: {step_results['mean_energy']:.4f} | \"\n",
    "                    f\"Policy Loss: {step_results['policy_loss']:.4f}\"\n",
    "                )\n",
    "                \n",
    "            # Save checkpoints periodically\n",
    "            if iteration % self.config.get('save_frequency', 100) == 0 and iteration > 0:\n",
    "                self.save_checkpoint(f\"checkpoint_iter_{iteration}.pt\")\n",
    "                \n",
    "        logger.info(\"Training completed\")\n",
    "        self.save_checkpoint(\"final_checkpoint.pt\")\n",
    "        self.save_results(\"training_results.pkl\")\n",
    "        \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint_dir = self.config.get('checkpoint_dir', './checkpoints')\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'policy_state_dict': self.policy_net.state_dict(),\n",
    "            'policy_optimizer': self.policy_optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'iteration': len(self.results['rewards'])\n",
    "        }\n",
    "        \n",
    "        if self.critic is not None:\n",
    "            checkpoint['critic_state_dict'] = self.critic.state_dict()\n",
    "            checkpoint['critic_optimizer'] = self.critic_optimizer.state_dict()\n",
    "            \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        \n",
    "    def save_results(self, filename):\n",
    "        \"\"\"Save training results.\"\"\"\n",
    "        results_dir = self.config.get('results_dir', './results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        results_path = os.path.join(results_dir, filename)\n",
    "        \n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(self.results, f)\n",
    "            \n",
    "        logger.info(f\"Saved results to {results_path}\")\n",
    "        \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])\n",
    "        self.policy_optimizer.load_state_dict(checkpoint['policy_optimizer'])\n",
    "        \n",
    "        if self.critic is not None and 'critic_state_dict' in checkpoint:\n",
    "            self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "            self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "            \n",
    "        logger.info(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "        return checkpoint.get('iteration', 0)\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for RL-based latent space exploration.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 256], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer for mean\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "        # Learnable log std for exploration\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # def _initialize_weights(self):\n",
    "    #     \"\"\"Initialize network weights.\"\"\"\n",
    "    #     for m in self.modules():\n",
    "    #         if isinstance(m, nn.Linear):\n",
    "    #             nn.init.xavier_normal_(m.weight)\n",
    "    #             if m.bias is not None:\n",
    "    #                 nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "                \n",
    "                # Ensure dtype is correct\n",
    "                m.weight.data = m.weight.data.to(dtype=torch.float32)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = m.bias.data.to(dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, z_noise):\n",
    "        \"\"\"\n",
    "        Forward pass through the policy network.\n",
    "        \n",
    "        Args:\n",
    "            z_noise: Random noise tensor of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            z_sampled: Sampled latent vectors\n",
    "            log_probs: Log probabilities of the sampled vectors\n",
    "        \"\"\"\n",
    "        x = self.fc_layers(z_noise)\n",
    "        mu = self.fc_mu(x)\n",
    "        \n",
    "        # Get standard deviation from learnable parameter\n",
    "        std = torch.exp(self.log_std.clamp(-20, 2))  # Clamp for stability\n",
    "        \n",
    "        # Create normal distribution\n",
    "        dist = Normal(mu, std)\n",
    "        \n",
    "        # Sample using reparameterization trick\n",
    "        z_sampled = dist.rsample()\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        log_probs = dist.log_prob(z_sampled).sum(dim=-1)\n",
    "        \n",
    "        return z_sampled, log_probs\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"Critic network for actor-critic method.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 128], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value output\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the critic network.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent vector of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            value: Predicted value of the state\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class EnergyPredictor(nn.Module):\n",
    "    \"\"\"Surrogate model to predict formation energy from latent space.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value for formation energy\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict formation energy from latent vector.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class TopologicalPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Surrogate model to predict topological invariants (Z2, Chern number) \n",
    "    from latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64], num_invariants=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - multiple values for topological invariants\n",
    "        # For 3D topological insulators, typically 4 Z2 invariants (ν₀;ν₁ν₂ν₃)\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.invariant_head = nn.Linear(input_dim, num_invariants)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict topological invariants from latent vector.\"\"\"\n",
    "        features = self.feature_extractor(z)\n",
    "        # Apply sigmoid to constrain outputs between 0 and 1\n",
    "        # In practice, these would be discretized to 0 or 1 when interpreting\n",
    "        invariants = torch.sigmoid(self.invariant_head(features))\n",
    "        return invariants\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer for more stable training.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size=10000):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def add(self, z, reward, log_prob):\n",
    "        \"\"\"Add experience to buffer.\"\"\"\n",
    "        if len(self.buffer) < self.max_size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (z, reward, log_prob)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        z, rewards, log_probs = map(np.array, zip(*batch))\n",
    "        return z, rewards, log_probs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size.\"\"\"\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import logging\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/cdvae')\n",
    "import cdvae\n",
    "# from cdvae.pl_modules.model import CDVAE\n",
    "# from cdvae.common.data_utils import get_train_val_test_test_loaders\n",
    "# from cdvae.common.data_utils import get_train_val_test_loaders\n",
    "# from cdvae.pl_data.dataset import CDVAEDataset\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CDVAE_TI_Generator:\n",
    "    \"\"\"\n",
    "    Crystal Diffusion Variational Autoencoder (CDVAE) with Reinforcement Learning\n",
    "    for targeted generation of Topological Insulator materials.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.float32 #set default tensor type to float32\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize CDVAE model components\n",
    "        self.initialize_models()\n",
    "        \n",
    "        # Set up optimizers\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Initialize results tracking\n",
    "        self.results = {\n",
    "            'rewards': [],\n",
    "            'z_gap': [],\n",
    "            'topological_indices': [],\n",
    "            'formation_energies': [],\n",
    "            'best_structures': [],\n",
    "            'best_rewards': [],\n",
    "        }\n",
    "        \n",
    "        # Initialize replay buffer for experience replay\n",
    "        self.replay_buffer = ReplayBuffer(config['buffer_size'])\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize CDVAE encoder, decoder and policy networks.\"\"\"\n",
    "        # Import specific model classes\n",
    "        try:\n",
    "            from cdvae.pl_modules.decoder import GemNetTDecoder\n",
    "            from cdvae.common.data_utils import StandardScalerTorch\n",
    "            from cdvae.common.data_utils import ATOM_TYPES\n",
    "     \n",
    "        except ImportError:\n",
    "            logger.error(\"Failed to import CDVAE modules. Please ensure CDVAE is installed correctly.\")\n",
    "            raise\n",
    "            \n",
    "        # Get dimensions and parameters from config\n",
    "        self.latent_dim = self.config['latent_dim']\n",
    "        self.n_elements = len(self.config['elements']) if 'elements' in self.config else len(ATOM_TYPES.get())\n",
    "        \n",
    "        #TODO: possibly write an encoder file addition to cdvae\n",
    "        # Initialize encoder (if using pre-trained weights)\n",
    "        # if self.config.get('use_encoder', False):\n",
    "        #     self.encoder = GraphEncoder(\n",
    "        #         hidden_dim=self.config['hidden_dim'],\n",
    "        #         latent_dim=self.latent_dim,\n",
    "        #         use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        #     ).to(self.device)\n",
    "            \n",
    "        #     if self.config.get('encoder_checkpoint'):\n",
    "        #         self._load_model(self.encoder, self.config['encoder_checkpoint'])\n",
    "        # else:\n",
    "        #     self.encoder = None\n",
    "\n",
    "        self.encoder = None\n",
    "            \n",
    "        # Initialize decoder\n",
    "        self.decoder = GemNetTDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.config['hidden_dim'],\n",
    "            #cutoff=self.config.get('cutoff', 6.0),\n",
    "            max_neighbors=self.config.get('max_neighbors', 20),\n",
    "            #use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('decoder_checkpoint'):\n",
    "            self._load_model(self.decoder, self.config['decoder_checkpoint'])\n",
    "\n",
    "        import inspect\n",
    "        print(\"Decoder signature:\", inspect.signature(self.decoder.forward))\n",
    "            \n",
    "        # Initialize policy network for RL\n",
    "        self.policy_net = PolicyNetwork(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('policy_hidden_dims', [256, 256]),\n",
    "            activation=self.config.get('policy_activation', 'relu')\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize critic network for actor-critic methods\n",
    "        if self.config.get('use_critic', True):\n",
    "            self.critic = CriticNetwork(\n",
    "                latent_dim=self.latent_dim,\n",
    "                hidden_dims=self.config.get('critic_hidden_dims', [256, 128]),\n",
    "                activation=self.config.get('critic_activation', 'relu')\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.critic = None\n",
    "            \n",
    "        # DFT surrogate models - predict quantum properties directly from latent space\n",
    "        self.energy_predictor = EnergyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('energy_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.topological_predictor = TopologicalPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('topo_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('surrogate_checkpoint'):\n",
    "            self._load_surrogate_models(self.config['surrogate_checkpoint'])\n",
    "        \n",
    "    def setup_optimizers(self):\n",
    "        \"\"\"Set up optimizers for different components.\"\"\"\n",
    "        # Policy optimizer\n",
    "        self.policy_optimizer = torch.optim.Adam(\n",
    "            self.policy_net.parameters(),\n",
    "            lr=self.config.get('policy_lr', 1e-4),\n",
    "            weight_decay=self.config.get('policy_weight_decay', 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Critic optimizer (if using actor-critic)\n",
    "        if self.critic is not None:\n",
    "            self.critic_optimizer = torch.optim.Adam(\n",
    "                self.critic.parameters(),\n",
    "                lr=self.config.get('critic_lr', 3e-4),\n",
    "                weight_decay=self.config.get('critic_weight_decay', 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Surrogate model optimizers for fine-tuning\n",
    "        if self.config.get('train_surrogates', False):\n",
    "            self.energy_optimizer = torch.optim.Adam(\n",
    "                self.energy_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "            self.topo_optimizer = torch.optim.Adam(\n",
    "                self.topological_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "    def _load_model(self, model, checkpoint_path):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'state_dict' in checkpoint:\n",
    "                # Handle pytorch-lightning checkpoints\n",
    "                state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items() \n",
    "                              if k.startswith('model.')}\n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "            else:\n",
    "                # Handle regular torch checkpoints\n",
    "                model.load_state_dict(checkpoint, strict=False)\n",
    "            logger.info(f\"Loaded weights from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load weights: {e}\")\n",
    "            \n",
    "    def _load_surrogate_models(self, checkpoint_path):\n",
    "        \"\"\"Load surrogate model weights.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.energy_predictor.load_state_dict(checkpoint['energy_predictor'])\n",
    "            self.topological_predictor.load_state_dict(checkpoint['topo_predictor'])\n",
    "            logger.info(f\"Loaded surrogate models from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load surrogate models: {e}\")\n",
    "    \n",
    "    def generate_structures(self, batch_size=None):\n",
    "        \"\"\"Generate crystal structures using the policy network and decoder.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.get('batch_size', 32)\n",
    "                \n",
    "        # Sample latent vectors from the policy network\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim, device=self.device, dtype=self.dtype)\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\n",
    "        \n",
    "        # For testing, let's use a smaller batch size and fewer atoms per crystal\n",
    "        max_atoms = 8  # Small number of atoms per crystal for testing\n",
    "        \n",
    "        # Create a batch where each structure has a different number of atoms\n",
    "        num_atoms = torch.randint(2, max_atoms+1, (batch_size,), device=self.device)\n",
    "    \n",
    "        # Create tensors with proper dimensions\n",
    "        total_atoms = num_atoms.sum().item()\n",
    "        \n",
    "        # Create a batch index (for tracking purposes, not passed to decoder)\n",
    "        batch_idx = torch.repeat_interleave(\n",
    "            torch.arange(batch_size, device=self.device), \n",
    "            num_atoms\n",
    "        )\n",
    "        \n",
    "        # Random fractional coordinates for each atom (values between 0 and 1)\n",
    "        frac_coords = torch.rand(total_atoms, 3, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Random atom types\n",
    "        atom_types = torch.randint(0, self.n_elements + 1, (total_atoms,), device=self.device)\n",
    "        \n",
    "        # Random unit cell parameters\n",
    "        lengths = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 5 + 5  # Between 5-10 Å\n",
    "        angles = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 30 + 90  # Between 90-120°\n",
    "\n",
    "        print(\"z_sampled.shape:\", z_sampled.shape)\n",
    "        print(\"frac_coords.shape:\", frac_coords.shape)\n",
    "        print(\"atom_types.shape:\", atom_types.shape,\n",
    "            \"   max atom_types:\", atom_types.max().item(),\n",
    "            \"   n_elements:\", self.n_elements)\n",
    "        print(\"num_atoms.shape:\", num_atoms.shape,\n",
    "            \"   sum num_atoms:\", num_atoms.sum().item())\n",
    "        print(\"lengths.shape:\", lengths.shape)\n",
    "        print(\"angles.shape:\", angles.shape)\n",
    "\n",
    "    \n",
    "        # Generate structures using the decoder\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Remove batch_idx from the arguments - decoder doesn't expect it\n",
    "                pred_cart_coord_diff, pred_atom_types = self.decoder(\n",
    "                    z_sampled,\n",
    "                    frac_coords,\n",
    "                    atom_types,\n",
    "                    num_atoms,\n",
    "                    lengths,\n",
    "                    angles\n",
    "                )\n",
    "                \n",
    "                # Combine the results\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,  # Still store it for reference\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles,\n",
    "                    'pred_cart_coord_diff': pred_cart_coord_diff,\n",
    "                    'pred_atom_types': pred_atom_types\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in decoder: {e}\")\n",
    "                # Add more debug information if needed\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles\n",
    "                }\n",
    "            \n",
    "        return generated_structures, z_sampled, log_probs\n",
    "    \n",
    "    def evaluate_structures(self, structures, z_vectors):\n",
    "        \"\"\"Evaluate generated structures using surrogate models.\"\"\"\n",
    "        # Predict formation energies\n",
    "        with torch.no_grad():\n",
    "            energies = self.energy_predictor(z_vectors)\n",
    "            \n",
    "            # Predict topological indices (Z2 invariants, Chern numbers, etc.)\n",
    "            topo_indices = self.topological_predictor(z_vectors)\n",
    "            \n",
    "            # Calculate band gaps (can be part of the topological predictor or separate)\n",
    "            band_gaps = self.estimate_band_gap(structures, z_vectors)\n",
    "            \n",
    "        # Combine predictions into a comprehensive evaluation\n",
    "        evaluations = {\n",
    "            'formation_energies': energies.cpu().numpy(),\n",
    "            'topological_indices': topo_indices.cpu().numpy(),\n",
    "            'band_gaps': band_gaps.cpu().numpy() if isinstance(band_gaps, torch.Tensor) else band_gaps\n",
    "        }\n",
    "        \n",
    "        return evaluations\n",
    "    \n",
    "    def calculate_rewards(self, evaluations):\n",
    "        \"\"\"Calculate rewards based on desired material properties.\"\"\"\n",
    "        # Extract evaluations\n",
    "        energies = evaluations['formation_energies']\n",
    "        topo_indices = evaluations['topological_indices']\n",
    "        band_gaps = evaluations['band_gaps']\n",
    "\n",
    "        energies  = np.array(energies).squeeze()  \n",
    "        band_gaps = np.array(band_gaps).squeeze()  \n",
    "        \n",
    "        # Convert to numpy for easier manipulation\n",
    "        if isinstance(energies, torch.Tensor):\n",
    "            energies = energies.cpu().numpy().squeeze()\n",
    "        if isinstance(topo_indices, torch.Tensor):\n",
    "            topo_indices = topo_indices.cpu().numpy()\n",
    "        if isinstance(band_gaps, torch.Tensor):\n",
    "            band_gaps = band_gaps.cpu().numpy().squeeze()\n",
    "            \n",
    "        # Calculate stability reward component\n",
    "        # Lower formation energy is better, but must be below threshold to be stable\n",
    "        # stability_threshold = self.config.get('stability_threshold', 0.1)\n",
    "        # stability_rewards = -energies * (energies < stability_threshold)\n",
    "\n",
    "        stability_rewards = -energies * (energies < self.config['stability_threshold'])\n",
    "        \n",
    "        # Calculate topological reward component\n",
    "        # For Z2 invariants, we typically want (1;000) for 3D TIs\n",
    "        # This is a simplified example - actual implementation depends on how topo_indices are represented\n",
    "        topo_rewards = np.sum(topo_indices * self.config.get('topo_weights'), axis=1)\n",
    "        \n",
    "        # Calculate band gap reward component\n",
    "        # Usually want a moderate band gap (not too small, not too large)\n",
    "        # target_gap = self.config.get('target_band_gap', 0.3)  # in eV\n",
    "        # gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\n",
    "        # gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target_gap) / gap_tolerance, 1.0)\n",
    "\n",
    "        target = self.config['target_band_gap']\n",
    "        tol    = self.config['gap_tolerance']\n",
    "        gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target) / tol, 1.0)\n",
    "        \n",
    "        combined_rewards = ( self.config['w_stability']   * stability_rewards\n",
    "                       + self.config['w_topological'] * topo_rewards\n",
    "                       + self.config['w_gap']         * gap_rewards )\n",
    "        \n",
    "        # Combine reward components with configurable weights\n",
    "        # w_stability = self.config.get('w_stability', 1.0)\n",
    "        # w_topological = self.config.get('w_topological', 2.0)\n",
    "        # w_gap = self.config.get('w_gap', 1.5)\n",
    "        \n",
    "        # combined_rewards = (w_stability * stability_rewards + \n",
    "        #                    w_topological * topo_rewards +\n",
    "        #                    w_gap * gap_rewards)\n",
    "        \n",
    "        # Create rewards dictionary\n",
    "        rewards_dict = {\n",
    "            'total': combined_rewards,\n",
    "            'stability': stability_rewards,\n",
    "            'topological': topo_rewards,\n",
    "            'band_gap': gap_rewards\n",
    "        }\n",
    "        \n",
    "        return rewards_dict\n",
    "    \n",
    "    def estimate_band_gap(self, structures, z_vectors):\n",
    "        \"\"\"Estimate band gaps of structures using a surrogate model.\"\"\"\n",
    "        # This would typically be a separate model or part of topological_predictor\n",
    "        # For simplicity, we'll use a mock implementation\n",
    "        batch_size = z_vectors.shape[0]\n",
    "        \n",
    "        # Mock band gap estimation (replace with actual model)\n",
    "        # In practice, this would use a trained neural network or other predictor\n",
    "        gaps = 0.2 + 0.3 * torch.sigmoid(z_vectors[:, 0]) + 0.1 * torch.randn(batch_size).to(self.device)\n",
    "        \n",
    "        return gaps\n",
    "    \n",
    "    def reinforce_update(self, rewards, log_probs):\n",
    "        \"\"\"Update policy network using REINFORCE algorithm.\"\"\"\n",
    "        # Convert to tensor with the right dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Normalize rewards\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "        \n",
    "        # Calculate policy loss\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\n",
    "        \n",
    "        # Update policy\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        # Optional gradient clipping\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            \n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item()\n",
    "    \n",
    "    def actor_critic_update(self, z_vectors, rewards, log_probs):\n",
    "        \"\"\"Update policy and critic networks using Actor-Critic algorithm.\"\"\"\n",
    "        if self.critic is None:\n",
    "            return self.reinforce_update(rewards, log_probs)\n",
    "            \n",
    "        # Convert rewards to tensor with proper dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Get critic's value predictions\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\n",
    "        \n",
    "        # Calculate advantages\n",
    "        advantages = rewards_tensor - value_predictions.detach()\n",
    "        \n",
    "        # Calculate policy (actor) loss\n",
    "        policy_loss = -(log_probs * advantages).mean()\n",
    "        \n",
    "        # Calculate value (critic) loss\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\n",
    "        \n",
    "        # Option 1: Combine losses and do a single backward pass\n",
    "        total_loss = policy_loss + critic_loss\n",
    "        \n",
    "        # Zero all gradients\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        \n",
    "        # Single backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Apply gradient clipping if needed\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.critic.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "        \n",
    "        # Update both networks\n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform a single training step.\"\"\"\n",
    "        # Generate structures\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\n",
    "        print(len(structures))\n",
    "\n",
    "        if not structures: \n",
    "            logger.error(\"no strucutres generated in this step\")\n",
    "            return  {'mean_reward': 0, 'max_reward': 0, 'mean_energy': 0, 'policy_loss': 0}\n",
    "        \n",
    "        # Evaluate structures\n",
    "        evaluations = self.evaluate_structures(structures, z_vectors)\n",
    "        \n",
    "        # Calculate rewards\n",
    "        rewards_dict = self.calculate_rewards(evaluations)\n",
    "        total_rewards = rewards_dict['total']\n",
    "        \n",
    "        # Store experience in replay buffer\n",
    "        for i in range(len(total_rewards)):\n",
    "            self.replay_buffer.add(\n",
    "                z_vectors[i].detach().cpu().numpy(),\n",
    "                total_rewards[i],\n",
    "                log_probs[i].detach().cpu().numpy()\n",
    "            )\n",
    "        \n",
    "        # Update policy using actor-critic or REINFORCE\n",
    "        if self.critic is not None:\n",
    "            loss_info = self.actor_critic_update(z_vectors, total_rewards, log_probs)\n",
    "            policy_loss = loss_info[0]\n",
    "        else:\n",
    "            policy_loss = self.reinforce_update(total_rewards, log_probs)\n",
    "            \n",
    "        # Track best structures\n",
    "        best_idx = np.argmax(total_rewards)\n",
    "\n",
    "        if best_idx >= len(total_rewards):\n",
    "            logger.warning(f\"best_idx {best_idx} out of bounds for total_rewards with length {len(total_rewards)}\")\n",
    "            best_idx = len(total_rewards) # Fallback to first item\n",
    "\n",
    "        print(f\"Type of total_rewards: {type(total_rewards)}\")\n",
    "        print(f\"Shape of total_rewards: {total_rewards.shape if hasattr(total_rewards, 'shape') else 'no shape attribute'}\")\n",
    "        print(f\"Type of total_rewards[best_idx]: {type(total_rewards[best_idx])}\")\n",
    "            \n",
    "        # Fix: Access the scalar value directly without trying to index further\n",
    "        #best_reward = float(total_rewards[best_idx])  # Remove the [0] indexing\n",
    "        reward_value = total_rewards[best_idx]\n",
    "        if isinstance(reward_value, np.ndarray):\n",
    "            if reward_value.size == 1:\n",
    "                best_reward = float(reward_value.item())\n",
    "            else:\n",
    "                # If it's an array with multiple values, take the first one\n",
    "                best_reward = float(reward_value[0])\n",
    "        else:\n",
    "            # If it's already a scalar type (int, float)\n",
    "            best_reward = float(reward_value)\n",
    "\n",
    "        # Determine if this iteration’s best is a new overall best\n",
    "        if len(self.results['best_rewards']) == 0:\n",
    "            is_new_best = True\n",
    "        else:\n",
    "            prev_best = max(self.results['best_rewards'])\n",
    "            # force a Python bool\n",
    "            is_new_best = bool(best_reward > prev_best)\n",
    "\n",
    "        if is_new_best:\n",
    "            best_struct = {\n",
    "                'frac_coords': structures['frac_coords'][best_idx],\n",
    "                'atom_types':  structures['atom_types'][best_idx],\n",
    "                'num_atoms':   structures['num_atoms'][best_idx],\n",
    "                'lengths':     structures['lengths'][best_idx],\n",
    "                'angles':      structures['angles'][best_idx],\n",
    "            }\n",
    "            # optional fields\n",
    "            pccd = structures.get('pred_cart_coord_diff', None)\n",
    "            if pccd is not None:\n",
    "                best_struct['pred_cart_coord_diff'] = pccd[best_idx]\n",
    "            pact = structures.get('pred_atom_types', None)\n",
    "            if pact is not None:\n",
    "                best_struct['pred_atom_types'] = pact[best_idx]\n",
    "\n",
    "            self.results['best_structures'].append(best_struct)\n",
    "\n",
    "        # Store results\n",
    "        self.results['rewards'].append(np.mean(total_rewards))\n",
    "        self.results['formation_energies'].append(np.mean(evaluations['formation_energies']))\n",
    "        self.results['topological_indices'].append(np.mean(evaluations['topological_indices']))\n",
    "        self.results['best_rewards'].append(best_reward)\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(total_rewards),\n",
    "            'max_reward': np.max(total_rewards),\n",
    "            'mean_energy': np.mean(evaluations['formation_energies']),\n",
    "            'policy_loss': policy_loss\n",
    "        }\n",
    "    \n",
    "    def train(self, num_iterations=None):\n",
    "        \"\"\"Train the model for the specified number of iterations.\"\"\"\n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.config.get('num_iterations', 500)\n",
    "            \n",
    "        logger.info(f\"Starting training for {num_iterations} iterations\")\n",
    "        \n",
    "        for iteration in tqdm(range(num_iterations)):\n",
    "            # Perform a training step\n",
    "            step_results = self.train_step()\n",
    "            \n",
    "            # Log progress periodically\n",
    "            if iteration % self.config.get('log_frequency', 10) == 0:\n",
    "                logger.info(\n",
    "                    f\"Iteration {iteration} | \"\n",
    "                    f\"Mean Reward: {step_results['mean_reward']:.4f} | \"\n",
    "                    f\"Max Reward: {step_results['max_reward']:.4f} | \"\n",
    "                    f\"Mean Energy: {step_results['mean_energy']:.4f} | \"\n",
    "                    f\"Policy Loss: {step_results['policy_loss']:.4f}\"\n",
    "                )\n",
    "                \n",
    "            # Save checkpoints periodically\n",
    "            if iteration % self.config.get('save_frequency', 100) == 0 and iteration > 0:\n",
    "                self.save_checkpoint(f\"checkpoint_iter_{iteration}.pt\")\n",
    "                \n",
    "        logger.info(\"Training completed\")\n",
    "        self.save_checkpoint(\"final_checkpoint.pt\")\n",
    "        self.save_results(\"training_results.pkl\")\n",
    "        \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint_dir = self.config.get('checkpoint_dir', './checkpoints')\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'policy_state_dict': self.policy_net.state_dict(),\n",
    "            'policy_optimizer': self.policy_optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'iteration': len(self.results['rewards'])\n",
    "        }\n",
    "        \n",
    "        if self.critic is not None:\n",
    "            checkpoint['critic_state_dict'] = self.critic.state_dict()\n",
    "            checkpoint['critic_optimizer'] = self.critic_optimizer.state_dict()\n",
    "            \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        \n",
    "    def save_results(self, filename):\n",
    "        \"\"\"Save training results.\"\"\"\n",
    "        results_dir = self.config.get('results_dir', './results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        results_path = os.path.join(results_dir, filename)\n",
    "        \n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(self.results, f)\n",
    "            \n",
    "        logger.info(f\"Saved results to {results_path}\")\n",
    "        \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])\n",
    "        self.policy_optimizer.load_state_dict(checkpoint['policy_optimizer'])\n",
    "        \n",
    "        if self.critic is not None and 'critic_state_dict' in checkpoint:\n",
    "            self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "            self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "            \n",
    "        logger.info(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "        return checkpoint.get('iteration', 0)\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for RL-based latent space exploration.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 256], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer for mean\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "        # Learnable log std for exploration\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # def _initialize_weights(self):\n",
    "    #     \"\"\"Initialize network weights.\"\"\"\n",
    "    #     for m in self.modules():\n",
    "    #         if isinstance(m, nn.Linear):\n",
    "    #             nn.init.xavier_normal_(m.weight)\n",
    "    #             if m.bias is not None:\n",
    "    #                 nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "                \n",
    "                # Ensure dtype is correct\n",
    "                m.weight.data = m.weight.data.to(dtype=torch.float32)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = m.bias.data.to(dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, z_noise):\n",
    "        \"\"\"\n",
    "        Forward pass through the policy network.\n",
    "        \n",
    "        Args:\n",
    "            z_noise: Random noise tensor of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            z_sampled: Sampled latent vectors\n",
    "            log_probs: Log probabilities of the sampled vectors\n",
    "        \"\"\"\n",
    "        x = self.fc_layers(z_noise)\n",
    "        mu = self.fc_mu(x)\n",
    "        \n",
    "        # Get standard deviation from learnable parameter\n",
    "        std = torch.exp(self.log_std.clamp(-20, 2))  # Clamp for stability\n",
    "        \n",
    "        # Create normal distribution\n",
    "        dist = Normal(mu, std)\n",
    "        \n",
    "        # Sample using reparameterization trick\n",
    "        z_sampled = dist.rsample()\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        log_probs = dist.log_prob(z_sampled).sum(dim=-1)\n",
    "        \n",
    "        return z_sampled, log_probs\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"Critic network for actor-critic method.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 128], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value output\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the critic network.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent vector of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            value: Predicted value of the state\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class EnergyPredictor(nn.Module):\n",
    "    \"\"\"Surrogate model to predict formation energy from latent space.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value for formation energy\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict formation energy from latent vector.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class TopologicalPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Surrogate model to predict topological invariants (Z2, Chern number) \n",
    "    from latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64], num_invariants=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - multiple values for topological invariants\n",
    "        # For 3D topological insulators, typically 4 Z2 invariants (ν₀;ν₁ν₂ν₃)\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.invariant_head = nn.Linear(input_dim, num_invariants)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict topological invariants from latent vector.\"\"\"\n",
    "        features = self.feature_extractor(z)\n",
    "        # Apply sigmoid to constrain outputs between 0 and 1\n",
    "        # In practice, these would be discretized to 0 or 1 when interpreting\n",
    "        invariants = torch.sigmoid(self.invariant_head(features))\n",
    "        return invariants\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer for more stable training.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size=10000):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def add(self, z, reward, log_prob):\n",
    "        \"\"\"Add experience to buffer.\"\"\"\n",
    "        if len(self.buffer) < self.max_size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (z, reward, log_prob)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        z, rewards, log_probs = map(np.array, zip(*batch))\n",
    "        return z, rewards, log_probs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size.\"\"\"\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import logging\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/cdvae')\n",
    "import cdvae\n",
    "# from cdvae.pl_modules.model import CDVAE\n",
    "# from cdvae.common.data_utils import get_train_val_test_test_loaders\n",
    "# from cdvae.common.data_utils import get_train_val_test_loaders\n",
    "# from cdvae.pl_data.dataset import CDVAEDataset\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CDVAE_TI_Generator:\n",
    "    \"\"\"\n",
    "    Crystal Diffusion Variational Autoencoder (CDVAE) with Reinforcement Learning\n",
    "    for targeted generation of Topological Insulator materials.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.float32 #set default tensor type to float32\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize CDVAE model components\n",
    "        self.initialize_models()\n",
    "        \n",
    "        # Set up optimizers\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Initialize results tracking\n",
    "        self.results = {\n",
    "            'rewards': [],\n",
    "            'z_gap': [],\n",
    "            'topological_indices': [],\n",
    "            'formation_energies': [],\n",
    "            'best_structures': [],\n",
    "            'best_rewards': [],\n",
    "        }\n",
    "        \n",
    "        # Initialize replay buffer for experience replay\n",
    "        self.replay_buffer = ReplayBuffer(config['buffer_size'])\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize CDVAE encoder, decoder and policy networks.\"\"\"\n",
    "        # Import specific model classes\n",
    "        try:\n",
    "            from cdvae.pl_modules.decoder import GemNetTDecoder\n",
    "            from cdvae.common.data_utils import StandardScalerTorch\n",
    "            from cdvae.common.data_utils import ATOM_TYPES\n",
    "     \n",
    "        except ImportError:\n",
    "            logger.error(\"Failed to import CDVAE modules. Please ensure CDVAE is installed correctly.\")\n",
    "            raise\n",
    "            \n",
    "        # Get dimensions and parameters from config\n",
    "        self.latent_dim = self.config['latent_dim']\n",
    "        self.n_elements = len(self.config['elements']) if 'elements' in self.config else len(ATOM_TYPES.get())\n",
    "        \n",
    "        #TODO: possibly write an encoder file addition to cdvae\n",
    "        # Initialize encoder (if using pre-trained weights)\n",
    "        # if self.config.get('use_encoder', False):\n",
    "        #     self.encoder = GraphEncoder(\n",
    "        #         hidden_dim=self.config['hidden_dim'],\n",
    "        #         latent_dim=self.latent_dim,\n",
    "        #         use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        #     ).to(self.device)\n",
    "            \n",
    "        #     if self.config.get('encoder_checkpoint'):\n",
    "        #         self._load_model(self.encoder, self.config['encoder_checkpoint'])\n",
    "        # else:\n",
    "        #     self.encoder = None\n",
    "\n",
    "        self.encoder = None\n",
    "            \n",
    "        # Initialize decoder\n",
    "        self.decoder = GemNetTDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.config['hidden_dim'],\n",
    "            #cutoff=self.config.get('cutoff', 6.0),\n",
    "            max_neighbors=self.config.get('max_neighbors', 20),\n",
    "            #use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('decoder_checkpoint'):\n",
    "            self._load_model(self.decoder, self.config['decoder_checkpoint'])\n",
    "\n",
    "        import inspect\n",
    "        print(\"Decoder signature:\", inspect.signature(self.decoder.forward))\n",
    "            \n",
    "        # Initialize policy network for RL\n",
    "        self.policy_net = PolicyNetwork(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('policy_hidden_dims', [256, 256]),\n",
    "            activation=self.config.get('policy_activation', 'relu')\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize critic network for actor-critic methods\n",
    "        if self.config.get('use_critic', True):\n",
    "            self.critic = CriticNetwork(\n",
    "                latent_dim=self.latent_dim,\n",
    "                hidden_dims=self.config.get('critic_hidden_dims', [256, 128]),\n",
    "                activation=self.config.get('critic_activation', 'relu')\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.critic = None\n",
    "            \n",
    "        # DFT surrogate models - predict quantum properties directly from latent space\n",
    "        self.energy_predictor = EnergyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('energy_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.topological_predictor = TopologicalPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('topo_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('surrogate_checkpoint'):\n",
    "            self._load_surrogate_models(self.config['surrogate_checkpoint'])\n",
    "        \n",
    "    def setup_optimizers(self):\n",
    "        \"\"\"Set up optimizers for different components.\"\"\"\n",
    "        # Policy optimizer\n",
    "        self.policy_optimizer = torch.optim.Adam(\n",
    "            self.policy_net.parameters(),\n",
    "            lr=self.config.get('policy_lr', 1e-4),\n",
    "            weight_decay=self.config.get('policy_weight_decay', 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Critic optimizer (if using actor-critic)\n",
    "        if self.critic is not None:\n",
    "            self.critic_optimizer = torch.optim.Adam(\n",
    "                self.critic.parameters(),\n",
    "                lr=self.config.get('critic_lr', 3e-4),\n",
    "                weight_decay=self.config.get('critic_weight_decay', 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Surrogate model optimizers for fine-tuning\n",
    "        if self.config.get('train_surrogates', False):\n",
    "            self.energy_optimizer = torch.optim.Adam(\n",
    "                self.energy_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "            self.topo_optimizer = torch.optim.Adam(\n",
    "                self.topological_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "    def _load_model(self, model, checkpoint_path):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'state_dict' in checkpoint:\n",
    "                # Handle pytorch-lightning checkpoints\n",
    "                state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items() \n",
    "                              if k.startswith('model.')}\n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "            else:\n",
    "                # Handle regular torch checkpoints\n",
    "                model.load_state_dict(checkpoint, strict=False)\n",
    "            logger.info(f\"Loaded weights from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load weights: {e}\")\n",
    "            \n",
    "    def _load_surrogate_models(self, checkpoint_path):\n",
    "        \"\"\"Load surrogate model weights.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.energy_predictor.load_state_dict(checkpoint['energy_predictor'])\n",
    "            self.topological_predictor.load_state_dict(checkpoint['topo_predictor'])\n",
    "            logger.info(f\"Loaded surrogate models from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load surrogate models: {e}\")\n",
    "    \n",
    "    def generate_structures(self, batch_size=None):\n",
    "        \"\"\"Generate crystal structures using the policy network and decoder.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.get('batch_size', 32)\n",
    "                \n",
    "        # Sample latent vectors from the policy network\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim, device=self.device, dtype=self.dtype)\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\n",
    "        \n",
    "        # For testing, let's use a smaller batch size and fewer atoms per crystal\n",
    "        max_atoms = 8  # Small number of atoms per crystal for testing\n",
    "        \n",
    "        # Create a batch where each structure has a different number of atoms\n",
    "        num_atoms = torch.randint(2, max_atoms+1, (batch_size,), device=self.device)\n",
    "    \n",
    "        # Create tensors with proper dimensions\n",
    "        total_atoms = num_atoms.sum().item()\n",
    "        \n",
    "        # Create a batch index (for tracking purposes, not passed to decoder)\n",
    "        batch_idx = torch.repeat_interleave(\n",
    "            torch.arange(batch_size, device=self.device), \n",
    "            num_atoms\n",
    "        )\n",
    "        \n",
    "        # Random fractional coordinates for each atom (values between 0 and 1)\n",
    "        frac_coords = torch.rand(total_atoms, 3, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Random atom types\n",
    "        atom_types = torch.randint(0, self.n_elements + 1, (total_atoms,), device=self.device)\n",
    "        \n",
    "        # Random unit cell parameters\n",
    "        lengths = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 5 + 5  # Between 5-10 Å\n",
    "        angles = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 30 + 90  # Between 90-120°\n",
    "\n",
    "        print(\"z_sampled.shape:\", z_sampled.shape)\n",
    "        print(\"frac_coords.shape:\", frac_coords.shape)\n",
    "        print(\"atom_types.shape:\", atom_types.shape,\n",
    "            \"   max atom_types:\", atom_types.max().item(),\n",
    "            \"   n_elements:\", self.n_elements)\n",
    "        print(\"num_atoms.shape:\", num_atoms.shape,\n",
    "            \"   sum num_atoms:\", num_atoms.sum().item())\n",
    "        print(\"lengths.shape:\", lengths.shape)\n",
    "        print(\"angles.shape:\", angles.shape)\n",
    "\n",
    "    \n",
    "        # Generate structures using the decoder\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Remove batch_idx from the arguments - decoder doesn't expect it\n",
    "                pred_cart_coord_diff, pred_atom_types = self.decoder(\n",
    "                    z_sampled,\n",
    "                    frac_coords,\n",
    "                    atom_types,\n",
    "                    num_atoms,\n",
    "                    lengths,\n",
    "                    angles\n",
    "                )\n",
    "                \n",
    "                # Combine the results\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,  # Still store it for reference\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles,\n",
    "                    'pred_cart_coord_diff': pred_cart_coord_diff,\n",
    "                    'pred_atom_types': pred_atom_types\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in decoder: {e}\")\n",
    "                # Add more debug information if needed\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles\n",
    "                }\n",
    "            \n",
    "        return generated_structures, z_sampled, log_probs\n",
    "    \n",
    "    def evaluate_structures(self, structures, z_vectors):\n",
    "        \"\"\"Evaluate generated structures using surrogate models.\"\"\"\n",
    "        # Predict formation energies\n",
    "        with torch.no_grad():\n",
    "            energies = self.energy_predictor(z_vectors)\n",
    "            \n",
    "            # Predict topological indices (Z2 invariants, Chern numbers, etc.)\n",
    "            topo_indices = self.topological_predictor(z_vectors)\n",
    "            \n",
    "            # Calculate band gaps (can be part of the topological predictor or separate)\n",
    "            band_gaps = self.estimate_band_gap(structures, z_vectors)\n",
    "            \n",
    "        # Combine predictions into a comprehensive evaluation\n",
    "        evaluations = {\n",
    "            'formation_energies': energies.cpu().numpy(),\n",
    "            'topological_indices': topo_indices.cpu().numpy(),\n",
    "            'band_gaps': band_gaps.cpu().numpy() if isinstance(band_gaps, torch.Tensor) else band_gaps\n",
    "        }\n",
    "        \n",
    "        return evaluations\n",
    "    \n",
    "    def calculate_rewards(self, evaluations):\n",
    "        \"\"\"Calculate rewards based on desired material properties.\"\"\"\n",
    "        # Extract evaluations\n",
    "        energies = evaluations['formation_energies']\n",
    "        topo_indices = evaluations['topological_indices']\n",
    "        band_gaps = evaluations['band_gaps']\n",
    "\n",
    "        energies  = np.array(energies).squeeze()  \n",
    "        band_gaps = np.array(band_gaps).squeeze()  \n",
    "        \n",
    "        # Convert to numpy for easier manipulation\n",
    "        if isinstance(energies, torch.Tensor):\n",
    "            energies = energies.cpu().numpy().squeeze()\n",
    "        if isinstance(topo_indices, torch.Tensor):\n",
    "            topo_indices = topo_indices.cpu().numpy()\n",
    "        if isinstance(band_gaps, torch.Tensor):\n",
    "            band_gaps = band_gaps.cpu().numpy().squeeze()\n",
    "            \n",
    "        # Calculate stability reward component\n",
    "        # Lower formation energy is better, but must be below threshold to be stable\n",
    "        # stability_threshold = self.config.get('stability_threshold', 0.1)\n",
    "        # stability_rewards = -energies * (energies < stability_threshold)\n",
    "\n",
    "        stability_rewards = -energies * (energies < self.config['stability_threshold'])\n",
    "        \n",
    "        # Calculate topological reward component\n",
    "        # For Z2 invariants, we typically want (1;000) for 3D TIs\n",
    "        # This is a simplified example - actual implementation depends on how topo_indices are represented\n",
    "        topo_rewards = np.sum(topo_indices * self.config.get('topo_weights'), axis=1)\n",
    "        \n",
    "        # Calculate band gap reward component\n",
    "        # Usually want a moderate band gap (not too small, not too large)\n",
    "        # target_gap = self.config.get('target_band_gap', 0.3)  # in eV\n",
    "        # gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\n",
    "        # gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target_gap) / gap_tolerance, 1.0)\n",
    "\n",
    "        target = self.config['target_band_gap']\n",
    "        tol    = self.config['gap_tolerance']\n",
    "        gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target) / tol, 1.0)\n",
    "        \n",
    "        combined_rewards = ( self.config['w_stability']   * stability_rewards\n",
    "                       + self.config['w_topological'] * topo_rewards\n",
    "                       + self.config['w_gap']         * gap_rewards )\n",
    "        \n",
    "        # Combine reward components with configurable weights\n",
    "        # w_stability = self.config.get('w_stability', 1.0)\n",
    "        # w_topological = self.config.get('w_topological', 2.0)\n",
    "        # w_gap = self.config.get('w_gap', 1.5)\n",
    "        \n",
    "        # combined_rewards = (w_stability * stability_rewards + \n",
    "        #                    w_topological * topo_rewards +\n",
    "        #                    w_gap * gap_rewards)\n",
    "        \n",
    "        # Create rewards dictionary\n",
    "        rewards_dict = {\n",
    "            'total': combined_rewards,\n",
    "            'stability': stability_rewards,\n",
    "            'topological': topo_rewards,\n",
    "            'band_gap': gap_rewards\n",
    "        }\n",
    "        \n",
    "        return rewards_dict\n",
    "    \n",
    "    def estimate_band_gap(self, structures, z_vectors):\n",
    "        \"\"\"Estimate band gaps of structures using a surrogate model.\"\"\"\n",
    "        # This would typically be a separate model or part of topological_predictor\n",
    "        # For simplicity, we'll use a mock implementation\n",
    "        batch_size = z_vectors.shape[0]\n",
    "        \n",
    "        # Mock band gap estimation (replace with actual model)\n",
    "        # In practice, this would use a trained neural network or other predictor\n",
    "        gaps = 0.2 + 0.3 * torch.sigmoid(z_vectors[:, 0]) + 0.1 * torch.randn(batch_size).to(self.device)\n",
    "        \n",
    "        return gaps\n",
    "    \n",
    "    def reinforce_update(self, rewards, log_probs):\n",
    "        \"\"\"Update policy network using REINFORCE algorithm.\"\"\"\n",
    "        # Convert to tensor with the right dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Normalize rewards\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "        \n",
    "        # Calculate policy loss\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\n",
    "        \n",
    "        # Update policy\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        # Optional gradient clipping\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            \n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item()\n",
    "    \n",
    "    def actor_critic_update(self, z_vectors, rewards, log_probs):\n",
    "        \"\"\"Update policy and critic networks using Actor-Critic algorithm.\"\"\"\n",
    "        if self.critic is None:\n",
    "            return self.reinforce_update(rewards, log_probs)\n",
    "            \n",
    "        # Convert rewards to tensor with proper dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Get critic's value predictions\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\n",
    "        \n",
    "        # Calculate advantages\n",
    "        advantages = rewards_tensor - value_predictions.detach()\n",
    "        \n",
    "        # Calculate policy (actor) loss\n",
    "        policy_loss = -(log_probs * advantages).mean()\n",
    "        \n",
    "        # Calculate value (critic) loss\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\n",
    "        \n",
    "        # Option 1: Combine losses and do a single backward pass\n",
    "        total_loss = policy_loss + critic_loss\n",
    "        \n",
    "        # Zero all gradients\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        \n",
    "        # Single backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Apply gradient clipping if needed\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.critic.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "        \n",
    "        # Update both networks\n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform a single training step.\"\"\"\n",
    "        # Generate structures\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\n",
    "        print(len(structures))\n",
    "\n",
    "        if not structures: \n",
    "            logger.error(\"no strucutres generated in this step\")\n",
    "            return  {'mean_reward': 0, 'max_reward': 0, 'mean_energy': 0, 'policy_loss': 0}\n",
    "        \n",
    "        # Evaluate structures\n",
    "        evaluations = self.evaluate_structures(structures, z_vectors)\n",
    "        \n",
    "        # Calculate rewards\n",
    "        rewards_dict = self.calculate_rewards(evaluations)\n",
    "        total_rewards = rewards_dict['total']\n",
    "        \n",
    "        # Store experience in replay buffer\n",
    "        for i in range(len(total_rewards)):\n",
    "            self.replay_buffer.add(\n",
    "                z_vectors[i].detach().cpu().numpy(),\n",
    "                total_rewards[i],\n",
    "                log_probs[i].detach().cpu().numpy()\n",
    "            )\n",
    "        \n",
    "        # Update policy using actor-critic or REINFORCE\n",
    "        if self.critic is not None:\n",
    "            loss_info = self.actor_critic_update(z_vectors, total_rewards, log_probs)\n",
    "            policy_loss = loss_info[0]\n",
    "        else:\n",
    "            policy_loss = self.reinforce_update(total_rewards, log_probs)\n",
    "            \n",
    "        # Track best structures\n",
    "        best_idx = np.argmax(total_rewards)\n",
    "\n",
    "        if best_idx >= len(total_rewards):\n",
    "            logger.warning(f\"best_idx {best_idx} out of bounds for total_rewards with length {len(total_rewards)}\")\n",
    "            best_idx = len(total_rewards) # Fallback to first item\n",
    "\n",
    "        print(f\"Type of total_rewards: {type(total_rewards)}\")\n",
    "        print(f\"Shape of total_rewards: {total_rewards.shape if hasattr(total_rewards, 'shape') else 'no shape attribute'}\")\n",
    "        print(f\"Type of total_rewards[best_idx]: {type(total_rewards[best_idx])}\")\n",
    "            \n",
    "        # Fix: Access the scalar value directly without trying to index further\n",
    "        #best_reward = float(total_rewards[best_idx])  # Remove the [0] indexing\n",
    "        reward_value = total_rewards[best_idx]\n",
    "        if isinstance(reward_value, np.ndarray):\n",
    "            if reward_value.size == 1:\n",
    "                best_reward = float(reward_value.item())\n",
    "            else:\n",
    "                # If it's an array with multiple values, take the first one\n",
    "                best_reward = float(reward_value[0])\n",
    "        else:\n",
    "            # If it's already a scalar type (int, float)\n",
    "            best_reward = float(reward_value)\n",
    "\n",
    "        # Determine if this iteration’s best is a new overall best\n",
    "        if len(self.results['best_rewards']) == 0:\n",
    "            is_new_best = True\n",
    "        else:\n",
    "            prev_best = max(self.results['best_rewards'])\n",
    "            # force a Python bool\n",
    "            is_new_best = bool(best_reward > prev_best)\n",
    "\n",
    "        if is_new_best:\n",
    "            best_struct = {\n",
    "                'frac_coords': structures['frac_coords'][best_idx],\n",
    "                'atom_types':  structures['atom_types'][best_idx],\n",
    "                'num_atoms':   structures['num_atoms'][best_idx],\n",
    "                'lengths':     structures['lengths'][best_idx],\n",
    "                'angles':      structures['angles'][best_idx],\n",
    "            }\n",
    "            # optional fields\n",
    "            pccd = structures.get('pred_cart_coord_diff', None)\n",
    "            if pccd is not None:\n",
    "                best_struct['pred_cart_coord_diff'] = pccd[best_idx]\n",
    "            pact = structures.get('pred_atom_types', None)\n",
    "            if pact is not None:\n",
    "                best_struct['pred_atom_types'] = pact[best_idx]\n",
    "\n",
    "            self.results['best_structures'].append(best_struct)\n",
    "\n",
    "        # Store results\n",
    "        self.results['rewards'].append(np.mean(total_rewards))\n",
    "        self.results['formation_energies'].append(np.mean(evaluations['formation_energies']))\n",
    "        self.results['topological_indices'].append(np.mean(evaluations['topological_indices']))\n",
    "        self.results['best_rewards'].append(best_reward)\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(total_rewards),\n",
    "            'max_reward': np.max(total_rewards),\n",
    "            'mean_energy': np.mean(evaluations['formation_energies']),\n",
    "            'policy_loss': policy_loss\n",
    "        }\n",
    "    \n",
    "    def train(self, num_iterations=None):\n",
    "        \"\"\"Train the model for the specified number of iterations.\"\"\"\n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.config.get('num_iterations', 500)\n",
    "            \n",
    "        logger.info(f\"Starting training for {num_iterations} iterations\")\n",
    "        \n",
    "        for iteration in tqdm(range(num_iterations)):\n",
    "            # Perform a training step\n",
    "            step_results = self.train_step()\n",
    "            \n",
    "            # Log progress periodically\n",
    "            if iteration % self.config.get('log_frequency', 10) == 0:\n",
    "                logger.info(\n",
    "                    f\"Iteration {iteration} | \"\n",
    "                    f\"Mean Reward: {step_results['mean_reward']:.4f} | \"\n",
    "                    f\"Max Reward: {step_results['max_reward']:.4f} | \"\n",
    "                    f\"Mean Energy: {step_results['mean_energy']:.4f} | \"\n",
    "                    f\"Policy Loss: {step_results['policy_loss']:.4f}\"\n",
    "                )\n",
    "                \n",
    "            # Save checkpoints periodically\n",
    "            if iteration % self.config.get('save_frequency', 100) == 0 and iteration > 0:\n",
    "                self.save_checkpoint(f\"checkpoint_iter_{iteration}.pt\")\n",
    "                \n",
    "        logger.info(\"Training completed\")\n",
    "        self.save_checkpoint(\"final_checkpoint.pt\")\n",
    "        self.save_results(\"training_results.pkl\")\n",
    "        \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint_dir = self.config.get('checkpoint_dir', './checkpoints')\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'policy_state_dict': self.policy_net.state_dict(),\n",
    "            'policy_optimizer': self.policy_optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'iteration': len(self.results['rewards'])\n",
    "        }\n",
    "        \n",
    "        if self.critic is not None:\n",
    "            checkpoint['critic_state_dict'] = self.critic.state_dict()\n",
    "            checkpoint['critic_optimizer'] = self.critic_optimizer.state_dict()\n",
    "            \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        \n",
    "    def save_results(self, filename):\n",
    "        \"\"\"Save training results.\"\"\"\n",
    "        results_dir = self.config.get('results_dir', './results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        results_path = os.path.join(results_dir, filename)\n",
    "        \n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(self.results, f)\n",
    "            \n",
    "        logger.info(f\"Saved results to {results_path}\")\n",
    "        \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])\n",
    "        self.policy_optimizer.load_state_dict(checkpoint['policy_optimizer'])\n",
    "        \n",
    "        if self.critic is not None and 'critic_state_dict' in checkpoint:\n",
    "            self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "            self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "            \n",
    "        logger.info(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "        return checkpoint.get('iteration', 0)\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for RL-based latent space exploration.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 256], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer for mean\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "        # Learnable log std for exploration\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # def _initialize_weights(self):\n",
    "    #     \"\"\"Initialize network weights.\"\"\"\n",
    "    #     for m in self.modules():\n",
    "    #         if isinstance(m, nn.Linear):\n",
    "    #             nn.init.xavier_normal_(m.weight)\n",
    "    #             if m.bias is not None:\n",
    "    #                 nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "                \n",
    "                # Ensure dtype is correct\n",
    "                m.weight.data = m.weight.data.to(dtype=torch.float32)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = m.bias.data.to(dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, z_noise):\n",
    "        \"\"\"\n",
    "        Forward pass through the policy network.\n",
    "        \n",
    "        Args:\n",
    "            z_noise: Random noise tensor of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            z_sampled: Sampled latent vectors\n",
    "            log_probs: Log probabilities of the sampled vectors\n",
    "        \"\"\"\n",
    "        x = self.fc_layers(z_noise)\n",
    "        mu = self.fc_mu(x)\n",
    "        \n",
    "        # Get standard deviation from learnable parameter\n",
    "        std = torch.exp(self.log_std.clamp(-20, 2))  # Clamp for stability\n",
    "        \n",
    "        # Create normal distribution\n",
    "        dist = Normal(mu, std)\n",
    "        \n",
    "        # Sample using reparameterization trick\n",
    "        z_sampled = dist.rsample()\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        log_probs = dist.log_prob(z_sampled).sum(dim=-1)\n",
    "        \n",
    "        return z_sampled, log_probs\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"Critic network for actor-critic method.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 128], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value output\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the critic network.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent vector of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            value: Predicted value of the state\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class EnergyPredictor(nn.Module):\n",
    "    \"\"\"Surrogate model to predict formation energy from latent space.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value for formation energy\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict formation energy from latent vector.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class TopologicalPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Surrogate model to predict topological invariants (Z2, Chern number) \n",
    "    from latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64], num_invariants=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - multiple values for topological invariants\n",
    "        # For 3D topological insulators, typically 4 Z2 invariants (ν₀;ν₁ν₂ν₃)\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.invariant_head = nn.Linear(input_dim, num_invariants)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict topological invariants from latent vector.\"\"\"\n",
    "        features = self.feature_extractor(z)\n",
    "        # Apply sigmoid to constrain outputs between 0 and 1\n",
    "        # In practice, these would be discretized to 0 or 1 when interpreting\n",
    "        invariants = torch.sigmoid(self.invariant_head(features))\n",
    "        return invariants\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer for more stable training.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size=10000):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def add(self, z, reward, log_prob):\n",
    "        \"\"\"Add experience to buffer.\"\"\"\n",
    "        if len(self.buffer) < self.max_size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (z, reward, log_prob)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        z, rewards, log_probs = map(np.array, zip(*batch))\n",
    "        return z, rewards, log_probs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size.\"\"\"\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.distributions import Normal, kl_divergence\n",
    "import logging\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/cdvae')\n",
    "import cdvae\n",
    "# from cdvae.pl_modules.model import CDVAE\n",
    "# from cdvae.common.data_utils import get_train_val_test_test_loaders\n",
    "# from cdvae.common.data_utils import get_train_val_test_loaders\n",
    "# from cdvae.pl_data.dataset import CDVAEDataset\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CDVAE_TI_Generator:\n",
    "    \"\"\"\n",
    "    Crystal Diffusion Variational Autoencoder (CDVAE) with Reinforcement Learning\n",
    "    for targeted generation of Topological Insulator materials.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.dtype = torch.float32 #set default tensor type to float32\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize CDVAE model components\n",
    "        self.initialize_models()\n",
    "        \n",
    "        # Set up optimizers\n",
    "        self.setup_optimizers()\n",
    "        \n",
    "        # Initialize results tracking\n",
    "        self.results = {\n",
    "            'rewards': [],\n",
    "            'z_gap': [],\n",
    "            'topological_indices': [],\n",
    "            'formation_energies': [],\n",
    "            'best_structures': [],\n",
    "            'best_rewards': [],\n",
    "        }\n",
    "        \n",
    "        # Initialize replay buffer for experience replay\n",
    "        self.replay_buffer = ReplayBuffer(config['buffer_size'])\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize CDVAE encoder, decoder and policy networks.\"\"\"\n",
    "        # Import specific model classes\n",
    "        try:\n",
    "            from cdvae.pl_modules.decoder import GemNetTDecoder\n",
    "            from cdvae.common.data_utils import StandardScalerTorch\n",
    "            from cdvae.common.data_utils import ATOM_TYPES\n",
    "     \n",
    "        except ImportError:\n",
    "            logger.error(\"Failed to import CDVAE modules. Please ensure CDVAE is installed correctly.\")\n",
    "            raise\n",
    "            \n",
    "        # Get dimensions and parameters from config\n",
    "        self.latent_dim = self.config['latent_dim']\n",
    "        self.n_elements = len(self.config['elements']) if 'elements' in self.config else len(ATOM_TYPES.get())\n",
    "        \n",
    "        #TODO: possibly write an encoder file addition to cdvae\n",
    "        # Initialize encoder (if using pre-trained weights)\n",
    "        # if self.config.get('use_encoder', False):\n",
    "        #     self.encoder = GraphEncoder(\n",
    "        #         hidden_dim=self.config['hidden_dim'],\n",
    "        #         latent_dim=self.latent_dim,\n",
    "        #         use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        #     ).to(self.device)\n",
    "            \n",
    "        #     if self.config.get('encoder_checkpoint'):\n",
    "        #         self._load_model(self.encoder, self.config['encoder_checkpoint'])\n",
    "        # else:\n",
    "        #     self.encoder = None\n",
    "\n",
    "        self.encoder = None\n",
    "            \n",
    "        # Initialize decoder\n",
    "        self.decoder = GemNetTDecoder(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dim=self.config['hidden_dim'],\n",
    "            #cutoff=self.config.get('cutoff', 6.0),\n",
    "            max_neighbors=self.config.get('max_neighbors', 20),\n",
    "            #use_layer_norm=self.config.get('use_layer_norm', True)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('decoder_checkpoint'):\n",
    "            self._load_model(self.decoder, self.config['decoder_checkpoint'])\n",
    "\n",
    "        import inspect\n",
    "        print(\"Decoder signature:\", inspect.signature(self.decoder.forward))\n",
    "            \n",
    "        # Initialize policy network for RL\n",
    "        self.policy_net = PolicyNetwork(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('policy_hidden_dims', [256, 256]),\n",
    "            activation=self.config.get('policy_activation', 'relu')\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize critic network for actor-critic methods\n",
    "        if self.config.get('use_critic', True):\n",
    "            self.critic = CriticNetwork(\n",
    "                latent_dim=self.latent_dim,\n",
    "                hidden_dims=self.config.get('critic_hidden_dims', [256, 128]),\n",
    "                activation=self.config.get('critic_activation', 'relu')\n",
    "            ).to(self.device)\n",
    "        else:\n",
    "            self.critic = None\n",
    "            \n",
    "        # DFT surrogate models - predict quantum properties directly from latent space\n",
    "        self.energy_predictor = EnergyPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('energy_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.topological_predictor = TopologicalPredictor(\n",
    "            latent_dim=self.latent_dim,\n",
    "            hidden_dims=self.config.get('topo_predictor_dims', [128, 64])\n",
    "        ).to(self.device)\n",
    "        \n",
    "        if self.config.get('surrogate_checkpoint'):\n",
    "            self._load_surrogate_models(self.config['surrogate_checkpoint'])\n",
    "        \n",
    "    def setup_optimizers(self):\n",
    "        \"\"\"Set up optimizers for different components.\"\"\"\n",
    "        # Policy optimizer\n",
    "        self.policy_optimizer = torch.optim.Adam(\n",
    "            self.policy_net.parameters(),\n",
    "            lr=self.config.get('policy_lr', 1e-4),\n",
    "            weight_decay=self.config.get('policy_weight_decay', 1e-6)\n",
    "        )\n",
    "        \n",
    "        # Critic optimizer (if using actor-critic)\n",
    "        if self.critic is not None:\n",
    "            self.critic_optimizer = torch.optim.Adam(\n",
    "                self.critic.parameters(),\n",
    "                lr=self.config.get('critic_lr', 3e-4),\n",
    "                weight_decay=self.config.get('critic_weight_decay', 1e-6)\n",
    "            )\n",
    "        \n",
    "        # Surrogate model optimizers for fine-tuning\n",
    "        if self.config.get('train_surrogates', False):\n",
    "            self.energy_optimizer = torch.optim.Adam(\n",
    "                self.energy_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "            self.topo_optimizer = torch.optim.Adam(\n",
    "                self.topological_predictor.parameters(),\n",
    "                lr=self.config.get('surrogate_lr', 1e-4)\n",
    "            )\n",
    "            \n",
    "    def _load_model(self, model, checkpoint_path):\n",
    "        \"\"\"Load model weights from checkpoint.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            if 'state_dict' in checkpoint:\n",
    "                # Handle pytorch-lightning checkpoints\n",
    "                state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items() \n",
    "                              if k.startswith('model.')}\n",
    "                model.load_state_dict(state_dict, strict=False)\n",
    "            else:\n",
    "                # Handle regular torch checkpoints\n",
    "                model.load_state_dict(checkpoint, strict=False)\n",
    "            logger.info(f\"Loaded weights from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load weights: {e}\")\n",
    "            \n",
    "    def _load_surrogate_models(self, checkpoint_path):\n",
    "        \"\"\"Load surrogate model weights.\"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "            self.energy_predictor.load_state_dict(checkpoint['energy_predictor'])\n",
    "            self.topological_predictor.load_state_dict(checkpoint['topo_predictor'])\n",
    "            logger.info(f\"Loaded surrogate models from {checkpoint_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load surrogate models: {e}\")\n",
    "    \n",
    "    def generate_structures(self, batch_size=None):\n",
    "        \"\"\"Generate crystal structures using the policy network and decoder.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = self.config.get('batch_size', 32)\n",
    "                \n",
    "        # Sample latent vectors from the policy network\n",
    "        z_noise = torch.randn(batch_size, self.latent_dim, device=self.device, dtype=self.dtype)\n",
    "        z_sampled, log_probs = self.policy_net(z_noise)\n",
    "        \n",
    "        # For testing, let's use a smaller batch size and fewer atoms per crystal\n",
    "        max_atoms = 8  # Small number of atoms per crystal for testing\n",
    "        \n",
    "        # Create a batch where each structure has a different number of atoms\n",
    "        num_atoms = torch.randint(2, max_atoms+1, (batch_size,), device=self.device)\n",
    "    \n",
    "        # Create tensors with proper dimensions\n",
    "        total_atoms = num_atoms.sum().item()\n",
    "        \n",
    "        # Create a batch index (for tracking purposes, not passed to decoder)\n",
    "        batch_idx = torch.repeat_interleave(\n",
    "            torch.arange(batch_size, device=self.device), \n",
    "            num_atoms\n",
    "        )\n",
    "        \n",
    "        # Random fractional coordinates for each atom (values between 0 and 1)\n",
    "        frac_coords = torch.rand(total_atoms, 3, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Random atom types\n",
    "        atom_types = torch.randint(0, self.n_elements + 1, (total_atoms,), device=self.device)\n",
    "        \n",
    "        # Random unit cell parameters\n",
    "        lengths = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 5 + 5  # Between 5-10 Å\n",
    "        angles = torch.rand(batch_size, 3, device=self.device, dtype=self.dtype) * 30 + 90  # Between 90-120°\n",
    "\n",
    "        print(\"z_sampled.shape:\", z_sampled.shape)\n",
    "        print(\"frac_coords.shape:\", frac_coords.shape)\n",
    "        print(\"atom_types.shape:\", atom_types.shape,\n",
    "            \"   max atom_types:\", atom_types.max().item(),\n",
    "            \"   n_elements:\", self.n_elements)\n",
    "        print(\"num_atoms.shape:\", num_atoms.shape,\n",
    "            \"   sum num_atoms:\", num_atoms.sum().item())\n",
    "        print(\"lengths.shape:\", lengths.shape)\n",
    "        print(\"angles.shape:\", angles.shape)\n",
    "\n",
    "    \n",
    "        # Generate structures using the decoder\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                # Remove batch_idx from the arguments - decoder doesn't expect it\n",
    "                pred_cart_coord_diff, pred_atom_types = self.decoder(\n",
    "                    z_sampled,\n",
    "                    frac_coords,\n",
    "                    atom_types,\n",
    "                    num_atoms,\n",
    "                    lengths,\n",
    "                    angles\n",
    "                )\n",
    "                \n",
    "                # Combine the results\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,  # Still store it for reference\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles,\n",
    "                    'pred_cart_coord_diff': pred_cart_coord_diff,\n",
    "                    'pred_atom_types': pred_atom_types\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error in decoder: {e}\")\n",
    "                # Add more debug information if needed\n",
    "                generated_structures = {\n",
    "                    'batch_idx': batch_idx,\n",
    "                    'frac_coords': frac_coords,\n",
    "                    'atom_types': atom_types,\n",
    "                    'num_atoms': num_atoms,\n",
    "                    'lengths': lengths,\n",
    "                    'angles': angles\n",
    "                }\n",
    "            \n",
    "        return generated_structures, z_sampled, log_probs\n",
    "    \n",
    "    def evaluate_structures(self, structures, z_vectors):\n",
    "        \"\"\"Evaluate generated structures using surrogate models.\"\"\"\n",
    "        # Predict formation energies\n",
    "        with torch.no_grad():\n",
    "            energies = self.energy_predictor(z_vectors)\n",
    "            \n",
    "            # Predict topological indices (Z2 invariants, Chern numbers, etc.)\n",
    "            topo_indices = self.topological_predictor(z_vectors)\n",
    "            \n",
    "            # Calculate band gaps (can be part of the topological predictor or separate)\n",
    "            band_gaps = self.estimate_band_gap(structures, z_vectors)\n",
    "            \n",
    "        # Combine predictions into a comprehensive evaluation\n",
    "        evaluations = {\n",
    "            'formation_energies': energies.cpu().numpy(),\n",
    "            'topological_indices': topo_indices.cpu().numpy(),\n",
    "            'band_gaps': band_gaps.cpu().numpy() if isinstance(band_gaps, torch.Tensor) else band_gaps\n",
    "        }\n",
    "        \n",
    "        return evaluations\n",
    "    \n",
    "    def calculate_rewards(self, evaluations):\n",
    "        \"\"\"Calculate rewards based on desired material properties.\"\"\"\n",
    "        # Extract evaluations\n",
    "        energies = evaluations['formation_energies']\n",
    "        topo_indices = evaluations['topological_indices']\n",
    "        band_gaps = evaluations['band_gaps']\n",
    "\n",
    "        energies  = np.array(energies).squeeze()  \n",
    "        band_gaps = np.array(band_gaps).squeeze()  \n",
    "        \n",
    "        # Convert to numpy for easier manipulation\n",
    "        if isinstance(energies, torch.Tensor):\n",
    "            energies = energies.cpu().numpy().squeeze()\n",
    "        if isinstance(topo_indices, torch.Tensor):\n",
    "            topo_indices = topo_indices.cpu().numpy()\n",
    "        if isinstance(band_gaps, torch.Tensor):\n",
    "            band_gaps = band_gaps.cpu().numpy().squeeze()\n",
    "            \n",
    "        # Calculate stability reward component\n",
    "        # Lower formation energy is better, but must be below threshold to be stable\n",
    "        # stability_threshold = self.config.get('stability_threshold', 0.1)\n",
    "        # stability_rewards = -energies * (energies < stability_threshold)\n",
    "\n",
    "        stability_rewards = -energies * (energies < self.config['stability_threshold'])\n",
    "        \n",
    "        # Calculate topological reward component\n",
    "        # For Z2 invariants, we typically want (1;000) for 3D TIs\n",
    "        # This is a simplified example - actual implementation depends on how topo_indices are represented\n",
    "        topo_rewards = np.sum(topo_indices * self.config.get('topo_weights'), axis=1)\n",
    "        \n",
    "        # Calculate band gap reward component\n",
    "        # Usually want a moderate band gap (not too small, not too large)\n",
    "        # target_gap = self.config.get('target_band_gap', 0.3)  # in eV\n",
    "        # gap_tolerance = self.config.get('gap_tolerance', 0.2)  # in eV\n",
    "        # gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target_gap) / gap_tolerance, 1.0)\n",
    "\n",
    "        target = self.config['target_band_gap']\n",
    "        tol    = self.config['gap_tolerance']\n",
    "        gap_rewards = 1.0 - np.minimum(np.abs(band_gaps - target) / tol, 1.0)\n",
    "        \n",
    "        combined_rewards = ( self.config['w_stability']   * stability_rewards\n",
    "                       + self.config['w_topological'] * topo_rewards\n",
    "                       + self.config['w_gap']         * gap_rewards )\n",
    "        \n",
    "        # Combine reward components with configurable weights\n",
    "        # w_stability = self.config.get('w_stability', 1.0)\n",
    "        # w_topological = self.config.get('w_topological', 2.0)\n",
    "        # w_gap = self.config.get('w_gap', 1.5)\n",
    "        \n",
    "        # combined_rewards = (w_stability * stability_rewards + \n",
    "        #                    w_topological * topo_rewards +\n",
    "        #                    w_gap * gap_rewards)\n",
    "        \n",
    "        # Create rewards dictionary\n",
    "        rewards_dict = {\n",
    "            'total': combined_rewards,\n",
    "            'stability': stability_rewards,\n",
    "            'topological': topo_rewards,\n",
    "            'band_gap': gap_rewards\n",
    "        }\n",
    "        \n",
    "        return rewards_dict\n",
    "    \n",
    "    def estimate_band_gap(self, structures, z_vectors):\n",
    "        \"\"\"Estimate band gaps of structures using a surrogate model.\"\"\"\n",
    "        # This would typically be a separate model or part of topological_predictor\n",
    "        # For simplicity, we'll use a mock implementation\n",
    "        batch_size = z_vectors.shape[0]\n",
    "        \n",
    "        # Mock band gap estimation (replace with actual model)\n",
    "        # In practice, this would use a trained neural network or other predictor\n",
    "        gaps = 0.2 + 0.3 * torch.sigmoid(z_vectors[:, 0]) + 0.1 * torch.randn(batch_size).to(self.device)\n",
    "        \n",
    "        return gaps\n",
    "    \n",
    "    def reinforce_update(self, rewards, log_probs):\n",
    "        \"\"\"Update policy network using REINFORCE algorithm.\"\"\"\n",
    "        # Convert to tensor with the right dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Normalize rewards\n",
    "        rewards_normalized = (rewards_tensor - rewards_tensor.mean()) / (rewards_tensor.std() + 1e-8)\n",
    "        \n",
    "        # Calculate policy loss\n",
    "        policy_loss = -(log_probs * rewards_normalized).mean()\n",
    "        \n",
    "        # Update policy\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        \n",
    "        # Optional gradient clipping\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            \n",
    "        self.policy_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item()\n",
    "    \n",
    "    def actor_critic_update(self, z_vectors, rewards, log_probs):\n",
    "        \"\"\"Update policy and critic networks using Actor-Critic algorithm.\"\"\"\n",
    "        if self.critic is None:\n",
    "            return self.reinforce_update(rewards, log_probs)\n",
    "            \n",
    "        # Convert rewards to tensor with proper dtype\n",
    "        rewards_tensor = torch.tensor(rewards, device=self.device, dtype=self.dtype)\n",
    "        \n",
    "        # Get critic's value predictions\n",
    "        value_predictions = self.critic(z_vectors).squeeze()\n",
    "        \n",
    "        # Calculate advantages\n",
    "        advantages = rewards_tensor - value_predictions.detach()\n",
    "        \n",
    "        # Calculate policy (actor) loss\n",
    "        policy_loss = -(log_probs * advantages).mean()\n",
    "        \n",
    "        # Calculate value (critic) loss\n",
    "        critic_loss = F.mse_loss(value_predictions, rewards_tensor)\n",
    "        \n",
    "        # Option 1: Combine losses and do a single backward pass\n",
    "        total_loss = policy_loss + critic_loss\n",
    "        \n",
    "        # Zero all gradients\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        \n",
    "        # Single backward pass\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Apply gradient clipping if needed\n",
    "        if self.config.get('clip_grad', False):\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.policy_net.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.critic.parameters(), \n",
    "                self.config.get('max_grad_norm', 1.0)\n",
    "            )\n",
    "        \n",
    "        # Update both networks\n",
    "        self.policy_optimizer.step()\n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        return policy_loss.item(), critic_loss.item()\n",
    "    \n",
    "    def train_step(self):\n",
    "        \"\"\"Perform a single training step.\"\"\"\n",
    "        # Generate structures\n",
    "        structures, z_vectors, log_probs = self.generate_structures()\n",
    "        print(len(structures))\n",
    "\n",
    "        if not structures: \n",
    "            logger.error(\"no strucutres generated in this step\")\n",
    "            return  {'mean_reward': 0, 'max_reward': 0, 'mean_energy': 0, 'policy_loss': 0}\n",
    "        \n",
    "        # Evaluate structures\n",
    "        evaluations = self.evaluate_structures(structures, z_vectors)\n",
    "        \n",
    "        # Calculate rewards\n",
    "        rewards_dict = self.calculate_rewards(evaluations)\n",
    "        total_rewards = rewards_dict['total']\n",
    "        \n",
    "        # Store experience in replay buffer\n",
    "        for i in range(len(total_rewards)):\n",
    "            self.replay_buffer.add(\n",
    "                z_vectors[i].detach().cpu().numpy(),\n",
    "                total_rewards[i],\n",
    "                log_probs[i].detach().cpu().numpy()\n",
    "            )\n",
    "        \n",
    "        # Update policy using actor-critic or REINFORCE\n",
    "        if self.critic is not None:\n",
    "            loss_info = self.actor_critic_update(z_vectors, total_rewards, log_probs)\n",
    "            policy_loss = loss_info[0]\n",
    "        else:\n",
    "            policy_loss = self.reinforce_update(total_rewards, log_probs)\n",
    "            \n",
    "        # Track best structures\n",
    "        best_idx = np.argmax(total_rewards)\n",
    "\n",
    "        if best_idx >= len(total_rewards):\n",
    "            logger.warning(f\"best_idx {best_idx} out of bounds for total_rewards with length {len(total_rewards)}\")\n",
    "            best_idx = len(total_rewards) # Fallback to first item\n",
    "\n",
    "        print(f\"Type of total_rewards: {type(total_rewards)}\")\n",
    "        print(f\"Shape of total_rewards: {total_rewards.shape if hasattr(total_rewards, 'shape') else 'no shape attribute'}\")\n",
    "        print(f\"Type of total_rewards[best_idx]: {type(total_rewards[best_idx])}\")\n",
    "            \n",
    "        # Fix: Access the scalar value directly without trying to index further\n",
    "        #best_reward = float(total_rewards[best_idx])  # Remove the [0] indexing\n",
    "        reward_value = total_rewards[best_idx]\n",
    "        if isinstance(reward_value, np.ndarray):\n",
    "            if reward_value.size == 1:\n",
    "                best_reward = float(reward_value.item())\n",
    "            else:\n",
    "                # If it's an array with multiple values, take the first one\n",
    "                best_reward = float(reward_value[0])\n",
    "        else:\n",
    "            # If it's already a scalar type (int, float)\n",
    "            best_reward = float(reward_value)\n",
    "\n",
    "        # Determine if this iteration’s best is a new overall best\n",
    "        if len(self.results['best_rewards']) == 0:\n",
    "            is_new_best = True\n",
    "        else:\n",
    "            prev_best = max(self.results['best_rewards'])\n",
    "            # force a Python bool\n",
    "            is_new_best = bool(best_reward > prev_best)\n",
    "\n",
    "        if is_new_best:\n",
    "            best_struct = {\n",
    "                'frac_coords': structures['frac_coords'][best_idx],\n",
    "                'atom_types':  structures['atom_types'][best_idx],\n",
    "                'num_atoms':   structures['num_atoms'][best_idx],\n",
    "                'lengths':     structures['lengths'][best_idx],\n",
    "                'angles':      structures['angles'][best_idx],\n",
    "            }\n",
    "            # optional fields\n",
    "            pccd = structures.get('pred_cart_coord_diff', None)\n",
    "            if pccd is not None:\n",
    "                best_struct['pred_cart_coord_diff'] = pccd[best_idx]\n",
    "            pact = structures.get('pred_atom_types', None)\n",
    "            if pact is not None:\n",
    "                best_struct['pred_atom_types'] = pact[best_idx]\n",
    "\n",
    "            self.results['best_structures'].append(best_struct)\n",
    "\n",
    "        # Store results\n",
    "        self.results['rewards'].append(np.mean(total_rewards))\n",
    "        self.results['formation_energies'].append(np.mean(evaluations['formation_energies']))\n",
    "        self.results['topological_indices'].append(np.mean(evaluations['topological_indices']))\n",
    "        self.results['best_rewards'].append(best_reward)\n",
    "        \n",
    "        return {\n",
    "            'mean_reward': np.mean(total_rewards),\n",
    "            'max_reward': np.max(total_rewards),\n",
    "            'mean_energy': np.mean(evaluations['formation_energies']),\n",
    "            'policy_loss': policy_loss\n",
    "        }\n",
    "    \n",
    "    def train(self, num_iterations=None):\n",
    "        \"\"\"Train the model for the specified number of iterations.\"\"\"\n",
    "        if num_iterations is None:\n",
    "            num_iterations = self.config.get('num_iterations', 500)\n",
    "            \n",
    "        logger.info(f\"Starting training for {num_iterations} iterations\")\n",
    "        \n",
    "        for iteration in tqdm(range(num_iterations)):\n",
    "            # Perform a training step\n",
    "            step_results = self.train_step()\n",
    "            \n",
    "            # Log progress periodically\n",
    "            if iteration % self.config.get('log_frequency', 10) == 0:\n",
    "                logger.info(\n",
    "                    f\"Iteration {iteration} | \"\n",
    "                    f\"Mean Reward: {step_results['mean_reward']:.4f} | \"\n",
    "                    f\"Max Reward: {step_results['max_reward']:.4f} | \"\n",
    "                    f\"Mean Energy: {step_results['mean_energy']:.4f} | \"\n",
    "                    f\"Policy Loss: {step_results['policy_loss']:.4f}\"\n",
    "                )\n",
    "                \n",
    "            # Save checkpoints periodically\n",
    "            if iteration % self.config.get('save_frequency', 100) == 0 and iteration > 0:\n",
    "                self.save_checkpoint(f\"checkpoint_iter_{iteration}.pt\")\n",
    "                \n",
    "        logger.info(\"Training completed\")\n",
    "        self.save_checkpoint(\"final_checkpoint.pt\")\n",
    "        self.save_results(\"training_results.pkl\")\n",
    "        \n",
    "    def save_checkpoint(self, filename):\n",
    "        \"\"\"Save model checkpoint.\"\"\"\n",
    "        checkpoint_dir = self.config.get('checkpoint_dir', './checkpoints')\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "        \n",
    "        checkpoint = {\n",
    "            'policy_state_dict': self.policy_net.state_dict(),\n",
    "            'policy_optimizer': self.policy_optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'iteration': len(self.results['rewards'])\n",
    "        }\n",
    "        \n",
    "        if self.critic is not None:\n",
    "            checkpoint['critic_state_dict'] = self.critic.state_dict()\n",
    "            checkpoint['critic_optimizer'] = self.critic_optimizer.state_dict()\n",
    "            \n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        logger.info(f\"Saved checkpoint to {checkpoint_path}\")\n",
    "        \n",
    "    def save_results(self, filename):\n",
    "        \"\"\"Save training results.\"\"\"\n",
    "        results_dir = self.config.get('results_dir', './results')\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        \n",
    "        results_path = os.path.join(results_dir, filename)\n",
    "        \n",
    "        with open(results_path, 'wb') as f:\n",
    "            pickle.dump(self.results, f)\n",
    "            \n",
    "        logger.info(f\"Saved results to {results_path}\")\n",
    "        \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        \"\"\"Load model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])\n",
    "        self.policy_optimizer.load_state_dict(checkpoint['policy_optimizer'])\n",
    "        \n",
    "        if self.critic is not None and 'critic_state_dict' in checkpoint:\n",
    "            self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "            self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer'])\n",
    "            \n",
    "        logger.info(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "        return checkpoint.get('iteration', 0)\n",
    "\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    \"\"\"Policy network for RL-based latent space exploration.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 256], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer for mean\n",
    "        self.fc_layers = nn.Sequential(*layers)\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        \n",
    "        # Learnable log std for exploration\n",
    "        self.log_std = nn.Parameter(torch.zeros(latent_dim))\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    # def _initialize_weights(self):\n",
    "    #     \"\"\"Initialize network weights.\"\"\"\n",
    "    #     for m in self.modules():\n",
    "    #         if isinstance(m, nn.Linear):\n",
    "    #             nn.init.xavier_normal_(m.weight)\n",
    "    #             if m.bias is not None:\n",
    "    #                 nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "                \n",
    "                # Ensure dtype is correct\n",
    "                m.weight.data = m.weight.data.to(dtype=torch.float32)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data = m.bias.data.to(dtype=torch.float32)\n",
    "    \n",
    "    def forward(self, z_noise):\n",
    "        \"\"\"\n",
    "        Forward pass through the policy network.\n",
    "        \n",
    "        Args:\n",
    "            z_noise: Random noise tensor of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            z_sampled: Sampled latent vectors\n",
    "            log_probs: Log probabilities of the sampled vectors\n",
    "        \"\"\"\n",
    "        x = self.fc_layers(z_noise)\n",
    "        mu = self.fc_mu(x)\n",
    "        \n",
    "        # Get standard deviation from learnable parameter\n",
    "        std = torch.exp(self.log_std.clamp(-20, 2))  # Clamp for stability\n",
    "        \n",
    "        # Create normal distribution\n",
    "        dist = Normal(mu, std)\n",
    "        \n",
    "        # Sample using reparameterization trick\n",
    "        z_sampled = dist.rsample()\n",
    "        \n",
    "        # Calculate log probabilities\n",
    "        log_probs = dist.log_prob(z_sampled).sum(dim=-1)\n",
    "        \n",
    "        return z_sampled, log_probs\n",
    "\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    \"\"\"Critic network for actor-critic method.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[256, 128], activation='relu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Map activation function string to actual function\n",
    "        act_fn = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(0.2),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'silu': nn.SiLU()\n",
    "        }.get(activation.lower(), nn.ReLU())\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(act_fn)\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value output\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # Apply weight initialization\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Forward pass through the critic network.\n",
    "        \n",
    "        Args:\n",
    "            z: Latent vector of shape [batch_size, latent_dim]\n",
    "            \n",
    "        Returns:\n",
    "            value: Predicted value of the state\n",
    "        \"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class EnergyPredictor(nn.Module):\n",
    "    \"\"\"Surrogate model to predict formation energy from latent space.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - single value for formation energy\n",
    "        layers.append(nn.Linear(input_dim, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict formation energy from latent vector.\"\"\"\n",
    "        return self.model(z)\n",
    "\n",
    "\n",
    "class TopologicalPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Surrogate model to predict topological invariants (Z2, Chern number) \n",
    "    from latent space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, hidden_dims=[128, 64], num_invariants=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Build network layers\n",
    "        layers = []\n",
    "        input_dim = latent_dim\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "            \n",
    "        # Output layer - multiple values for topological invariants\n",
    "        # For 3D topological insulators, typically 4 Z2 invariants (ν₀;ν₁ν₂ν₃)\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.invariant_head = nn.Linear(input_dim, num_invariants)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"Predict topological invariants from latent vector.\"\"\"\n",
    "        features = self.feature_extractor(z)\n",
    "        # Apply sigmoid to constrain outputs between 0 and 1\n",
    "        # In practice, these would be discretized to 0 or 1 when interpreting\n",
    "        invariants = torch.sigmoid(self.invariant_head(features))\n",
    "        return invariants\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Experience replay buffer for more stable training.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_size=10000):\n",
    "        self.max_size = max_size\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def add(self, z, reward, log_prob):\n",
    "        \"\"\"Add experience to buffer.\"\"\"\n",
    "        if len(self.buffer) < self.max_size:\n",
    "            self.buffer.append(None)\n",
    "        self.buffer[self.position] = (z, reward, log_prob)\n",
    "        self.position = (self.position + 1) % self.max_size\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\"\"\"\n",
    "        batch = random.sample(self.buffer, min(batch_size, len(self.buffer)))\n",
    "        z, rewards, log_probs = map(np.array, zip(*batch))\n",
    "        return z, rewards, log_probs\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Return current buffer size.\"\"\"\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
