{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def randomSeed(random_seed):\n",
    "\t\"\"\"Given a random seed, this will help reproduce results across runs\"\"\"\n",
    "\tif random_seed is not None:\n",
    "\t\ttorch.manual_seed(random_seed)\n",
    "\t\tif torch.cuda.is_available():\n",
    "\t\t\ttorch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "\n",
    "def getActivation(activation):\n",
    "\tif activation == 'softplus':\n",
    "\t\treturn nn.Softplus()\n",
    "\telif activation == 'relu':\n",
    "\t\treturn nn.ReLU()\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "\t\"\"\"\n",
    "\tConvolutional operation on graphs\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, atom_fea_len, nbr_fea_len, random_seed=None, activation='relu'):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize ConvLayer.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\n",
    "\t\tatom_fea_len: int\n",
    "\t\t\tNumber of atom hidden features.\n",
    "\t\tnbr_fea_len: int\n",
    "\t\t\tNumber of bond features.\n",
    "\t\trandom_seed: int\n",
    "\t\t\tSeed to reproduce consistent runs\n",
    "\t\tactivation: string ('relu' or 'softplus')\n",
    "\t\t\tDecides the activation function\n",
    "\t\t\"\"\"\n",
    "\t\trandomSeed(random_seed)\n",
    "\t\tsuper(ConvLayer, self).__init__()\n",
    "\t\tself.atom_fea_len = atom_fea_len\n",
    "\t\tself.nbr_fea_len = nbr_fea_len\n",
    "\t\tself.fc_full = nn.Linear(2 * self.atom_fea_len + self.nbr_fea_len,\n",
    "\t\t\t\t\t\t\t\t 2 * self.atom_fea_len)\n",
    "\t\tself.sigmoid = nn.Sigmoid()\n",
    "\t\tself.activation1 = getActivation(activation)\n",
    "\t\tself.bn1 = nn.BatchNorm1d(2 * self.atom_fea_len)\n",
    "\t\tself.bn2 = nn.BatchNorm1d(self.atom_fea_len)\n",
    "\t\tself.activation2 = getActivation(activation)\n",
    "\n",
    "\tdef forward(self, atom_in_fea, nbr_fea, nbr_fea_idx):\n",
    "\t\t\"\"\"\n",
    "\t\tForward pass\n",
    "\n",
    "\t\tN: Total number of atoms in the batch\n",
    "\t\tM: Max number of neighbors\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\n",
    "\t\tatom_in_fea: Variable(torch.Tensor) shape (N, atom_fea_len)\n",
    "\t\t  Atom hidden features before convolution\n",
    "\t\tnbr_fea: Variable(torch.Tensor) shape (N, M, nbr_fea_len)\n",
    "\t\t  Bond features of each atom's M neighbors\n",
    "\t\tnbr_fea_idx: torch.LongTensor shape (N, M)\n",
    "\t\t  Indices of M neighbors of each atom\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\n",
    "\t\tatom_out_fea: nn.Variable shape (N, atom_fea_len)\n",
    "\t\t  Atom hidden features after convolution\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t# TODO will there be problems with the index zero padding?\n",
    "\t\tN, M = nbr_fea_idx.shape\n",
    "\t\t# convolution\n",
    "\t\tatom_nbr_fea = atom_in_fea[nbr_fea_idx, :]\t\t# [N, M, atom_fea_len]\n",
    "\t\ttotal_nbr_fea = torch.cat(\n",
    "\t\t\t[atom_in_fea.unsqueeze(1).expand(N, M, self.atom_fea_len),\n",
    "\t\t\t atom_nbr_fea, nbr_fea], dim=2)\t\t# [N, M, nbr_fea_len + 2*atom_fea_len]\n",
    "\t\ttotal_gated_fea = self.fc_full(total_nbr_fea)\t\t# [N, M, 2*atom_fea_len]\n",
    "\t\ttotal_gated_fea = self.bn1(total_gated_fea.view(\n",
    "\t\t\t-1, self.atom_fea_len * 2)).view(N, M, self.atom_fea_len * 2)\n",
    "\t\tnbr_filter, nbr_core = total_gated_fea.chunk(2, dim=2)\t\t# [N, M, atom_fea_len] each\n",
    "\t\tnbr_filter = self.sigmoid(nbr_filter)\n",
    "\t\tnbr_core = self.activation1(nbr_core)\n",
    "\t\tnbr_sumed = torch.sum(nbr_filter * nbr_core, dim=1)\t\t# [N, atom_fea_len]\n",
    "\t\tnbr_sumed = self.bn2(nbr_sumed)\n",
    "\t\tout = self.activation2(atom_in_fea + nbr_sumed)\n",
    "\t\treturn out\n",
    "\n",
    "\n",
    "class MTCGCNN(nn.Module):\n",
    "\t\"\"\"\n",
    "\tCreate a multi-task crystal graph convolutional neural network for predicting multiple\n",
    "\tmaterial properties.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, orig_atom_fea_len, nbr_fea_len,\n",
    "\t\t\t\t\tatom_fea_len=64, n_conv=3, h_fea_len=128, n_p=1, activation='softplus',\n",
    "\t\t\t\t\trandom_seed=None, hard_parameter_sharing=True, n_hp=1, dropout=0):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize MTCGCNN.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\n",
    "\t\torig_atom_fea_len: int\n",
    "\t\t\tNumber of atom features in the input.\n",
    "\t\tnbr_fea_len: int\n",
    "\t\t\tNumber of bond features.\n",
    "\t\tatom_fea_len: int\n",
    "\t\t\tNumber of hidden atom features in the convolutional layers\n",
    "\t\tn_conv: int\n",
    "\t\t\tNumber of convolutional layers\n",
    "\t\th_fea_len: int\n",
    "\t\t\tNumber of hidden features after pooling\n",
    "\t\tn_p: int\n",
    "\t\t\tNumber of final output nodes, equivalent to the number of properties\n",
    "\t\t\tpredicting (for regression case)\n",
    "\t\trandom_seed: int\n",
    "\t\t\tSeed to reproduce consistent runs\n",
    "\t\thard_parameter_sharing: int\n",
    "\t\t\tThis shares the embedding network across various multi-property prediction\n",
    "\t\t\tand has self defined linear layers for each property in the end. NOTE that\n",
    "\t\t\tthis is the most sensible way or using multitasking (otherwise, one single\n",
    "\t\t\tlayer at the end might overfit to the training set badly)\n",
    "\t\tn_hp: int\n",
    "\t\t\tNumber of hidden layers in the hard parameter sharing level.\n",
    "\t\tactivation: string ('relu' or 'softplus')\n",
    "\t\t\tDecides the activation function\n",
    "\t\tdropout: fraction of nodes to dropout every forward iteration while training\n",
    "\t\t\"\"\"\n",
    "\t\trandomSeed(random_seed)\n",
    "\t\tsuper(MTCGCNN, self).__init__()\n",
    "\t\tself.hard_parameter_sharing = hard_parameter_sharing\n",
    "\t\tself.num_outputs = n_p\n",
    "\t\tself.embedding = nn.Linear(orig_atom_fea_len, atom_fea_len)\n",
    "\t\tself.convs = nn.ModuleList([ConvLayer(atom_fea_len=atom_fea_len,\n",
    "\t\t\t\t\t\t\t\t\t\t\t  nbr_fea_len=nbr_fea_len, random_seed=random_seed,\n",
    "\t\t\t\t\t\t\t\t\t\t\t  activation=activation)\n",
    "\t\t\t\t\t\t\t\t\tfor _ in range(n_conv)])\n",
    "\t\tself.dropout1 = nn.Dropout(p=dropout)\n",
    "\n",
    "\t\tif self.hard_parameter_sharing:\n",
    "\t\t\tself.conv_to_fc = nn.ModuleList([nn.Linear(atom_fea_len, h_fea_len)\\\n",
    "\t\t\t\t\t\t\t\t\tfor _ in range(self.num_outputs)])\n",
    "\t\t\tself.conv_to_fc_activation = nn.ModuleList([getActivation(activation) for _ in range(self.num_outputs)])\n",
    "\t\t\tif n_hp > 1:\n",
    "\t\t\t\tself.fc_hp = nn.ModuleList([\n",
    "\t\t\t\t\t\t\t\tnn.ModuleList([nn.Linear(h_fea_len, h_fea_len) for _ in range(n_hp - 1)])\n",
    "\t\t\t\t\t\t\t\t\tfor _ in range(self.num_outputs)])\n",
    "\t\t\t\tself.fc_activation = nn.ModuleList([\n",
    "\t\t\t\t\t\t\t\tnn.ModuleList([getActivation(activation) for _ in range(n_hp - 1)])\n",
    "\t\t\t\t\t\t\t\t\tfor _ in range(self.num_outputs)])\n",
    "\t\t\tself.fc_out = nn.ModuleList([nn.Linear(h_fea_len, 1) for _ in range(self.num_outputs)])\n",
    "\t\telse:\n",
    "\t\t\tself.conv_to_fc = nn.Linear(atom_fea_len, h_fea_len)\n",
    "\t\t\tself.conv_to_fc_activation = getActivation(activation)\n",
    "\t\t\tself.fc_out = nn.Linear(h_fea_len, self.num_outputs)\n",
    "\n",
    "\tdef forward(self, atom_fea, nbr_fea, nbr_fea_idx, crystal_atom_idx):\n",
    "\t\t\"\"\"\n",
    "\t\tForward pass\n",
    "\n",
    "\t\tN: Total number of atoms in the batch\n",
    "\t\tM: Max number of neighbors\n",
    "\t\tN0: Total number of crystals in the batch\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\n",
    "\t\tatom_fea: Variable(torch.Tensor) shape (N, orig_atom_fea_len)\n",
    "\t\t  Atom features from atom type\n",
    "\t\tnbr_fea: Variable(torch.Tensor) shape (N, M, nbr_fea_len)\n",
    "\t\t  Bond features of each atom's M neighbors\n",
    "\t\tnbr_fea_idx: torch.LongTensor shape (N, M)\n",
    "\t\t  Indices of M neighbors of each atom\n",
    "\t\tcrystal_atom_idx: list of torch.LongTensor of length N0\n",
    "\t\t  Mapping from the crystal idx to atom idx\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\n",
    "\t\tprediction: nn.Variable shape (N, )\n",
    "\t\t  Atom hidden features after convolution\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tatom_fea = self.embedding(atom_fea)\n",
    "\t\tfor conv_func in self.convs:\n",
    "\t\t\tatom_fea = conv_func(atom_fea, nbr_fea, nbr_fea_idx)\n",
    "\t\tcrys_fea = self.pooling(atom_fea, crystal_atom_idx)\n",
    "\t\tcrys_fea = self.dropout1(crys_fea)\n",
    "\t\t# crys_fea is the descriptor of the crystal which is shared by all the further tasks\n",
    "\n",
    "\t\tif self.hard_parameter_sharing:\n",
    "\t\t\tcrys_features = [self.conv_to_fc[i](self.conv_to_fc_activation[i](crys_fea))\\\n",
    "\t\t\t\t\t\t\t\tfor i in range(self.num_outputs)]\n",
    "\t\t\tcrys_features = [self.conv_to_fc_activation[i](crys_features[i]) for i in range(self.num_outputs)]\n",
    "\n",
    "\t\t\t# get the processed feature vectors using which we get the outputs\n",
    "\t\t\tprocessed_features = []\n",
    "\t\t\tfor i in range(self.num_outputs):\n",
    "\t\t\t\tout_val = crys_features[i]\n",
    "\t\t\t\tif hasattr(self, 'fc_hp'):\n",
    "\t\t\t\t\tfor fc, activation in zip(self.fc_hp[i], self.fc_activation[i]):\n",
    "\t\t\t\t\t\tout_val = activation(fc(out_val))\n",
    "\t\t\t\tprocessed_features.append(out_val)\n",
    "\n",
    "\t\t\t# final output layer\n",
    "\t\t\tout = [self.fc_out[i](processed_features[i]) for i in range(self.num_outputs)]\n",
    "\t\t\tout = torch.cat(out, 1)\n",
    "\t\telse:\n",
    "\t\t\tcrys_fea = self.conv_to_fc(self.conv_to_fc_activation(crys_fea))\n",
    "\t\t\tcrys_fea = self.conv_to_fc_activation(crys_fea)\n",
    "\t\t\tout = self.fc_out(crys_fea)\n",
    "\t\treturn out, crys_fea\n",
    "\n",
    "\tdef pooling(self, atom_fea, crystal_atom_idx):\n",
    "\t\t\"\"\"\n",
    "\t\tPooling the atom features to crystal features\n",
    "\n",
    "\t\tN: Total number of atoms in the batch\n",
    "\t\tN0: Total number of crystals in the batch\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\n",
    "\t\tatom_fea: Variable(torch.Tensor) shape (N, atom_fea_len)\n",
    "\t\t  Atom feature vectors of the batch\n",
    "\t\tcrystal_atom_idx: list of torch.LongTensor of length N0\n",
    "\t\t  Mapping from the crystal idx to atom idx\n",
    "\t\t\"\"\"\n",
    "\t\tassert sum([len(idx_map) for idx_map in crystal_atom_idx]) == \\\n",
    "\t\t\t   atom_fea.data.shape[0]\n",
    "\t\tsummed_fea = [torch.mean(atom_fea[idx_map], dim=0, keepdim=True)\n",
    "\t\t\t\t\t  for idx_map in crystal_atom_idx]\n",
    "\t\treturn torch.cat(summed_fea, dim=0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
