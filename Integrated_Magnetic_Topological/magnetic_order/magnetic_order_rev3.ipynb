{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/TIvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# first attempt at multi task learning and integration with topological quantum chemistry database\n",
    "import e3nn.util\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "\n",
    "import e3nn\n",
    "from e3nn import o3\n",
    "#from e3nn.util.datatypes import DataPeriodicNeighbors\n",
    "#from e3nn.nn._gate import GatedConvParityNetwork\n",
    "#from e3nn.math._linalg import Kernel\n",
    "\n",
    "import pymatgen as mg\n",
    "import pymatgen.io\n",
    "from pymatgen.core.structure import Structure\n",
    "import pymatgen.analysis.magnetism.analyzer as pg\n",
    "from mp_api.client import MPRester\n",
    "import numpy as np\n",
    "import pickle\n",
    "from mendeleev import element\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import io\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import time, os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "load_dotenv(Path(\"/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/Integrated_Magnetic_Topological/matprojectapi.env\"))\n",
    "api_key = os.getenv(\"MP_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pymatgen as pg\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.analysis.magnetism import CollinearMagneticStructureAnalyzer\n",
    "\n",
    "order_list_mp = []\n",
    "structures_list_mp = []\n",
    "formula_list_mp = []\n",
    "sites_list = []\n",
    "id_list_mp = []\n",
    "y_values_mp = []\n",
    "\n",
    "order_encode = {\"NM\": 0, \"AFM\": 1, \"FM\": 2, \"FiM\": 2}\n",
    "topo_encode = {False: 0, True: 1}\n",
    "\n",
    "# Load data\n",
    "mp_structures_dict = torch.load('/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/Integrated_Magnetic_Topological/magnetic_order/preload_data/mp_structures_2025-04-07_12-52.pt', \n",
    "                                weights_only=False)\n",
    "\n",
    "structures = mp_structures_dict['structures']\n",
    "materials = mp_structures_dict['materials_id']\n",
    "formulas = mp_structures_dict['formulas']\n",
    "orders = mp_structures_dict['order']\n",
    "nsites = mp_structures_dict['nsites']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_list = []\n",
    "\n",
    "for struct in structures:\n",
    "    analyzer = CollinearMagneticStructureAnalyzer(struct)\n",
    "    order_list.append(analyzer.ordering.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_NM = [i for i, order in enumerate(order_list) if order == 'NM']\n",
    "id_AFM = [i for i, order in enumerate(order_list) if order == 'AFM']\n",
    "id_FM = [i for i, order in enumerate(order_list) if order in ['FM', 'FiM']]\n",
    "\n",
    "# Shuffle\n",
    "np.random.shuffle(id_NM)\n",
    "np.random.shuffle(id_FM)\n",
    "np.random.shuffle(id_AFM)\n",
    "\n",
    "# Balance dataset (keeping AFM as reference size)\n",
    "id_AFM, id_AFM_to_delete = np.split(id_AFM, [int(len(id_AFM))])\n",
    "id_NM, id_NM_to_delete = np.split(id_NM, [int(1.2 * len(id_AFM))])\n",
    "id_FM, id_FM_to_delete = np.split(id_FM, [int(1.2 * len(id_AFM))])\n",
    "\n",
    "# Final index list\n",
    "selected_ids = np.concatenate((id_NM, id_FM, id_AFM))\n",
    "np.random.shuffle(selected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in selected_ids:\n",
    "    structure = structures[idx]\n",
    "    material_id = materials[idx]\n",
    "    formula = formulas[idx]\n",
    "    nsite = nsites[idx]\n",
    "\n",
    "    analyzer = CollinearMagneticStructureAnalyzer(structure)\n",
    "    ordering = analyzer.ordering\n",
    "\n",
    "    structures_list_mp.append(structure)\n",
    "    id_list_mp.append(material_id)\n",
    "    formula_list_mp.append(formula)\n",
    "    sites_list.append(nsite)\n",
    "    order_list_mp.append(ordering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 3587.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 17848.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-1983234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 23696.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-1014111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 17848.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-2647074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 31300.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-1096950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 20360.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-1184113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 19599.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-1184067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 16644.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-1056699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 23301.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-569423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "topo_encode = {False: 0, True: 1}\n",
    "topo_labels = []\n",
    "\n",
    "from mp_api.client import MPRester\n",
    "m = MPRester(api_key=api_key)\n",
    "\n",
    "for material_id in id_list_mp:\n",
    "    try:\n",
    "        result = m.materials.summary.search(material_ids=[material_id])\n",
    "        if result and hasattr(result[0], \"is_topological\"):\n",
    "            label = result[0].is_topological\n",
    "            topo_labels.append(topo_encode[label])\n",
    "        else:\n",
    "            print(f\"No topological info for {material_id}\")\n",
    "            topo_labels.append(topo_encode[False])\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving TI label for {material_id}: {e}\")\n",
    "        topo_labels.append(topo_encode[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pymatgen.core import Structure\n",
    "\n",
    "def fetch_tqc_magnetic_data(bcs_id=\"3.7\"):\n",
    "    \"\"\"\n",
    "    Fetch magnetic topological materials data from the TQC database\n",
    "    \"\"\"\n",
    "    # Simulated example structure — replace with API call in production\n",
    "    return {\n",
    "        \"magnetic_materials\": [\n",
    "            {\n",
    "                \"id\": \"mp-123\",\n",
    "                \"formula\": \"Fe2O3\",\n",
    "                \"spacegroup\": 167,\n",
    "                \"magnetic_ordering\": \"AFM\",\n",
    "                \"topological_class\": \"Strong TI\",\n",
    "                \"band_gap\": 0.8,\n",
    "                \"magnetic_moment\": 4.2\n",
    "            },\n",
    "            # Add more entries as needed\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def create_combined_dataset(mp_structures, tqc_data):\n",
    "    \"\"\"\n",
    "    Combine Materials Project structures (as Structure objects or dicts) with TQC magnetic data\n",
    "    \"\"\"\n",
    "    tqc_map = {item[\"id\"]: item for item in tqc_data[\"magnetic_materials\"]}\n",
    "    combined_data = []\n",
    "\n",
    "    for struct in mp_structures:\n",
    "        # Handle both dict and Structure input\n",
    "        if isinstance(struct, dict):\n",
    "            mp_id = struct.get(\"material_id\")\n",
    "            structure = struct.get(\"structure\")\n",
    "            formula = struct.get(\"pretty_formula\")\n",
    "            nsites = struct.get(\"nsites\")\n",
    "        elif isinstance(struct, Structure):\n",
    "            mp_id = getattr(struct, \"material_id\", None)\n",
    "            structure = struct\n",
    "            formula = structure.formula\n",
    "            nsites = structure.num_sites\n",
    "        else:\n",
    "            continue  # skip unknown formats\n",
    "\n",
    "        if mp_id in tqc_map:\n",
    "            tqc_info = tqc_map[mp_id]\n",
    "            struct_data = {\n",
    "                \"structure\": structure,\n",
    "                \"material_id\": mp_id,\n",
    "                \"formula\": formula,\n",
    "                \"nsites\": nsites,\n",
    "                \"magnetic_ordering\": tqc_info[\"magnetic_ordering\"],\n",
    "                \"topological_class\": tqc_info[\"topological_class\"],\n",
    "                \"band_gap\": tqc_info.get(\"band_gap\", None),\n",
    "                \"magnetic_moment\": tqc_info.get(\"magnetic_moment\", None),\n",
    "                \"symmetry_operations\": tqc_info.get(\"symmetry_operations\", None)\n",
    "            }\n",
    "            combined_data.append(struct_data)\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "# Example usage:\n",
    "tqc_data = fetch_tqc_magnetic_data(bcs_id=\"3.7\")\n",
    "combined_dataset = create_combined_dataset(structures, tqc_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.analysis.local_env import CrystalNN\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "import torch\n",
    "\n",
    "def extract_magnetic_features(structure):\n",
    "    \"\"\"\n",
    "    Extract features relevant for magnetic ordering classification\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # 1. Magnetic elements\n",
    "    magnetic_elements = ['Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Ce', 'Pr', 'Nd',\n",
    "                         'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb']\n",
    "    element_counts = {}\n",
    "    total_atoms = len(structure)\n",
    "\n",
    "    for site in structure:\n",
    "        symbol = str(site.specie.symbol)\n",
    "        element_counts[symbol] = element_counts.get(symbol, 0) + 1\n",
    "\n",
    "    magnetic_fraction = sum(element_counts.get(el, 0) for el in magnetic_elements) / total_atoms\n",
    "    features['magnetic_fraction'] = magnetic_fraction\n",
    "\n",
    "    # 2. Magnetic exchange pathways\n",
    "    magnetic_sites = [i for i, site in enumerate(structure) if str(site.specie.symbol) in magnetic_elements]\n",
    "    exchange_distances = []\n",
    "\n",
    "    for i in magnetic_sites:\n",
    "        for j in magnetic_sites:\n",
    "            if i < j:\n",
    "                distance = structure.get_distance(i, j)\n",
    "                if distance < 4.0:\n",
    "                    exchange_distances.append(distance)\n",
    "\n",
    "    if exchange_distances:\n",
    "        features['avg_exchange_distance'] = sum(exchange_distances) / len(exchange_distances)\n",
    "        features['min_exchange_distance'] = min(exchange_distances)\n",
    "    else:\n",
    "        features['avg_exchange_distance'] = 0.0\n",
    "        features['min_exchange_distance'] = 0.0\n",
    "\n",
    "    # 3. Crystal field distortion (optional, just log one example distortion)\n",
    "    # NOTE: This can produce many features, we log just one for simplicity\n",
    "    distortion_list = []\n",
    "    for i in magnetic_sites:\n",
    "        neighbors = structure.get_neighbors(structure[i], 3.0)\n",
    "        if neighbors:\n",
    "            distances = [n[1] for n in neighbors]\n",
    "            avg_distance = sum(distances) / len(distances)\n",
    "            distortion = sum((d - avg_distance)**2 for d in distances) / len(distances)\n",
    "            distortion_list.append(distortion)\n",
    "\n",
    "    features['avg_coordination_distortion'] = (\n",
    "        sum(distortion_list) / len(distortion_list) if distortion_list else 0.0\n",
    "    )\n",
    "\n",
    "    # 4. Symmetry features\n",
    "    try:\n",
    "        analyzer = SpacegroupAnalyzer(structure)\n",
    "        spacegroup = analyzer.get_space_group_number()\n",
    "    except Exception:\n",
    "        spacegroup = 0  # fallback if symmetry detection fails\n",
    "\n",
    "    features['spacegroup'] = spacegroup\n",
    "\n",
    "    # 5. Time-reversal breaking (heuristic)\n",
    "    features['potential_time_reversal_breaking'] = 1 if magnetic_fraction > 0.1 else 0\n",
    "\n",
    "    return features\n",
    "\n",
    "# Apply feature extraction to all structures\n",
    "magnetic_features = []\n",
    "for struct in structures_list_mp:\n",
    "    magnetic_features.append(extract_magnetic_features(struct))\n",
    "\n",
    "# Convert to tensor (ensure values are numeric)\n",
    "magnetic_feature_tensor = torch.tensor([\n",
    "    [\n",
    "        float(f['magnetic_fraction']),\n",
    "        float(f['avg_exchange_distance']),\n",
    "        float(f['min_exchange_distance']),\n",
    "        int(f['spacegroup']),\n",
    "        int(f['potential_time_reversal_breaking'])\n",
    "    ]\n",
    "    for f in magnetic_features\n",
    "], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import e3nn.nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "class MagneticTopologicalClassifier(torch.nn.Module):\n",
    "    def __init__(self, atom_type_in, hidden_dim=128, model_kwargs=None):\n",
    "        super().__init__()\n",
    "        if model_kwargs is None:\n",
    "            model_kwargs = {}\n",
    "\n",
    "        # Atom embedding\n",
    "        self.atom_embedding = torch.nn.Linear(atom_type_in, hidden_dim)\n",
    "        \n",
    "        # Magnetic attention module\n",
    "        self.magnetic_attention = MagneticAttention(hidden_dim)\n",
    "        \n",
    "        # E3NN convolution layers (you must define GatedConvParityNetwork elsewhere)\n",
    "        self.model = e3nn.nn.Gate(**model_kwargs)\n",
    "       # self.model = GatedConvParityNetwork(**model_kwargs)\n",
    "        \n",
    "        # Magnetic ordering head\n",
    "        self.magnetic_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 3)  # NM, AFM, FM/FiM\n",
    "        )\n",
    "        \n",
    "        # Topological classification head\n",
    "        self.topological_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 4)  # None, Weak TI, Strong TI, HOTI\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch=None, n_norm=35):\n",
    "        # Initial embedding\n",
    "        x = self.atom_embedding(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Magnetic attention layer\n",
    "        x = self.magnetic_attention(x, edge_index, edge_attr)\n",
    "        \n",
    "        # E3NN-based processing\n",
    "        x = self.model(x, edge_index, edge_attr, n_norm=n_norm)\n",
    "        \n",
    "        # Global pooling\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        x_global = scatter_add(x, batch, dim=0)\n",
    "        \n",
    "        # Classification heads\n",
    "        magnetic_pred = self.magnetic_head(x_global)\n",
    "        topological_pred = self.topological_head(x_global)\n",
    "        \n",
    "        return magnetic_pred, topological_pred\n",
    "\n",
    "\n",
    "class MagneticAttention(MessagePassing):\n",
    "    \"\"\"\n",
    "    Attention mechanism for magnetic interactions\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__(aggr='add')  # Aggregation function\n",
    "        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.k_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.att_proj = nn.Linear(2 * hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        q = self.q_proj(x)\n",
    "        k = self.k_proj(x)\n",
    "        v = self.v_proj(x)\n",
    "        return self.propagate(edge_index, q=q, k=k, v=v, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, q_i, k_j, v_j, edge_attr):\n",
    "        attention_input = torch.cat([q_i, k_j], dim=-1)\n",
    "        alpha = F.leaky_relu(self.att_proj(attention_input).squeeze(-1))\n",
    "        alpha = torch.softmax(alpha, dim=0)\n",
    "        return alpha.unsqueeze(-1) * v_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def evaluate_multi_task(model, dataloader, device):\n",
    "    \"\"\"Evaluate model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    magnetic_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    topological_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    magnetic_loss_cumulative = 0.0\n",
    "    topological_loss_cumulative = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in dataloader:\n",
    "            d.to(device)\n",
    "            # Forward pass\n",
    "            magnetic_pred, topological_pred = model(d.x, d.edge_index, d.edge_attr, \n",
    "                                                  n_norm=True, batch=d.batch)\n",
    "            # Compute losses\n",
    "            magnetic_loss = magnetic_loss_fn(magnetic_pred, d.magnetic_y)\n",
    "            topological_loss = topological_loss_fn(topological_pred, d.topological_y)\n",
    "            \n",
    "            # Update cumulative losses\n",
    "            magnetic_loss_cumulative += magnetic_loss.detach().item()\n",
    "            topological_loss_cumulative += topological_loss.detach().item()\n",
    "    \n",
    "    # Compute average losses\n",
    "    magnetic_valid_loss = magnetic_loss_cumulative / len(dataloader)\n",
    "    topological_valid_loss = topological_loss_cumulative / len(dataloader)\n",
    "    \n",
    "    return magnetic_valid_loss, topological_valid_loss\n",
    "\n",
    "def multi_task_training(model, dataloader, dataloader_valid, max_iter=101, device=\"cpu\"):\n",
    "    # Define parameters\n",
    "    params = {\n",
    "        'adamw_lr': 0.001,  # Learning rate for AdamW optimizer\n",
    "        'adamw_wd': 0.01    # Weight decay for AdamW optimizer\n",
    "    }\n",
    "    \n",
    "    model.to(device)\n",
    "    # Loss functions\n",
    "    magnetic_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    topological_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=params['adamw_lr'], weight_decay=params['adamw_wd'])\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.78)\n",
    "    \n",
    "    # Training metrics\n",
    "    valid_loss_min = np.inf\n",
    "    \n",
    "    for step in range(max_iter):\n",
    "        model.train()\n",
    "        magnetic_loss_cumulative = 0.0\n",
    "        topological_loss_cumulative = 0.0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for j, d in enumerate(dataloader):\n",
    "            d.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            magnetic_pred, topological_pred = model(d.x, d.edge_index, d.edge_attr, \n",
    "                                                  n_norm=True, batch=d.batch)\n",
    "            \n",
    "            # Compute losses\n",
    "            magnetic_loss = magnetic_loss_fn(magnetic_pred, d.magnetic_y)\n",
    "            topological_loss = topological_loss_fn(topological_pred, d.topological_y)\n",
    "            \n",
    "            # Apply class weighting for imbalanced classes\n",
    "            #TODO: can change this\n",
    "            cost_multiplier = 1\n",
    "            if d.magnetic_y.item() == 2: # FM/FiM classes\n",
    "                magnetic_loss = cost_multiplier * magnetic_loss\n",
    "            \n",
    "            # Combine losses\n",
    "            combined_loss = magnetic_loss + topological_loss\n",
    "            \n",
    "            # Update cumulative losses\n",
    "            magnetic_loss_cumulative += magnetic_loss.detach().item()\n",
    "            topological_loss_cumulative += topological_loss.detach().item()\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            combined_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Compute average losses\n",
    "        magnetic_train_loss = magnetic_loss_cumulative / len(dataloader)\n",
    "        topological_train_loss = topological_loss_cumulative / len(dataloader)\n",
    "        \n",
    "        # Validation\n",
    "        magnetic_valid_loss, topological_valid_loss = evaluate_multi_task(model, dataloader_valid, device)\n",
    "        \n",
    "        # Log progress\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Step {step:4d}/{max_iter - 1:4d} \"\n",
    "                  f\"Magnetic Loss: {magnetic_train_loss:7.4f} \"\n",
    "                  f\"Topological Loss: {topological_train_loss:7.4f} \"\n",
    "                  f\"Valid Magnetic: {magnetic_valid_loss:7.4f} \"\n",
    "                  f\"Valid Topological: {topological_valid_loss:7.4f} \"\n",
    "                  f\"Time: {time.time() - start_time:.4f}\")\n",
    "        \n",
    "        # Save model if validation loss improves\n",
    "        valid_loss = magnetic_valid_loss + topological_valid_loss\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model...'.format(\n",
    "                valid_loss_min, valid_loss))\n",
    "            run_name = datetime.today().strftime('%Y-%m-%d_%H-%M')\n",
    "            torch.save(model.state_dict(), run_name + 'multi_task_model.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_symmetry_indicators(structure):\n",
    "    \"\"\"\n",
    "    Extract symmetry indicators relevant for topological classification\n",
    "    Based on Topological Quantum Chemistry principles\n",
    "    \"\"\"\n",
    "    indicators = {}\n",
    "    \n",
    "    # Get space group information\n",
    "    analyzer = SpacegroupAnalyzer(structure)\n",
    "    spacegroup_number = analyzer.get_space_group_number()\n",
    "    point_group = analyzer.get_point_group_symbol()\n",
    "    \n",
    "    indicators['spacegroup_number'] = spacegroup_number\n",
    "    \n",
    "    # Check for inversion symmetry (important for many topological materials)\n",
    "    indicators['has_inversion'] = 1 if analyzer.has_inversion() else 0\n",
    "    \n",
    "    # Time-reversal symmetry is crucial for topological classification\n",
    "    # In a real implementation, this would be more sophisticated\n",
    "    magnetic_elements = ['Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Gd', 'Dy', 'Ho', 'Er', 'Tm', 'Yb']\n",
    "    has_magnetic_elements = any(element in str(structure.composition) for element in magnetic_elements)\n",
    "    indicators['potential_time_reversal_breaking'] = 1 if has_magnetic_elements else 0\n",
    "    \n",
    "    # BCS symmetry indicators based on BCS 3.7 from the TQC database\n",
    "    # This is a simplified implementation\n",
    "    if spacegroup_number in [2, 10, 47, 83, 87, 199, 216, 227]:  # These are examples\n",
    "        indicators['compatible_with_bcs_3_7'] = 1\n",
    "    else:\n",
    "        indicators['compatible_with_bcs_3_7'] = 0\n",
    "    \n",
    "    # Add indicators for nonsymmorphic symmetries\n",
    "    indicators['has_nonsymmorphic'] = 1 if analyzer.is_nonsymmorphic() else 0\n",
    "    \n",
    "    # Add band connectivity indicators\n",
    "    # In real implementation, this would require electronic structure calculation\n",
    "    indicators['estimated_band_inversion'] = 0  # Placeholder\n",
    "    \n",
    "    return indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bcs_compatibility(structure, bcs_id=\"3.7\"):\n",
    "    \"\"\"\n",
    "    Check if a structure is compatible with a specific BCS classification\n",
    "    from the Topological Quantum Chemistry database\n",
    "    \"\"\"\n",
    "    # This would typically require calling the TQC API or using their methods\n",
    "    # For this example, we'll use a simplified approach\n",
    "    \n",
    "    analyzer = SpacegroupAnalyzer(structure)\n",
    "    spacegroup = analyzer.get_space_group_number()\n",
    "    \n",
    "    # BCS 3.7 compatibility rules (simplified)\n",
    "    # In reality, this would involve more detailed symmetry analysis\n",
    "    if bcs_id == \"3.7\":\n",
    "        # Example conditions for BCS 3.7 (these would be replaced with actual conditions)\n",
    "        if spacegroup in [2, 10, 47, 83, 87, 199, 216, 227]:\n",
    "            # Check additional conditions like orbital character, band inversion, etc.\n",
    "            composition = structure.composition\n",
    "            \n",
    "            # Check for elements commonly found in TIs with this BCS\n",
    "            has_heavy_elements = any(element in str(composition) for element in ['Bi', 'Sb', 'Te', 'Se'])\n",
    "            \n",
    "            # Check for inversion symmetry (important for many TIs)\n",
    "            has_inversion = analyzer.has_inversion()\n",
    "            \n",
    "            return has_heavy_elements and has_inversion\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: change this lol\n",
    "\n",
    "def predict_topological_class(struct, symmetry_indicators, is_bcs_compatible):\n",
    "    if not is_bcs_compatible:\n",
    "        return \"None\"\n",
    "    if symmetry_indicators.get(\"z4\", 0) == 1:\n",
    "        return \"Strong TI\"\n",
    "    return \"Weak TI\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from pymatgen.core import Element\n",
    "from pymatgen.analysis.magnetism.analyzer import CollinearMagneticStructureAnalyzer\n",
    "\n",
    "def preprocess_structures_with_tqc(structures, bcs_id=\"3.7\", params=None):\n",
    "    \"\"\"\n",
    "    Enhanced preprocessing pipeline incorporating TQC data and BCS classification.\n",
    "    Now uses torch_geometric.data.Data instead of deprecated DataPeriodicNeighbors.\n",
    "    \"\"\"\n",
    "    if params is None:\n",
    "        params = {'max_radius': 5.0}\n",
    "        \n",
    "    len_element = 100  # Number of elements you plan to support (e.g. Z < 100)\n",
    "\n",
    "    processed_data = []\n",
    "    \n",
    "    for i, struct in enumerate(structures):\n",
    "        print(f\"Processing structure {i+1}/{len(structures)}\", end=\"\\r\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            # Basic atom features (3 features per element max)\n",
    "            input_features = torch.zeros(len(struct), 3 * len_element)\n",
    "            for j, site in enumerate(struct):\n",
    "                elem = str(site.specie)\n",
    "                Z = Element(elem).Z\n",
    "                input_features[j, Z] = Element(elem).atomic_radius or 0\n",
    "                input_features[j, len_element + Z] = Element(elem).en_pauling or 0\n",
    "                input_features[j, 2 * len_element + Z] = Element(elem).dipole_polarizability or 0\n",
    "            \n",
    "            # Extract features\n",
    "            magnetic_feats = extract_magnetic_features(struct)\n",
    "            symmetry_indicators = extract_symmetry_indicators(struct)\n",
    "            is_bcs_compatible = check_bcs_compatibility(struct, bcs_id=bcs_id)\n",
    "            \n",
    "            # Magnetic ordering\n",
    "            analyzer = CollinearMagneticStructureAnalyzer(struct)\n",
    "            magnetic_order = analyzer.ordering\n",
    "            \n",
    "            # Topological classification (stubbed)\n",
    "            topo_class = predict_topological_class(struct, symmetry_indicators, is_bcs_compatible)\n",
    "            \n",
    "            # Convert to tensor dataset\n",
    "            data_point = Data(\n",
    "                x=input_features,\n",
    "                pos=torch.tensor(struct.cart_coords, dtype=torch.float),\n",
    "                lattice=torch.tensor(struct.lattice.matrix, dtype=torch.float),\n",
    "                y_magnetic=torch.tensor([order_encode[magnetic_order]], dtype=torch.long),\n",
    "                y_topological=torch.tensor([topo_encode[topo_class]], dtype=torch.long),\n",
    "                magnetic_features=torch.tensor(list(magnetic_feats.values()), dtype=torch.float),\n",
    "                symmetry_features=torch.tensor(list(symmetry_indicators.values()), dtype=torch.float),\n",
    "                bcs_compatible=torch.tensor([int(is_bcs_compatible)], dtype=torch.float)\n",
    "            )\n",
    "            \n",
    "            processed_data.append(data_point)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing structure {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_magnetic_space_group(structure):\n",
    "    \"\"\"\n",
    "    Analyze the magnetic space group of a structure\n",
    "    Important for classifying magnetic topological materials\n",
    "    \"\"\"\n",
    "    # This is a placeholder for more sophisticated analysis\n",
    "    # In practice, you would use a library like ISOTROPY or Bilbao Crystallographic Server\n",
    "    \n",
    "    # Get standard space group\n",
    "    analyzer = SpacegroupAnalyzer(structure)\n",
    "    space_group = analyzer.get_space_group_number()\n",
    "    \n",
    "    # Analyze magnetic ordering\n",
    "    mag_analyzer = CollinearMagneticStructureAnalyzer(structure)\n",
    "    ordering = mag_analyzer.ordering.name\n",
    "    \n",
    "    # Simplified magnetic space group determination\n",
    "    # In reality, this requires detailed analysis of symmetry and magnetic moments\n",
    "    if ordering == \"NM\":\n",
    "        # Non-magnetic: equivalent to standard space group\n",
    "        mag_space_group = f\"{space_group}.0\"\n",
    "    elif ordering == \"FM\":\n",
    "        # Ferromagnetic: typically type III or IV MSG\n",
    "        if analyzer.has_inversion():\n",
    "            mag_space_group = f\"{space_group}.10\"  # Example type IV\n",
    "        else:\n",
    "            mag_space_group = f\"{space_group}.8\"   # Example type III\n",
    "    elif ordering == \"AFM\":\n",
    "        # Antiferromagnetic: typically type II or III MSG\n",
    "        if space_group % 2 == 0:  # Even space groups often become type II\n",
    "            mag_space_group = f\"{space_group}.7\"   # Example type II\n",
    "        else:\n",
    "            mag_space_group = f\"{space_group}.9\"   # Example type III\n",
    "    else:\n",
    "        mag_space_group = \"unknown\"\n",
    "    \n",
    "    # For BCS 3.7 compatibility\n",
    "    compatible_with_bcs37 = False\n",
    "    if mag_space_group in [\"2.4\", \"10.42\", \"47.252\", \"83.43\", \"87.78\", \"199.13\", \"216.77\", \"227.131\"]:\n",
    "        compatible_with_bcs37 = True\n",
    "    \n",
    "    return {\n",
    "        \"magnetic_space_group\": mag_space_group,\n",
    "        \"compatible_with_bcs37\": compatible_with_bcs37\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MagneticTopologicalTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, edge_attr_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        self.attention_layers = nn.ModuleList([\n",
    "            GraphMultiHeadAttention(hidden_dim, num_heads, edge_attr_dim)\n",
    "            for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        self.ffn_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "            ) for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        self.layer_norms1 = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim) for _ in range(3)\n",
    "        ])\n",
    "        self.layer_norms2 = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim) for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        self.magnetic_head = nn.Linear(hidden_dim, 3)      # NM, AFM, FM/FiM\n",
    "        self.topological_head = nn.Linear(hidden_dim, 2)   # Not TI, TI\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        for i in range(3):\n",
    "            attention_output = self.attention_layers[i](x, edge_index, edge_attr)\n",
    "            x = self.layer_norms1[i](x + attention_output)\n",
    "            ffn_output = self.ffn_layers[i](x)\n",
    "            x = self.layer_norms2[i](x + ffn_output)\n",
    "        \n",
    "        x = torch_scatter.scatter_mean(x, batch, dim=0)\n",
    "        \n",
    "        magnetic_pred = self.magnetic_head(x)\n",
    "        topological_pred = self.topological_head(x)\n",
    "        \n",
    "        return magnetic_pred, torch.sigmoid(topological_pred)\n",
    "\n",
    "\n",
    "class GraphMultiHeadAttention(MessagePassing):\n",
    "    def __init__(self, hidden_dim, num_heads, edge_attr_dim):\n",
    "        super().__init__(aggr='add')\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        \n",
    "        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.k_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.edge_proj = nn.Linear(edge_attr_dim, num_heads)\n",
    "        self.output_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Project inputs\n",
    "        q = self.q_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "        k = self.k_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "        v = self.v_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Process edge attributes\n",
    "        edge_weights = self.edge_proj(edge_attr).unsqueeze(-1)  # [E, num_heads, 1]\n",
    "        \n",
    "        # Propagate through edges\n",
    "        out = self.propagate(edge_index, q=q, k=k, v=v, edge_weights=edge_weights)\n",
    "        \n",
    "        # Project output\n",
    "        return self.output_proj(out.view(-1, self.hidden_dim))\n",
    "    \n",
    "    def message(self, q_i, k_j, v_j, edge_weights):\n",
    "        attention = (q_i * k_j).sum(dim=-1) / math.sqrt(self.head_dim)  # [E, num_heads]\n",
    "        attention = attention.unsqueeze(-1) * edge_weights             # Apply edge weighting\n",
    "        attention = F.softmax(attention, dim=0)                        # Normalize over neighbors\n",
    "        return attention * v_j                                         # [E, num_heads, head_dim]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCS37Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Specialized classifier for BCS 3.7 magnetic topological materials\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Symmetry analysis module\n",
    "        self.symmetry_module = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        \n",
    "        # Final classification heads\n",
    "        self.magnetic_head = nn.Linear(16, 3)  # NM, AFM, FM/FiM\n",
    "        self.bcs_compatibility_head = nn.Linear(16, 1)  # Sigmoid will be applied\n",
    "        \n",
    "    def forward(self, x, structure_features):\n",
    "        # Extract features\n",
    "        features = self.feature_extraction(x)\n",
    "        \n",
    "        # Add structure-level features like symmetry indicators\n",
    "        combined_features = features + structure_features\n",
    "        \n",
    "        # Analyze symmetry\n",
    "        symmetry_features = self.symmetry_module(combined_features)\n",
    "        \n",
    "        # Get predictions\n",
    "        magnetic_pred = self.magnetic_head(symmetry_features)\n",
    "        bcs_compatibility = torch.sigmoid(self.bcs_compatibility_head(symmetry_features))\n",
    "        \n",
    "        return magnetic_pred, bcs_compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_loss(magnetic_pred, topological_pred, batch):\n",
    "    \"\"\"\n",
    "    Compute the loss for both magnetic and topological predictions.\n",
    "\n",
    "    Arguments:\n",
    "    - magnetic_pred: Predictions for the magnetic ordering (output from the magnetic head)\n",
    "    - topological_pred: Predictions for the topological class (output from the topological head)\n",
    "    - batch: Batch of data containing the true labels for magnetic and topological classes\n",
    "\n",
    "    Returns:\n",
    "    - loss: Total loss (sum of magnetic and topological losses)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Magnetic prediction loss (Cross-Entropy Loss)\n",
    "    magnetic_true = batch.magnetic_y\n",
    "    magnetic_loss = F.cross_entropy(magnetic_pred, magnetic_true)\n",
    "    \n",
    "    # Topological prediction loss (Cross-Entropy Loss)\n",
    "    topological_true = batch.topological_y\n",
    "    topological_loss = F.cross_entropy(topological_pred, topological_true)\n",
    "    \n",
    "    # Total loss is the sum of both losses\n",
    "    total_loss = magnetic_loss + topological_loss\n",
    "    \n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MagneticTopologicalTransformer.__init__() missing 1 required positional argument: 'edge_attr_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m atom_types_dim = \u001b[32m3\u001b[39m  \u001b[38;5;66;03m# For this case, you would need 3 features per atom type\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m model = \u001b[43mMagneticTopologicalTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43matom_types_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m.to(device)  \u001b[38;5;66;03m# Make sure to move the model to the correct device\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Preprocess data with TQC insights\u001b[39;00m\n\u001b[32m     20\u001b[39m enhanced_data = preprocess_structures_with_tqc(structures_list_mp, bcs_id=\u001b[33m\"\u001b[39m\u001b[33m3.7\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: MagneticTopologicalTransformer.__init__() missing 1 required positional argument: 'edge_attr_dim'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "# Define the device (use CUDA if available, otherwise use CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define atom_types_dim based on your feature encoding\n",
    "# For example, if you use atomic radius, electronegativity, and dipole moment as features for each atom type\n",
    "atom_types_dim = 3  # For this case, you would need 3 features per atom type\n",
    "\n",
    "# Initialize the model\n",
    "model = MagneticTopologicalTransformer(\n",
    "    input_dim=atom_types_dim, \n",
    "    hidden_dim=128,\n",
    "    num_heads=4, \n",
    "    edge_attr_dim= 1\n",
    ").to(device)  # Make sure to move the model to the correct device\n",
    "\n",
    "# Preprocess data with TQC insights\n",
    "enhanced_data = preprocess_structures_with_tqc(structures_list_mp, bcs_id=\"3.7\")\n",
    "\n",
    "# Split data\n",
    "indices = np.arange(len(enhanced_data))\n",
    "np.random.shuffle(indices)\n",
    "index_tr, index_va, index_te = np.split(indices, [int(.8 * len(indices)), int(.9 * len(indices))])\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 16  # Increased batch size for transformer\n",
    "dataloader = torch_geometric.data.DataLoader(\n",
    "    [enhanced_data[i] for i in index_tr], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "dataloader_valid = torch_geometric.data.DataLoader(\n",
    "    [enhanced_data[i] for i in index_va], \n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Initialize optimizer with learning rate warmup\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "\n",
    "# Learning rate scheduler (Cosine annealing with warmup)\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=100,  # First restart period\n",
    "    T_mult=2,  # Multiply restart period after each cycle\n",
    "    eta_min=0,  # Minimum learning rate\n",
    "    last_epoch=-1  # Start from epoch 0\n",
    ")\n",
    "\n",
    "# Training function placeholder (assuming you have defined it previously)\n",
    "def train_mag_topo_model(model, optimizer, scheduler, dataloader, dataloader_valid, max_epochs, device):\n",
    "    model.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)  # Ensure the batch is on the correct device\n",
    "            optimizer.zero_grad()\n",
    "            magnetic_pred, topological_pred = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            # Define loss functions and backpropagate here\n",
    "            loss = compute_loss(magnetic_pred, topological_pred, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader_valid:\n",
    "                batch = batch.to(device)  # Ensure validation batch is on the correct device\n",
    "                magnetic_pred, topological_pred = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "                # Compute validation loss or any evaluation metric here\n",
    "                val_loss = compute_loss(magnetic_pred, topological_pred, batch)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{max_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "# Train the model\n",
    "train_mag_topo_model(\n",
    "    model, \n",
    "    optimizer, \n",
    "    scheduler,\n",
    "    dataloader, \n",
    "    dataloader_valid, \n",
    "    max_epochs=100, \n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MagneticTopologicalTransformer.__init__() missing 1 required positional argument: 'edge_attr_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[32m      2\u001b[39m atom_types_dim = \u001b[32m3\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model = \u001b[43mMagneticTopologicalTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43matom_types_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Preprocess data with TQC insights\u001b[39;00m\n\u001b[32m     10\u001b[39m enhanced_data = preprocess_structures_with_tqc(structures_list_mp, bcs_id=\u001b[33m\"\u001b[39m\u001b[33m3.7\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: MagneticTopologicalTransformer.__init__() missing 1 required positional argument: 'edge_attr_dim'"
     ]
    }
   ],
   "source": [
    "# # Initialize the model\n",
    "# atom_types_dim = 3\n",
    "# model = MagneticTopologicalTransformer(\n",
    "#     input_dim=atom_types_dim, \n",
    "#     hidden_dim=128,\n",
    "#     num_heads=4\n",
    "# )\n",
    "\n",
    "# # Preprocess data with TQC insights\n",
    "# enhanced_data = preprocess_structures_with_tqc(structures_list_mp, bcs_id=\"3.7\")\n",
    "\n",
    "# # Split data\n",
    "# indices = np.arange(len(enhanced_data))\n",
    "# np.random.shuffle(indices)\n",
    "# index_tr, index_va, index_te = np.split(indices, [int(.8 * len(indices)), int(.9 * len(indices))])\n",
    "\n",
    "# # Create dataloaders\n",
    "# batch_size = 16  # Increased batch size for transformer\n",
    "# dataloader = torch_geometric.data.DataLoader(\n",
    "#     [enhanced_data[i] for i in index_tr], \n",
    "#     batch_size=batch_size, \n",
    "#     shuffle=True\n",
    "# )\n",
    "# dataloader_valid = torch_geometric.data.DataLoader(\n",
    "#     [enhanced_data[i] for i in index_va], \n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "\n",
    "# # Initialize optimizer with learning rate warmup\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "# scheduler = get_cosine_schedule_with_warmup(\n",
    "#     optimizer, \n",
    "#     num_warmup_steps=100, \n",
    "#     num_training_steps=100*len(dataloader)\n",
    "# )\n",
    "\n",
    "# # Train model\n",
    "# train_mag_topo_model(\n",
    "#     model, \n",
    "#     optimizer, \n",
    "#     scheduler,\n",
    "#     dataloader, \n",
    "#     dataloader_valid, \n",
    "#     max_epochs=100, \n",
    "#     device= 'cpu'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
