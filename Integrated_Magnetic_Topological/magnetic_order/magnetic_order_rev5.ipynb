{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/TIvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Magnetic Topological Material Classifier\n",
    "=======================================\n",
    "A deep learning framework for simultaneously predicting magnetic ordering and topological classification\n",
    "of crystalline materials using graph neural networks and transformers.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_scatter import scatter_add, scatter_mean\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Materials science libraries\n",
    "import pymatgen as pmg\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.core import Element\n",
    "from pymatgen.analysis.magnetism.analyzer import CollinearMagneticStructureAnalyzer\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from mp_api.client import MPRester\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MP_API_KEY\")\n",
    "\n",
    "# Constants\n",
    "ORDER_ENCODE = {\"NM\": 0, \"AFM\": 1, \"FM\": 2, \"FiM\": 2}  # FiM grouped with FM\n",
    "TOPO_ENCODE = {False: 0, True: 1}  # Non-topological vs topological\n",
    "\n",
    "# Global parameters\n",
    "PARAMS = {\n",
    "    'max_radius': 8.0,        # Maximum cutoff radius for atom connections\n",
    "    'n_norm': 35,             # Normalization factor\n",
    "    'hidden_dim': 128,        # Hidden dimension size\n",
    "    'num_heads': 4,           # Number of attention heads\n",
    "    'num_layers': 3,          # Number of transformer layers\n",
    "    'batch_size': 8,          # Batch size for training\n",
    "    'lr': 0.0005,             # Learning rate\n",
    "    'weight_decay': 0.01,     # Weight decay for regularization\n",
    "    'max_epochs': 200,        # Maximum training epochs\n",
    "    'early_stop_patience': 15  # Patience for early stopping\n",
    "}\n",
    "\n",
    "\n",
    "#===============================\n",
    "# DATA STRUCTURES AND PROCESSING\n",
    "#===============================\n",
    "\n",
    "class MaterialData(Data):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Geometric Data class for material structure data with proper batching.\n",
    "    \"\"\"\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'edge_index':\n",
    "            return self.num_nodes\n",
    "        if key == 'cell_index':\n",
    "            return self.num_nodes\n",
    "        return super().__inc__(key, value, *args, **kwargs)\n",
    "\n",
    "\n",
    "def get_element_properties(symbol):\n",
    "    \"\"\"Get key properties for an element by symbol.\"\"\"\n",
    "    try:\n",
    "        elem = Element(symbol)\n",
    "        return {\n",
    "            'Z': elem.Z,\n",
    "            'group': elem.group,\n",
    "            'row': elem.row,\n",
    "            'atomic_radius': elem.atomic_radius or 0.0,\n",
    "            'atomic_mass': elem.atomic_mass or 0.0,\n",
    "            'electronegativity': elem.electronegativity or 0.0,\n",
    "            'is_magnetic': int(symbol in ['Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Gd', 'Dy', 'Ho', 'Er', 'Tm', 'Yb'])\n",
    "        }\n",
    "    except Exception:\n",
    "        # Default values if element properties can't be retrieved\n",
    "        return {'Z': 0, 'group': 0, 'row': 0, 'atomic_radius': 0.0, \n",
    "                'atomic_mass': 0.0, 'electronegativity': 0.0, 'is_magnetic': 0}\n",
    "\n",
    "\n",
    "def extract_structure_features(structure):\n",
    "    \"\"\"Extract features from a pymatgen Structure object.\"\"\"\n",
    "    # Symmetry features\n",
    "    analyzer = SpacegroupAnalyzer(structure)\n",
    "    spacegroup = analyzer.get_space_group_number()\n",
    "    point_group = analyzer.get_point_group_symbol()\n",
    "    has_inversion = int(analyzer.has_inversion())\n",
    "    \n",
    "    # Magnetic features\n",
    "    mag_elements = ['Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Gd', 'Dy', 'Ho', 'Er', 'Tm', 'Yb']\n",
    "    mag_count = sum(1 for site in structure if site.species_string in mag_elements)\n",
    "    mag_fraction = mag_count / len(structure)\n",
    "    \n",
    "    # Lattice features\n",
    "    a, b, c = structure.lattice.abc\n",
    "    alpha, beta, gamma = structure.lattice.angles\n",
    "    volume = structure.lattice.volume\n",
    "    density = structure.density\n",
    "    \n",
    "    return {\n",
    "        'spacegroup': spacegroup,\n",
    "        'point_group_id': hash(point_group) % 100,  # Simple hash for point group\n",
    "        'has_inversion': has_inversion,\n",
    "        'mag_fraction': mag_fraction,\n",
    "        'a': a, 'b': b, 'c': c,\n",
    "        'alpha': alpha, 'beta': beta, 'gamma': gamma,\n",
    "        'volume': volume,\n",
    "        'density': density\n",
    "    }\n",
    "\n",
    "\n",
    "def structure_to_graph(structure, max_radius=8.0):\n",
    "    \"\"\"\n",
    "    Convert a pymatgen Structure to a graph representation.\n",
    "    \n",
    "    Args:\n",
    "        structure: pymatgen Structure object\n",
    "        max_radius: Maximum bond distance to consider\n",
    "        \n",
    "    Returns:\n",
    "        x: Node features tensor\n",
    "        edge_index: Edge connectivity tensor\n",
    "        edge_attr: Edge features tensor\n",
    "        pos: Node positions tensor\n",
    "        structure_features: Global structure features tensor\n",
    "    \"\"\"\n",
    "    num_sites = len(structure)\n",
    "    \n",
    "    # Node features: 7 features per atom\n",
    "    node_features = []\n",
    "    for site in structure:\n",
    "        element = site.species_string\n",
    "        props = get_element_properties(element)\n",
    "        \n",
    "        # Feature vector for each atom: element properties\n",
    "        features = [\n",
    "            props['Z'] / 100,  # Normalized atomic number\n",
    "            props['group'] / 18,  # Normalized group\n",
    "            props['row'] / 7,  # Normalized row\n",
    "            props['atomic_radius'] / 2.0 if props['atomic_radius'] else 0,  # Normalized radius\n",
    "            props['electronegativity'] / 4.0 if props['electronegativity'] else 0,  # Normalized electronegativity\n",
    "            props['atomic_mass'] / 250.0,  # Normalized mass\n",
    "            float(props['is_magnetic'])  # Is magnetic element\n",
    "        ]\n",
    "        node_features.append(features)\n",
    "    \n",
    "    # Node positions\n",
    "    positions = torch.tensor(structure.cart_coords, dtype=torch.float)\n",
    "    \n",
    "    # Create edges based on distance\n",
    "    src_list = []\n",
    "    dst_list = []\n",
    "    edge_attr_list = []\n",
    "    \n",
    "    # For each pair of atoms, check if they're within max_radius\n",
    "    for i in range(num_sites):\n",
    "        for j in range(num_sites):\n",
    "            if i == j:  # Skip self-loops for now\n",
    "                continue\n",
    "                \n",
    "            # Get the distance considering periodic boundary conditions\n",
    "            dist = structure.get_distance(i, j)\n",
    "            \n",
    "            if dist <= max_radius:\n",
    "                src_list.append(i)\n",
    "                dst_list.append(j)\n",
    "                \n",
    "                # Edge features: distance, direction vector (normalized)\n",
    "                direction = positions[j] - positions[i]\n",
    "                direction_norm = torch.norm(direction)\n",
    "                if direction_norm > 0:\n",
    "                    direction = direction / direction_norm\n",
    "                \n",
    "                # Create edge feature vector:\n",
    "                # [distance, dx, dy, dz]\n",
    "                edge_attr_list.append([dist / max_radius] + direction.tolist())\n",
    "    \n",
    "    # If no edges were found, create self-loops to avoid errors\n",
    "    if not src_list:\n",
    "        for i in range(num_sites):\n",
    "            src_list.append(i)\n",
    "            dst_list.append(i)\n",
    "            edge_attr_list.append([0.0, 0.0, 0.0, 0.0])  # Self-loop has zero features\n",
    "    \n",
    "    # Convert to tensors\n",
    "    edge_index = torch.tensor([src_list, dst_list], dtype=torch.long)\n",
    "    edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "    \n",
    "    # Extract global structure features\n",
    "    structure_feats = extract_structure_features(structure)\n",
    "    structure_features = torch.tensor([\n",
    "        structure_feats['spacegroup'] / 230,  # Normalize by max space group\n",
    "        structure_feats['point_group_id'] / 100,\n",
    "        float(structure_feats['has_inversion']),\n",
    "        structure_feats['mag_fraction'],\n",
    "        structure_feats['a'] / 20.0,  # Normalize lattice parameters\n",
    "        structure_feats['b'] / 20.0,\n",
    "        structure_feats['c'] / 20.0,\n",
    "        structure_feats['alpha'] / 180.0,\n",
    "        structure_feats['beta'] / 180.0,\n",
    "        structure_feats['gamma'] / 180.0,\n",
    "        structure_feats['volume'] / 1000.0,\n",
    "        structure_feats['density'] / 20.0\n",
    "    ], dtype=torch.float).unsqueeze(0).repeat(num_sites, 1)\n",
    "    \n",
    "    return x, edge_index, edge_attr, positions, structure_features\n",
    "\n",
    "\n",
    "def process_structures(structures, materials_ids=None, formulas=None):\n",
    "    \"\"\"\n",
    "    Process a list of structures into graph data objects.\n",
    "    \n",
    "    Args:\n",
    "        structures: List of pymatgen Structure objects\n",
    "        materials_ids: List of Material Project IDs (optional)\n",
    "        formulas: List of chemical formulas (optional)\n",
    "        \n",
    "    Returns:\n",
    "        data_list: List of MaterialData objects\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    \n",
    "    for i, structure in enumerate(structures):\n",
    "        print(f\"Processing structure {i+1}/{len(structures)}\", end=\"\\r\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            # Extract magnetic ordering\n",
    "            mag_analyzer = CollinearMagneticStructureAnalyzer(structure)\n",
    "            ordering = mag_analyzer.ordering.name\n",
    "            magnetic_y = ORDER_ENCODE.get(ordering, 0)\n",
    "            \n",
    "            # Get material ID and formula if provided\n",
    "            material_id = materials_ids[i] if materials_ids else f\"struct_{i}\"\n",
    "            formula = formulas[i] if formulas else structure.composition.reduced_formula\n",
    "            \n",
    "            # Convert structure to graph representation\n",
    "            x, edge_index, edge_attr, pos, structure_features = structure_to_graph(\n",
    "                structure, max_radius=PARAMS['max_radius']\n",
    "            )\n",
    "            \n",
    "            # Create data object\n",
    "            data = MaterialData(\n",
    "                x=x,\n",
    "                edge_index=edge_index,\n",
    "                edge_attr=edge_attr,\n",
    "                pos=pos,\n",
    "                structure_features=structure_features,\n",
    "                magnetic_y=torch.tensor([magnetic_y], dtype=torch.long),\n",
    "                topological_y=torch.tensor([0], dtype=torch.long),  # Default to non-topological\n",
    "                material_id=material_id,\n",
    "                formula=formula,\n",
    "                num_atoms=len(structure)\n",
    "            )\n",
    "            data.num_nodes = x.size(0) \n",
    "            data_list.append(data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing structure {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nProcessed {len(data_list)}/{len(structures)} structures successfully\")\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def fetch_topological_labels(data_list, api_key):\n",
    "    \"\"\"\n",
    "    Fetch topological classifications for materials using the Materials Project API.\n",
    "    \n",
    "    Args:\n",
    "        data_list: List of MaterialData objects\n",
    "        api_key: Materials Project API key\n",
    "        \n",
    "    Returns:\n",
    "        data_list: Updated list with topological labels\n",
    "    \"\"\"\n",
    "    materials_with_topo_info = 0\n",
    "    \n",
    "    with MPRester(api_key=api_key) as mpr:\n",
    "        for i, data in enumerate(data_list):\n",
    "            material_id = data.material_id\n",
    "            \n",
    "            try:\n",
    "                # Skip if not a real MP ID\n",
    "                if not material_id.startswith(\"mp-\"):\n",
    "                    continue\n",
    "                    \n",
    "                # Query Materials Project API\n",
    "                result = mpr.materials.summary.search(material_ids=[material_id])\n",
    "                \n",
    "                if result and hasattr(result[0], \"is_topological\"):\n",
    "                    label = result[0].is_topological\n",
    "                    data.topological_y = torch.tensor([TOPO_ENCODE[label]], dtype=torch.long)\n",
    "                    materials_with_topo_info += 1\n",
    "                    print(f\"Found topological info for {material_id}: {label}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error retrieving topological info for {material_id}: {e}\")\n",
    "    \n",
    "    print(f\"Added topological labels for {materials_with_topo_info} materials\")\n",
    "    return data_list\n",
    "\n",
    "\n",
    "def load_and_process_data(mp_structures_file, api_key=None):\n",
    "    \"\"\"\n",
    "    Load and process materials data.\n",
    "    \n",
    "    Args:\n",
    "        mp_structures_file: Path to saved structures file\n",
    "        api_key: Materials Project API key for topological data\n",
    "        \n",
    "    Returns:\n",
    "        processed_data: List of processed MaterialData objects\n",
    "    \"\"\"\n",
    "    print(f\"Loading structures from {mp_structures_file}\")\n",
    "    mp_structures_dict = torch.load(mp_structures_file, weights_only=False)\n",
    "    \n",
    "    structures = mp_structures_dict['structures']\n",
    "    materials_ids = mp_structures_dict['materials_id']\n",
    "    formulas = mp_structures_dict['formulas']\n",
    "    \n",
    "    print(f\"Loaded {len(structures)} structures\")\n",
    "    \n",
    "    # Process structures to graph data\n",
    "    processed_data = process_structures(structures, materials_ids, formulas)\n",
    "    \n",
    "    # Fetch topological labels if API key is provided\n",
    "    if api_key:\n",
    "        processed_data = fetch_topological_labels(processed_data, api_key)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "\n",
    "def prepare_datasets(data_list, train_ratio=0.8, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split data into training, validation and test sets.\n",
    "    \n",
    "    Args:\n",
    "        data_list: List of MaterialData objects\n",
    "        train_ratio: Ratio of training data\n",
    "        val_ratio: Ratio of validation data\n",
    "        \n",
    "    Returns:\n",
    "        train_loader, val_loader, test_loader: DataLoader objects\n",
    "    \"\"\"\n",
    "    # Balance datasets by magnetic ordering\n",
    "    data_by_order = {0: [], 1: [], 2: []}\n",
    "    \n",
    "    for data in data_list:\n",
    "        magnetic_y = data.magnetic_y.item()\n",
    "        data_by_order[magnetic_y].append(data)\n",
    "    \n",
    "    print(f\"Data distribution by magnetic ordering:\")\n",
    "    for order, items in data_by_order.items():\n",
    "        order_name = {0: \"NM\", 1: \"AFM\", 2: \"FM/FiM\"}[order]\n",
    "        print(f\"  {order_name}: {len(items)} structures\")\n",
    "    \n",
    "    # Find minimum count to ensure balanced classes\n",
    "    min_count = min(len(items) for items in data_by_order.values())\n",
    "    balanced_data = []\n",
    "    \n",
    "    for order, items in data_by_order.items():\n",
    "        random.shuffle(items)\n",
    "        balanced_data.extend(items[:min_count])\n",
    "    \n",
    "    # Shuffle balanced dataset\n",
    "    random.shuffle(balanced_data)\n",
    "    \n",
    "    # Split into train/val/test\n",
    "    n = len(balanced_data)\n",
    "    train_size = int(train_ratio * n)\n",
    "    val_size = int(val_ratio * n)\n",
    "    \n",
    "    train_data = balanced_data[:train_size]\n",
    "    val_data = balanced_data[train_size:train_size + val_size]\n",
    "    test_data = balanced_data[train_size + val_size:]\n",
    "    \n",
    "    print(f\"Dataset splits: Train={len(train_data)}, Val={len(val_data)}, Test={len(test_data)}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_data, batch_size=PARAMS['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=PARAMS['batch_size'])\n",
    "    test_loader = DataLoader(test_data, batch_size=PARAMS['batch_size'])\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "#===============================\n",
    "# MODEL ARCHITECTURE\n",
    "#===============================\n",
    "\n",
    "class AttentionLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    Graph attention layer for materials science applications.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, num_heads=4, edge_dim=4):\n",
    "        super().__init__(aggr='add')\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        \n",
    "        # Query, key, value projections\n",
    "        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.k_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Edge feature projection\n",
    "        self.edge_proj = nn.Sequential(\n",
    "            nn.Linear(edge_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_heads)\n",
    "        )\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.ln1 = nn.LayerNorm(hidden_dim)\n",
    "        self.ln2 = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # First attention block with residual connection\n",
    "        identity = x\n",
    "        out = self.ln1(x)\n",
    "        out = self._attention_block(out, edge_index, edge_attr)\n",
    "        out = out + identity\n",
    "        \n",
    "        # Feed-forward block with residual connection\n",
    "        identity = out\n",
    "        out = self.ln2(out)\n",
    "        out = self.ffn(out)\n",
    "        return out + identity\n",
    "    \n",
    "    def _attention_block(self, x, edge_index, edge_attr):\n",
    "        # Project inputs to queries, keys, values\n",
    "        q = self.q_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "        k = self.k_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "        v = self.v_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Process edge attributes\n",
    "        edge_weights = self.edge_proj(edge_attr).unsqueeze(-1)  # [E, num_heads, 1]\n",
    "        \n",
    "        # Propagate through the graph\n",
    "        out = self.propagate(edge_index, q=q, k=k, v=v, edge_weights=edge_weights)\n",
    "        \n",
    "        # Project output back to original dimension\n",
    "        return self.output_proj(out.view(-1, self.hidden_dim))\n",
    "    \n",
    "    def message(self, q_i, k_j, v_j, edge_weights, index, ptr, size_i):\n",
    "        # Compute attention scores\n",
    "        attention = (q_i * k_j).sum(dim=-1) / math.sqrt(self.head_dim)\n",
    "        \n",
    "        # Multiply by edge weights (based on edge features)\n",
    "        attention = attention.unsqueeze(-1) * edge_weights\n",
    "        \n",
    "        # Apply softmax to normalize scores\n",
    "        alpha = F.softmax(attention, dim=0)\n",
    "        \n",
    "        # Apply attention weights to values\n",
    "        return alpha * v_j\n",
    "\n",
    "\n",
    "class MagneticTopologicalTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based model for predicting magnetic ordering and topological class.\n",
    "    \"\"\"\n",
    "    def __init__(self, node_dim=7, structure_dim=12, hidden_dim=128, edge_dim=4, num_heads=4, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Input projections\n",
    "        self.node_proj = nn.Linear(node_dim, hidden_dim)\n",
    "        self.structure_proj = nn.Linear(structure_dim, hidden_dim)\n",
    "        \n",
    "        # Attention layers\n",
    "        self.attention_layers = nn.ModuleList([\n",
    "            AttentionLayer(hidden_dim, num_heads, edge_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output heads\n",
    "        self.magnetic_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 3)  # NM, AFM, FM/FiM\n",
    "        )\n",
    "        \n",
    "        self.topological_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 2)  # Not TI, TI\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, structure_features, batch):\n",
    "        # Project node and structure features\n",
    "        h_nodes = self.node_proj(x)\n",
    "        h_struct = self.structure_proj(structure_features)\n",
    "        \n",
    "        # Combine node features with structure features\n",
    "        h = h_nodes + h_struct\n",
    "        \n",
    "        # Apply attention layers\n",
    "        for layer in self.attention_layers:\n",
    "            h = layer(h, edge_index, edge_attr)\n",
    "        \n",
    "        # Global pooling\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(h.size(0), dtype=torch.long, device=h.device)\n",
    "        \n",
    "        h_global = scatter_mean(h, batch, dim=0)\n",
    "        \n",
    "        # Predict magnetic ordering and topological class\n",
    "        magnetic_pred = self.magnetic_head(h_global)\n",
    "        topological_pred = self.topological_head(h_global)\n",
    "        \n",
    "        return magnetic_pred, topological_pred\n",
    "\n",
    "\n",
    "#===============================\n",
    "# TRAINING AND EVALUATION\n",
    "#===============================\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting\"\"\"\n",
    "    def __init__(self, patience=15, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "            return True\n",
    "            \n",
    "        if val_loss > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "            return False\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "            return True\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, device, alpha=0.5):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    magnetic_loss_total = 0\n",
    "    topological_loss_total = 0\n",
    "    \n",
    "    # Class weights to handle imbalance\n",
    "    magnetic_class_weights = torch.tensor([1.0, 1.2, 1.2], device=device)\n",
    "    topological_class_weights = torch.tensor([1.0, 1.5], device=device)\n",
    "    \n",
    "    # Loss functions\n",
    "    magnetic_criterion = nn.CrossEntropyLoss(weight=magnetic_class_weights)\n",
    "    topological_criterion = nn.CrossEntropyLoss(weight=topological_class_weights)\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        magnetic_pred, topological_pred = model(\n",
    "            batch.x, \n",
    "            batch.edge_index, \n",
    "            batch.edge_attr, \n",
    "            batch.structure_features,\n",
    "            batch.batch\n",
    "        )\n",
    "        \n",
    "        # Compute losses\n",
    "        magnetic_loss = magnetic_criterion(magnetic_pred, batch.magnetic_y.squeeze())\n",
    "        topological_loss = topological_criterion(topological_pred, batch.topological_y.squeeze())\n",
    "        \n",
    "        # Combined loss with weighting parameter alpha\n",
    "        loss = alpha * magnetic_loss + (1 - alpha) * topological_loss\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track losses\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "        magnetic_loss_total += magnetic_loss.item() * batch.num_graphs\n",
    "        topological_loss_total += topological_loss.item() * batch.num_graphs\n",
    "    \n",
    "    # Calculate average losses\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    avg_magnetic_loss = magnetic_loss_total / len(dataloader.dataset)\n",
    "    avg_topological_loss = topological_loss_total / len(dataloader.dataset)\n",
    "    \n",
    "    return avg_loss, avg_magnetic_loss, avg_topological_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloader, device, alpha=0.5):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    magnetic_loss_total = 0\n",
    "    topological_loss_total = 0\n",
    "    \n",
    "    magnetic_preds = []\n",
    "    magnetic_targets = []\n",
    "    topological_preds = []\n",
    "    topological_targets = []\n",
    "    \n",
    "    magnetic_class_weights = torch.tensor([1.0, 1.2, 1.2], device=device)\n",
    "    topological_class_weights = torch.tensor([1.0, 1.5], device=device)\n",
    "    \n",
    "    magnetic_criterion = nn.CrossEntropyLoss(weight=magnetic_class_weights)\n",
    "    topological_criterion = nn.CrossEntropyLoss(weight=topological_class_weights)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            magnetic_pred, topological_pred = model(\n",
    "                batch.x, \n",
    "                batch.edge_index, \n",
    "                batch.edge_attr, \n",
    "                batch.structure_features,\n",
    "                batch.batch\n",
    "            )\n",
    "            \n",
    "            # Compute losses\n",
    "            magnetic_loss = magnetic_criterion(magnetic_pred, batch.magnetic_y.squeeze())\n",
    "            topological_loss = topological_criterion(topological_pred, batch.topological_y.squeeze())\n",
    "            \n",
    "            # Combined loss\n",
    "            loss = alpha * magnetic_loss + (1 - alpha) * topological_loss\n",
    "            \n",
    "            # Track losses\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "            magnetic_loss_total += magnetic_loss.item() * batch.num_graphs\n",
    "            topological_loss_total += topological_loss.item() * batch.num_graphs\n",
    "            \n",
    "            # Track predictions for metrics\n",
    "            magnetic_preds.append(magnetic_pred.argmax(dim=1).cpu())\n",
    "            magnetic_targets.append(batch.magnetic_y.squeeze().cpu())\n",
    "            topological_preds.append(topological_pred.argmax(dim=1).cpu())\n",
    "            topological_targets.append(batch.topological_y.squeeze().cpu())\n",
    "    \n",
    "    # Concatenate predictions and targets\n",
    "    magnetic_preds = torch.cat(magnetic_preds)\n",
    "    magnetic_targets = torch.cat(magnetic_targets)\n",
    "    topological_preds = torch.cat(topological_preds)\n",
    "    topological_targets = torch.cat(topological_targets)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    magnetic_acc = accuracy_score(magnetic_targets, magnetic_preds)\n",
    "    magnetic_f1 = f1_score(magnetic_targets, magnetic_preds, average='macro')\n",
    "    topological_acc = accuracy_score(topological_targets, topological_preds)\n",
    "    topological_f1 = f1_score(topological_targets, topological_preds, average='macro')\n",
    "    \n",
    "    # Calculate average losses\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    avg_magnetic_loss = magnetic_loss_total / len(dataloader.dataset)\n",
    "    avg_topological_loss = topological_loss_total / len(dataloader.dataset)\n",
    "    \n",
    "    return (avg_loss, avg_magnetic_loss, avg_topological_loss, \n",
    "            magnetic_acc, magnetic_f1, topological_acc, topological_f1)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, model_save_path=\"./model\"):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping.\n",
    "    \n",
    "    Args:\n",
    "        model: MagneticTopologicalTransformer model\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        device: Device to train on (CPU or GPU)\n",
    "        model_save_path: Directory to save model checkpoints\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained model\n",
    "        history: Training history\n",
    "    \"\"\"\n",
    "    # Create save directory if it doesn't exist\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=PARAMS['lr'], \n",
    "        weight_decay=PARAMS['weight_decay']\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min', \n",
    "        factor=0.5, \n",
    "        patience=10\n",
    "    )\n",
    "    \n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=PARAMS['early_stop_patience'])\n",
    "    \n",
    "    # Initialize best model tracker\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = os.path.join(model_save_path, \"best_model.pt\")\n",
    "    \n",
    "    # Initialize training history\n",
    "    history = {\n",
    "        'train_loss': [], \n",
    "        'val_loss': [],\n",
    "        'train_magnetic_loss': [], \n",
    "        'val_magnetic_loss': [],\n",
    "        'train_topological_loss': [], \n",
    "        'val_topological_loss': [],\n",
    "        'magnetic_acc': [],\n",
    "        'magnetic_f1': [],\n",
    "        'topological_acc': [],\n",
    "        'topological_f1': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    print(\"Starting training...\")\n",
    "    \n",
    "    for epoch in range(PARAMS['max_epochs']):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Train one epoch\n",
    "        train_loss, train_magnetic_loss, train_topological_loss = train_epoch(\n",
    "            model, train_loader, optimizer, device\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_metrics = validate(model, val_loader, device)\n",
    "        (val_loss, val_magnetic_loss, val_topological_loss, \n",
    "         magnetic_acc, magnetic_f1, topological_acc, topological_f1) = val_metrics\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)  # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_magnetic_loss'].append(train_magnetic_loss)\n",
    "        history['val_magnetic_loss'].append(val_magnetic_loss)\n",
    "        history['train_topological_loss'].append(train_topological_loss)\n",
    "        history['val_topological_loss'].append(val_topological_loss)\n",
    "        history['magnetic_acc'].append(magnetic_acc)\n",
    "        history['magnetic_f1'].append(magnetic_f1)\n",
    "        history['topological_acc'].append(topological_acc)\n",
    "        history['topological_f1'].append(topological_f1)\n",
    "\n",
    "        # Print progress\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch+1}/{PARAMS['max_epochs']} - {epoch_time:.2f}s - \"\n",
    "            f\"Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - \"\n",
    "            f\"Magnetic Loss: {train_magnetic_loss:.4f}/{val_magnetic_loss:.4f} - \"\n",
    "            f\"Topological Loss: {train_topological_loss:.4f}/{val_topological_loss:.4f} - \"\n",
    "            f\"Magnetic Acc: {magnetic_acc:.4f} - Magnetic F1: {magnetic_f1:.4f} - \"\n",
    "            f\"Topological Acc: {topological_acc:.4f} - Topological F1: {topological_f1:.4f}\")\n",
    "\n",
    "        # Save checkpoint if best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'history': history,\n",
    "                'best_val_loss': best_val_loss\n",
    "            }, os.path.join(PARAMS['checkpoint_dir'], 'best_model.pth'))\n",
    "            print(f\"Saved best model with validation loss: {best_val_loss:.4f}\")\n",
    "            \n",
    "        # Early stopping check\n",
    "        if val_loss > best_val_loss and epoch > PARAMS['min_epochs']:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= PARAMS['patience']:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "        else:\n",
    "            early_stop_counter = 0\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0\n",
    "    magnetic_loss = 0\n",
    "    topological_loss = 0\n",
    "    \n",
    "    all_magnetic_preds = []\n",
    "    all_magnetic_labels = []\n",
    "    all_topological_preds = []\n",
    "    all_topological_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # No gradient calculation needed for testing\n",
    "        for batch_idx, (data, magnetic_target, topological_target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            magnetic_target = magnetic_target.to(device)\n",
    "            topological_target = topological_target.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            magnetic_output, topological_output = model(data)\n",
    "            \n",
    "            # Calculate losses\n",
    "            batch_magnetic_loss = F.binary_cross_entropy_with_logits(magnetic_output, magnetic_target)\n",
    "            batch_topological_loss = F.binary_cross_entropy_with_logits(topological_output, topological_target)\n",
    "            batch_loss = batch_magnetic_loss + batch_topological_loss\n",
    "            \n",
    "            # Accumulate losses\n",
    "            test_loss += batch_loss.item()\n",
    "            magnetic_loss += batch_magnetic_loss.item()\n",
    "            topological_loss += batch_topological_loss.item()\n",
    "            \n",
    "            # Store predictions and labels for metrics calculation\n",
    "            magnetic_preds = (torch.sigmoid(magnetic_output) > 0.5).float().cpu().numpy()\n",
    "            topological_preds = (torch.sigmoid(topological_output) > 0.5).float().cpu().numpy()\n",
    "            \n",
    "            all_magnetic_preds.extend(magnetic_preds)\n",
    "            all_magnetic_labels.extend(magnetic_target.cpu().numpy())\n",
    "            all_topological_preds.extend(topological_preds)\n",
    "            all_topological_labels.extend(topological_target.cpu().numpy())\n",
    "    \n",
    "    # Calculate average losses\n",
    "    test_loss /= len(test_loader)\n",
    "    magnetic_loss /= len(test_loader)\n",
    "    topological_loss /= len(test_loader)\n",
    "    \n",
    "    # Convert lists to arrays for scikit-learn metrics\n",
    "    all_magnetic_preds = np.array(all_magnetic_preds)\n",
    "    all_magnetic_labels = np.array(all_magnetic_labels)\n",
    "    all_topological_preds = np.array(all_topological_preds)\n",
    "    all_topological_labels = np.array(all_topological_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    magnetic_acc = accuracy_score(all_magnetic_labels, all_magnetic_preds)\n",
    "    magnetic_f1 = f1_score(all_magnetic_labels, all_magnetic_preds, average='weighted')\n",
    "    topological_acc = accuracy_score(all_topological_labels, all_topological_preds)\n",
    "    topological_f1 = f1_score(all_topological_labels, all_topological_preds, average='weighted')\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"Total Loss: {test_loss:.4f}\")\n",
    "    print(f\"Magnetic Loss: {magnetic_loss:.4f}, Accuracy: {magnetic_acc:.4f}, F1 Score: {magnetic_f1:.4f}\")\n",
    "    print(f\"Topological Loss: {topological_loss:.4f}, Accuracy: {topological_acc:.4f}, F1 Score: {topological_f1:.4f}\")\n",
    "    \n",
    "    # Return all metrics\n",
    "    return {\n",
    "        'test_loss': test_loss,\n",
    "        'magnetic_loss': magnetic_loss,\n",
    "        'topological_loss': topological_loss,\n",
    "        'magnetic_acc': magnetic_acc,\n",
    "        'magnetic_f1': magnetic_f1,\n",
    "        'topological_acc': topological_acc,\n",
    "        'topological_f1': topological_f1,\n",
    "        'magnetic_preds': all_magnetic_preds,\n",
    "        'magnetic_labels': all_magnetic_labels,\n",
    "        'topological_preds': all_topological_preds,\n",
    "        'topological_labels': all_topological_labels\n",
    "    }\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pymatgen.core import Structure\n",
    "\n",
    "# Custom dataset for materials data\n",
    "class MaterialsDataset(Dataset):\n",
    "    def __init__(self, struct_dict, magnetic_labels, topological_labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            struct_dict (dict): Dictionary containing materials data with keys:\n",
    "                - structures: list of pymatgen Structure objects\n",
    "                - materials_id: list of material IDs\n",
    "                - nsites: list of number of sites\n",
    "                - formulas: list of chemical formulas\n",
    "                - order: list of order parameters\n",
    "            magnetic_labels (array): Binary labels for magnetic properties\n",
    "            topological_labels (array): Binary labels for topological properties\n",
    "            transform (callable, optional): Optional transform to be applied on features\n",
    "        \"\"\"\n",
    "        self.structures = struct_dict[\"structures\"]\n",
    "        self.materials_ids = struct_dict[\"materials_id\"]\n",
    "        self.nsites = struct_dict[\"nsites\"]\n",
    "        self.formulas = struct_dict[\"formulas\"]\n",
    "        self.order = struct_dict[\"order\"]\n",
    "        \n",
    "        self.magnetic_labels = magnetic_labels\n",
    "        self.topological_labels = topological_labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.structures)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Extract relevant features from the structure\n",
    "        structure = self.structures[idx]\n",
    "        \n",
    "        # Feature extraction from structure\n",
    "        features = self._extract_features(structure, idx)\n",
    "        \n",
    "        magnetic_label = self.magnetic_labels[idx]\n",
    "        topological_label = self.topological_labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            features = self.transform(features)\n",
    "            \n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(magnetic_label, dtype=torch.float32), torch.tensor(topological_label, dtype=torch.float32)\n",
    "    \n",
    "    def _extract_features(self, structure, idx):\n",
    "        \"\"\"Extract features from a pymatgen Structure object and other available data\"\"\"\n",
    "        # Here you can implement feature extraction based on the structure\n",
    "        # This is a simple example - you'll want to enhance this based on your domain knowledge\n",
    "        \n",
    "        # Basic structural features\n",
    "        num_sites = self.nsites[idx]\n",
    "        order_param = self.order[idx]\n",
    "        \n",
    "        # Get lattice parameters\n",
    "        a, b, c = structure.lattice.abc\n",
    "        alpha, beta, gamma = structure.lattice.angles\n",
    "        volume = structure.volume\n",
    "        density = structure.density\n",
    "        \n",
    "        # Element-based features (example)\n",
    "        elements = [site.specie.symbol for site in structure]\n",
    "        unique_elements = set(elements)\n",
    "        num_elements = len(unique_elements)\n",
    "        \n",
    "        # Count of each element\n",
    "        element_counts = {}\n",
    "        for element in elements:\n",
    "            if element in element_counts:\n",
    "                element_counts[element] += 1\n",
    "            else:\n",
    "                element_counts[element] = 1\n",
    "        \n",
    "        # Statistical features of atomic properties\n",
    "        atomic_numbers = [site.specie.Z for site in structure]\n",
    "        avg_atomic_number = np.mean(atomic_numbers)\n",
    "        std_atomic_number = np.std(atomic_numbers)\n",
    "        \n",
    "        # Combine all features\n",
    "        features = [\n",
    "            num_sites, \n",
    "            order_param,\n",
    "            a, b, c, \n",
    "            alpha, beta, gamma,\n",
    "            volume,\n",
    "            density,\n",
    "            num_elements,\n",
    "            avg_atomic_number,\n",
    "            std_atomic_number\n",
    "        ]\n",
    "        \n",
    "        # You can add more domain-specific features here\n",
    "        \n",
    "        return np.array(features, dtype=np.float32)\n",
    "\n",
    "# Model Definition - Multi-task Neural Network\n",
    "class MagneticTopologicalModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=[256, 128, 64], dropout_rate=0.3):\n",
    "        super(MagneticTopologicalModel, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        \n",
    "        # Shared layers\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(dim))\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_dim = dim\n",
    "        \n",
    "        self.shared_layers = nn.Sequential(*layers)\n",
    "        \n",
    "        # Task-specific heads\n",
    "        self.magnetic_head = nn.Linear(hidden_dims[-1], 1)\n",
    "        self.topological_head = nn.Linear(hidden_dims[-1], 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through shared layers\n",
    "        shared_features = self.shared_layers(x)\n",
    "        \n",
    "        # Task-specific predictions\n",
    "        magnetic_output = self.magnetic_head(shared_features)\n",
    "        topological_output = self.topological_head(shared_features)\n",
    "        \n",
    "        return magnetic_output.squeeze(), topological_output.squeeze()\n",
    "\n",
    "def train_epoch(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    magnetic_loss = 0\n",
    "    topological_loss = 0\n",
    "    \n",
    "    all_magnetic_preds = []\n",
    "    all_magnetic_labels = []\n",
    "    all_topological_preds = []\n",
    "    all_topological_labels = []\n",
    "    \n",
    "    for batch_idx, (data, magnetic_target, topological_target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        magnetic_target = magnetic_target.to(device)\n",
    "        topological_target = topological_target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        magnetic_output, topological_output = model(data)\n",
    "        \n",
    "        # Calculate losses\n",
    "        batch_magnetic_loss = F.binary_cross_entropy_with_logits(magnetic_output, magnetic_target)\n",
    "        batch_topological_loss = F.binary_cross_entropy_with_logits(topological_output, topological_target)\n",
    "        batch_loss = batch_magnetic_loss + batch_topological_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate losses\n",
    "        train_loss += batch_loss.item()\n",
    "        magnetic_loss += batch_magnetic_loss.item()\n",
    "        topological_loss += batch_topological_loss.item()\n",
    "        \n",
    "        # Store predictions and labels for metrics calculation\n",
    "        magnetic_preds = (torch.sigmoid(magnetic_output) > 0.5).float().cpu().numpy()\n",
    "        topological_preds = (torch.sigmoid(topological_output) > 0.5).float().cpu().numpy()\n",
    "        \n",
    "        all_magnetic_preds.extend(magnetic_preds)\n",
    "        all_magnetic_labels.extend(magnetic_target.cpu().numpy())\n",
    "        all_topological_preds.extend(topological_preds)\n",
    "        all_topological_labels.extend(topological_target.cpu().numpy())\n",
    "    \n",
    "    # Calculate average losses\n",
    "    train_loss /= len(train_loader)\n",
    "    magnetic_loss /= len(train_loader)\n",
    "    topological_loss /= len(train_loader)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    magnetic_acc = accuracy_score(all_magnetic_labels, all_magnetic_preds)\n",
    "    magnetic_f1 = f1_score(all_magnetic_labels, all_magnetic_preds, average='weighted')\n",
    "    topological_acc = accuracy_score(all_topological_labels, all_topological_preds)\n",
    "    topological_f1 = f1_score(all_topological_labels, all_topological_preds, average='weighted')\n",
    "    \n",
    "    return train_loss, magnetic_loss, topological_loss, magnetic_acc, magnetic_f1, topological_acc, topological_f1\n",
    "\n",
    "def validate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    magnetic_loss = 0\n",
    "    topological_loss = 0\n",
    "    \n",
    "    all_magnetic_preds = []\n",
    "    all_magnetic_labels = []\n",
    "    all_topological_preds = []\n",
    "    all_topological_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, magnetic_target, topological_target) in enumerate(val_loader):\n",
    "            data = data.to(device)\n",
    "            magnetic_target = magnetic_target.to(device)\n",
    "            topological_target = topological_target.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            magnetic_output, topological_output = model(data)\n",
    "            \n",
    "            # Calculate losses\n",
    "            batch_magnetic_loss = F.binary_cross_entropy_with_logits(magnetic_output, magnetic_target)\n",
    "            batch_topological_loss = F.binary_cross_entropy_with_logits(topological_output, topological_target)\n",
    "            batch_loss = batch_magnetic_loss + batch_topological_loss\n",
    "            \n",
    "            # Accumulate losses\n",
    "            val_loss += batch_loss.item()\n",
    "            magnetic_loss += batch_magnetic_loss.item()\n",
    "            topological_loss += batch_topological_loss.item()\n",
    "            \n",
    "            # Store predictions and labels for metrics calculation\n",
    "            magnetic_preds = (torch.sigmoid(magnetic_output) > 0.5).float().cpu().numpy()\n",
    "            topological_preds = (torch.sigmoid(topological_output) > 0.5).float().cpu().numpy()\n",
    "            \n",
    "            all_magnetic_preds.extend(magnetic_preds)\n",
    "            all_magnetic_labels.extend(magnetic_target.cpu().numpy())\n",
    "            all_topological_preds.extend(topological_preds)\n",
    "            all_topological_labels.extend(topological_target.cpu().numpy())\n",
    "    \n",
    "    # Calculate average losses\n",
    "    val_loss /= len(val_loader)\n",
    "    magnetic_loss /= len(val_loader)\n",
    "    topological_loss /= len(val_loader)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    magnetic_acc = accuracy_score(all_magnetic_labels, all_magnetic_preds)\n",
    "    magnetic_f1 = f1_score(all_magnetic_labels, all_magnetic_preds, average='weighted')\n",
    "    topological_acc = accuracy_score(all_topological_labels, all_topological_preds)\n",
    "    topological_f1 = f1_score(all_topological_labels, all_topological_preds, average='weighted')\n",
    "    \n",
    "    return val_loss, magnetic_loss, topological_loss, magnetic_acc, magnetic_f1, topological_acc, topological_f1\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    magnetic_loss = 0\n",
    "    topological_loss = 0\n",
    "    \n",
    "    all_magnetic_preds = []\n",
    "    all_magnetic_labels = []\n",
    "    all_topological_preds = []\n",
    "    all_topological_labels = []\n",
    "    all_material_ids = []  # To track which materials were predicted correctly/incorrectly\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, magnetic_target, topological_target) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            magnetic_target = magnetic_target.to(device)\n",
    "            topological_target = topological_target.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            magnetic_output, topological_output = model(data)\n",
    "            \n",
    "            # Calculate losses\n",
    "            batch_magnetic_loss = F.binary_cross_entropy_with_logits(magnetic_output, magnetic_target)\n",
    "            batch_topological_loss = F.binary_cross_entropy_with_logits(topological_output, topological_target)\n",
    "            batch_loss = batch_magnetic_loss + batch_topological_loss\n",
    "            \n",
    "            # Accumulate losses\n",
    "            test_loss += batch_loss.item()\n",
    "            magnetic_loss += batch_magnetic_loss.item()\n",
    "            topological_loss += batch_topological_loss.item()\n",
    "            \n",
    "            # Store predictions and labels for metrics calculation\n",
    "            magnetic_preds = (torch.sigmoid(magnetic_output) > 0.5).float().cpu().numpy()\n",
    "            topological_preds = (torch.sigmoid(topological_output) > 0.5).float().cpu().numpy()\n",
    "            \n",
    "            all_magnetic_preds.extend(magnetic_preds)\n",
    "            all_magnetic_labels.extend(magnetic_target.cpu().numpy())\n",
    "            all_topological_preds.extend(topological_preds)\n",
    "            all_topological_labels.extend(topological_target.cpu().numpy())\n",
    "            \n",
    "            # Track material IDs for this batch (if available in the dataset)\n",
    "            # all_material_ids.extend([test_loader.dataset.materials_ids[idx] for idx in range(batch_idx * test_loader.batch_size, min((batch_idx + 1) * test_loader.batch_size, len(test_loader.dataset)))])\n",
    "    \n",
    "    # Calculate average losses\n",
    "    test_loss /= len(test_loader)\n",
    "    magnetic_loss /= len(test_loader)\n",
    "    topological_loss /= len(test_loader)\n",
    "    \n",
    "    # Convert lists to arrays for scikit-learn metrics\n",
    "    all_magnetic_preds = np.array(all_magnetic_preds)\n",
    "    all_magnetic_labels = np.array(all_magnetic_labels)\n",
    "    all_topological_preds = np.array(all_topological_preds)\n",
    "    all_topological_labels = np.array(all_topological_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    magnetic_acc = accuracy_score(all_magnetic_labels, all_magnetic_preds)\n",
    "    magnetic_f1 = f1_score(all_magnetic_labels, all_magnetic_preds, average='weighted')\n",
    "    topological_acc = accuracy_score(all_topological_labels, all_topological_preds)\n",
    "    topological_f1 = f1_score(all_topological_labels, all_topological_preds, average='weighted')\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Test Results:\")\n",
    "    print(f\"Total Loss: {test_loss:.4f}\")\n",
    "    print(f\"Magnetic Loss: {magnetic_loss:.4f}, Accuracy: {magnetic_acc:.4f}, F1 Score: {magnetic_f1:.4f}\")\n",
    "    print(f\"Topological Loss: {topological_loss:.4f}, Accuracy: {topological_acc:.4f}, F1 Score: {topological_f1:.4f}\")\n",
    "    \n",
    "    # Calculate and plot confusion matrices\n",
    "    plot_confusion_matrices(all_magnetic_labels, all_magnetic_preds, all_topological_labels, all_topological_preds)\n",
    "    \n",
    "    return {\n",
    "        'test_loss': test_loss,\n",
    "        'magnetic_loss': magnetic_loss,\n",
    "        'topological_loss': topological_loss,\n",
    "        'magnetic_acc': magnetic_acc,\n",
    "        'magnetic_f1': magnetic_f1,\n",
    "        'topological_acc': topological_acc,\n",
    "        'topological_f1': topological_f1,\n",
    "        'magnetic_preds': all_magnetic_preds,\n",
    "        'magnetic_labels': all_magnetic_labels,\n",
    "        'topological_preds': all_topological_preds,\n",
    "        'topological_labels': all_topological_labels\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrices(magnetic_labels, magnetic_preds, topological_labels, topological_preds):\n",
    "    # Create figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    # Plot magnetic confusion matrix\n",
    "    magnetic_cm = confusion_matrix(magnetic_labels, magnetic_preds)\n",
    "    sns.heatmap(magnetic_cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axes[0])\n",
    "    axes[0].set_title(\"Magnetic Property Confusion Matrix\")\n",
    "    axes[0].set_xlabel(\"Predicted\")\n",
    "    axes[0].set_ylabel(\"True\")\n",
    "    \n",
    "    # Plot topological confusion matrix\n",
    "    topological_cm = confusion_matrix(topological_labels, topological_preds)\n",
    "    sns.heatmap(topological_cm, annot=True, fmt=\"d\", cmap=\"Greens\", ax=axes[1])\n",
    "    axes[1].set_title(\"Topological Property Confusion Matrix\")\n",
    "    axes[1].set_xlabel(\"Predicted\")\n",
    "    axes[1].set_ylabel(\"True\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrices.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Print additional metrics\n",
    "    print(\"\\nDetailed Classification Results:\")\n",
    "    print(\"Magnetic Property:\")\n",
    "    print(f\"True Positive: {magnetic_cm[1, 1]}\")\n",
    "    print(f\"False Positive: {magnetic_cm[0, 1]}\")\n",
    "    print(f\"True Negative: {magnetic_cm[0, 0]}\")\n",
    "    print(f\"False Negative: {magnetic_cm[1, 0]}\")\n",
    "    \n",
    "    print(\"\\nTopological Property:\")\n",
    "    print(f\"True Positive: {topological_cm[1, 1]}\")\n",
    "    print(f\"False Positive: {topological_cm[0, 1]}\")\n",
    "    print(f\"True Negative: {topological_cm[0, 0]}\")\n",
    "    print(f\"False Negative: {topological_cm[1, 0]}\")\n",
    "\n",
    "# Main training function\n",
    "def train_model(train_struct_dict, val_struct_dict, train_magnetic_labels, train_topological_labels, \n",
    "               val_magnetic_labels, val_topological_labels, params):\n",
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = MaterialsDataset(train_struct_dict, train_magnetic_labels, train_topological_labels)\n",
    "    val_dataset = MaterialsDataset(val_struct_dict, val_magnetic_labels, val_topological_labels)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
    "    \n",
    "    # Determine input dimension based on feature extraction\n",
    "    sample_features = train_dataset[0][0]\n",
    "    input_dim = sample_features.shape[0]\n",
    "    \n",
    "    # Initialize model\n",
    "    model = MagneticTopologicalModel(input_dim, hidden_dims=params['hidden_dims'], \n",
    "                                     dropout_rate=params['dropout_rate']).to(device)\n",
    "    \n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    best_val_loss = float('inf')\n",
    "    early_stop_counter = 0\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_magnetic_loss': [], 'val_magnetic_loss': [],\n",
    "        'train_topological_loss': [], 'val_topological_loss': [],\n",
    "        'magnetic_acc': [], 'magnetic_f1': [],\n",
    "        'topological_acc': [], 'topological_f1': []\n",
    "    }\n",
    "    \n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(params['checkpoint_dir'], exist_ok=True)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(params['max_epochs']):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # Train one epoch\n",
    "        train_loss, train_magnetic_loss, train_topological_loss, magnetic_acc, magnetic_f1, topological_acc, topological_f1 = train_epoch(model, train_loader, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_magnetic_loss, val_topological_loss, val_magnetic_acc, val_magnetic_f1, val_topological_acc, val_topological_f1 = validate(model, val_loader, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_magnetic_loss'].append(train_magnetic_loss)\n",
    "        history['val_magnetic_loss'].append(val_magnetic_loss)\n",
    "        history['train_topological_loss'].append(train_topological_loss)\n",
    "        history['val_topological_loss'].append(val_topological_loss)\n",
    "        history['magnetic_acc'].append(val_magnetic_acc)\n",
    "        history['magnetic_f1'].append(val_magnetic_f1)\n",
    "        history['topological_acc'].append(val_topological_acc)\n",
    "        history['topological_f1'].append(val_topological_f1)\n",
    "        \n",
    "        # Print progress\n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f\"Epoch {epoch+1}/{params['max_epochs']} - {epoch_time:.2f}s - \"\n",
    "              f\"Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - \"\n",
    "              f\"Magnetic Loss: {train_magnetic_loss:.4f}/{val_magnetic_loss:.4f} - \"\n",
    "              f\"Topological Loss: {train_topological_loss:.4f}/{val_topological_loss:.4f} - \"\n",
    "              f\"Magnetic Acc: {val_magnetic_acc:.4f} - Magnetic F1: {val_magnetic_f1:.4f} - \"\n",
    "              f\"Topological Acc: {val_topological_acc:.4f} - Topological F1: {val_topological_f1:.4f}\")\n",
    "        \n",
    "        # Save checkpoint if best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'history': history,\n",
    "                'best_val_loss': best_val_loss\n",
    "            }, os.path.join(params['checkpoint_dir'], 'best_model.pth'))\n",
    "            print(f\"Saved best model with validation loss: {best_val_loss:.4f}\")\n",
    "            \n",
    "            # Reset early stopping counter\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            # Increment early stopping counter\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= params['patience'] and epoch > params['min_epochs']:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def plot_training_history(history):\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot losses\n",
    "    axs[0, 0].plot(epochs, history['train_loss'], 'b-', label='Training Loss')\n",
    "    axs[0, 0].plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n",
    "    axs[0, 0].set_title('Total Loss')\n",
    "    axs[0, 0].set_xlabel('Epochs')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].legend()\n",
    "    \n",
    "    # Plot task-specific losses\n",
    "    axs[0, 1].plot(epochs, history['train_magnetic_loss'], 'b--', label='Train Magnetic Loss')\n",
    "    axs[0, 1].plot(epochs, history['val_magnetic_loss'], 'r--', label='Val Magnetic Loss')\n",
    "    axs[0, 1].plot(epochs, history['train_topological_loss'], 'g--', label='Train Topological Loss')\n",
    "    axs[0, 1].plot(epochs, history['val_topological_loss'], 'm--', label='Val Topological Loss')\n",
    "    axs[0, 1].set_title('Task-Specific Losses')\n",
    "    axs[0, 1].set_xlabel('Epochs')\n",
    "    axs[0, 1].set_ylabel('Loss')\n",
    "    axs[0, 1].legend()\n",
    "    \n",
    "    # Plot magnetic metrics\n",
    "    axs[1, 0].plot(epochs, history['magnetic_acc'], 'b-', label='Magnetic Accuracy')\n",
    "    axs[1, 0].plot(epochs, history['magnetic_f1'], 'r-', label='Magnetic F1 Score')\n",
    "    axs[1, 0].set_title('Magnetic Property Metrics')\n",
    "    axs[1, 0].set_xlabel('Epochs')\n",
    "    axs[1, 0].set_ylabel('Score')\n",
    "    axs[1, 0].legend()\n",
    "    \n",
    "    # Plot topological metrics\n",
    "    axs[1, 1].plot(epochs, history['topological_acc'], 'b-', label='Topological Accuracy')\n",
    "    axs[1, 1].plot(epochs, history['topological_f1'], 'r-', label='Topological F1 Score')\n",
    "    axs[1, 1].set_title('Topological Property Metrics')\n",
    "    axs[1, 1].set_xlabel('Epochs')\n",
    "    axs[1, 1].set_ylabel('Score')\n",
    "    axs[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.show()\n",
    "\n",
    "# Main test function\n",
    "def run_test(test_struct_dict, test_magnetic_labels, test_topological_labels, checkpoint_path, batch_size=32):\n",
    "    # Setup device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = MaterialsDataset(test_struct_dict, test_magnetic_labels, test_topological_labels)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Determine input dimension based on feature extraction\n",
    "    sample_features = test_dataset[0][0]\n",
    "    input_dim = sample_features.shape[0]\n",
    "    \n",
    "    # Initialize model\n",
    "    model = MagneticTopologicalModel(input_dim).to(device)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded model from epoch {checkpoint['epoch']+1} with validation loss: {checkpoint['best_val_loss']:.4f}\")\n",
    "    \n",
    "    # Test the model\n",
    "    test_results = test_model(model, test_loader, device)\n",
    "    \n",
    "    # You can add more analysis here based on test_results\n",
    "    \n",
    "    return test_results, model\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Define hyperparameters\n",
    "    PARAMS = {\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 0.001,\n",
    "        'weight_decay': 1e-5,\n",
    "        'hidden_dims': [256, 128, 64],\n",
    "        'dropout_rate': 0.3,\n",
    "        'max_epochs': 100,\n",
    "        'min_epochs': 10,\n",
    "        'patience': 10,\n",
    "        'checkpoint_dir': './checkpoints'\n",
    "    }\n",
    "    \n",
    "    # You would need to prepare these variables:\n",
    "    # 1. train_struct_dict, val_struct_dict, test_struct_dict - dictionaries with your structure data\n",
    "    # 2. train_magnetic_labels, train_topological_labels - binary labels for training\n",
    "    # 3. val_magnetic_labels, val_topological_labels - binary labels for validation\n",
    "    # 4. test_magnetic_labels, test_topological_labels - binary labels for testing\n",
    "    \n",
    "    # Example training call:\n",
    "    # model, history = train_model(train_struct_dict, val_struct_dict, \n",
    "    #                            train_magnetic_labels, train_topological_labels,\n",
    "    #                            val_magnetic_labels, val_topological_labels, \n",
    "    #                            PARAMS)\n",
    "    \n",
    "    # Example testing call:\n",
    "    # test_results, model = run_test(test_struct_dict, test_magnetic_labels, test_topological_labels,\n",
    "    #                               os.path.join(PARAMS['checkpoint_dir'], 'best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first attempt at multi task learning and integration with topological quantum chemistry database\n",
    "import e3nn.util\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "\n",
    "import e3nn\n",
    "from e3nn import o3\n",
    "#from e3nn.util.datatypes import DataPeriodicNeighbors\n",
    "#from e3nn.nn._gate import GatedConvParityNetwork\n",
    "#from e3nn.math._linalg import Kernel\n",
    "\n",
    "import pymatgen as mg\n",
    "import pymatgen.io\n",
    "from pymatgen.core.structure import Structure\n",
    "import pymatgen.analysis.magnetism.analyzer as pg\n",
    "from mp_api.client import MPRester\n",
    "import numpy as np\n",
    "import pickle\n",
    "from mendeleev import element\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import io\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import time, os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "load_dotenv(Path(\"/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/Integrated_Magnetic_Topological/matprojectapi.env\"))\n",
    "api_key = os.getenv(\"MP_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pymatgen as pg\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.analysis.magnetism import CollinearMagneticStructureAnalyzer\n",
    "\n",
    "order_list_mp = []\n",
    "structures_list_mp = []\n",
    "formula_list_mp = []\n",
    "sites_list = []\n",
    "id_list_mp = []\n",
    "y_values_mp = []\n",
    "\n",
    "order_encode = {\"NM\": 0, \"AFM\": 1, \"FM\": 2, \"FiM\": 2}\n",
    "topo_encode = {False: 0, True: 1}\n",
    "\n",
    "# Load data\n",
    "mp_structures_dict = torch.load('/Users/abiralshakya/Documents/Research/Topological_Insulators_OnGithub/generative_nmti/Integrated_Magnetic_Topological/magnetic_order/preload_data/mp_structures_2025-04-07_12-52.pt', \n",
    "                                weights_only=False)\n",
    "\n",
    "structures = mp_structures_dict['structures']\n",
    "materials = mp_structures_dict['materials_id']\n",
    "formulas = mp_structures_dict['formulas']\n",
    "orders = mp_structures_dict['order']\n",
    "nsites = mp_structures_dict['nsites']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_list = []\n",
    "\n",
    "for struct in structures:\n",
    "    analyzer = CollinearMagneticStructureAnalyzer(struct)\n",
    "    order_list.append(analyzer.ordering.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_NM = [i for i, order in enumerate(order_list) if order == 'NM']\n",
    "id_AFM = [i for i, order in enumerate(order_list) if order == 'AFM']\n",
    "id_FM = [i for i, order in enumerate(order_list) if order in ['FM', 'FiM']]\n",
    "\n",
    "# Shuffle\n",
    "np.random.shuffle(id_NM)\n",
    "np.random.shuffle(id_FM)\n",
    "np.random.shuffle(id_AFM)\n",
    "\n",
    "# Balance dataset (keeping AFM as reference size)\n",
    "id_AFM, id_AFM_to_delete = np.split(id_AFM, [int(len(id_AFM))])\n",
    "id_NM, id_NM_to_delete = np.split(id_NM, [int(1.2 * len(id_AFM))])\n",
    "id_FM, id_FM_to_delete = np.split(id_FM, [int(1.2 * len(id_AFM))])\n",
    "\n",
    "# Final index list\n",
    "selected_ids = np.concatenate((id_NM, id_FM, id_AFM))\n",
    "np.random.shuffle(selected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in selected_ids:\n",
    "    structure = structures[idx]\n",
    "    material_id = materials[idx]\n",
    "    formula = formulas[idx]\n",
    "    nsite = nsites[idx]\n",
    "\n",
    "    analyzer = CollinearMagneticStructureAnalyzer(structure)\n",
    "    ordering = analyzer.ordering\n",
    "\n",
    "    structures_list_mp.append(structure)\n",
    "    id_list_mp.append(material_id)\n",
    "    formula_list_mp.append(formula)\n",
    "    sites_list.append(nsite)\n",
    "    order_list_mp.append(ordering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 16710.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-1245108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 25731.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-1184067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 25731.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 22192.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-1067880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 23301.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-10658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 28532.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-1184113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 32263.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-613989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 23301.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 1/1 [00:00<00:00, 18157.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No topological info for mp-2647013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "topo_encode = {False: 0, True: 1}\n",
    "topo_labels = []\n",
    "\n",
    "from mp_api.client import MPRester\n",
    "m = MPRester(api_key=api_key)\n",
    "\n",
    "for material_id in id_list_mp:\n",
    "    try:\n",
    "        result = m.materials.summary.search(material_ids=[material_id])\n",
    "        if result and hasattr(result[0], \"is_topological\"):\n",
    "            label = result[0].is_topological\n",
    "            topo_labels.append(topo_encode[label])\n",
    "        else:\n",
    "            print(f\"No topological info for {material_id}\")\n",
    "            topo_labels.append(topo_encode[False])\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving TI label for {material_id}: {e}\")\n",
    "        topo_labels.append(topo_encode[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pymatgen.core import Structure\n",
    "\n",
    "def fetch_tqc_magnetic_data(bcs_id=\"3.7\"):\n",
    "    \"\"\"\n",
    "    Fetch magnetic topological materials data from the TQC database\n",
    "    \"\"\"\n",
    "    # Simulated example structure — replace with API call in production\n",
    "    return {\n",
    "        \"magnetic_materials\": [\n",
    "            {\n",
    "                \"id\": \"mp-123\",\n",
    "                \"formula\": \"Fe2O3\",\n",
    "                \"spacegroup\": 167,\n",
    "                \"magnetic_ordering\": \"AFM\",\n",
    "                \"topological_class\": \"Strong TI\",\n",
    "                \"band_gap\": 0.8,\n",
    "                \"magnetic_moment\": 4.2\n",
    "            },\n",
    "            # Add more entries as needed\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def create_combined_dataset(mp_structures, tqc_data):\n",
    "    \"\"\"\n",
    "    Combine Materials Project structures (as Structure objects or dicts) with TQC magnetic data\n",
    "    \"\"\"\n",
    "    tqc_map = {item[\"id\"]: item for item in tqc_data[\"magnetic_materials\"]}\n",
    "    combined_data = []\n",
    "\n",
    "    for struct in mp_structures:\n",
    "        # Handle both dict and Structure input\n",
    "        if isinstance(struct, dict):\n",
    "            mp_id = struct.get(\"material_id\")\n",
    "            structure = struct.get(\"structure\")\n",
    "            formula = struct.get(\"pretty_formula\")\n",
    "            nsites = struct.get(\"nsites\")\n",
    "        elif isinstance(struct, Structure):\n",
    "            mp_id = getattr(struct, \"material_id\", None)\n",
    "            structure = struct\n",
    "            formula = structure.formula\n",
    "            nsites = structure.num_sites\n",
    "        else:\n",
    "            continue  # skip unknown formats\n",
    "\n",
    "        if mp_id in tqc_map:\n",
    "            tqc_info = tqc_map[mp_id]\n",
    "            struct_data = {\n",
    "                \"structure\": structure,\n",
    "                \"material_id\": mp_id,\n",
    "                \"formula\": formula,\n",
    "                \"nsites\": nsites,\n",
    "                \"magnetic_ordering\": tqc_info[\"magnetic_ordering\"],\n",
    "                \"topological_class\": tqc_info[\"topological_class\"],\n",
    "                \"band_gap\": tqc_info.get(\"band_gap\", None),\n",
    "                \"magnetic_moment\": tqc_info.get(\"magnetic_moment\", None),\n",
    "                \"symmetry_operations\": tqc_info.get(\"symmetry_operations\", None)\n",
    "            }\n",
    "            combined_data.append(struct_data)\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "# Example usage:\n",
    "tqc_data = fetch_tqc_magnetic_data(bcs_id=\"3.7\")\n",
    "combined_dataset = create_combined_dataset(structures, tqc_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.analysis.local_env import CrystalNN\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "import torch\n",
    "\n",
    "def extract_magnetic_features(structure):\n",
    "    \"\"\"\n",
    "    Extract features relevant for magnetic ordering classification\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "\n",
    "    # 1. Magnetic elements\n",
    "    magnetic_elements = ['Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Ce', 'Pr', 'Nd',\n",
    "                         'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb']\n",
    "    element_counts = {}\n",
    "    total_atoms = len(structure)\n",
    "\n",
    "    for site in structure:\n",
    "        symbol = str(site.specie.symbol)\n",
    "        element_counts[symbol] = element_counts.get(symbol, 0) + 1\n",
    "\n",
    "    magnetic_fraction = sum(element_counts.get(el, 0) for el in magnetic_elements) / total_atoms\n",
    "    features['magnetic_fraction'] = magnetic_fraction\n",
    "\n",
    "    # 2. Magnetic exchange pathways\n",
    "    magnetic_sites = [i for i, site in enumerate(structure) if str(site.specie.symbol) in magnetic_elements]\n",
    "    exchange_distances = []\n",
    "\n",
    "    for i in magnetic_sites:\n",
    "        for j in magnetic_sites:\n",
    "            if i < j:\n",
    "                distance = structure.get_distance(i, j)\n",
    "                if distance < 4.0:\n",
    "                    exchange_distances.append(distance)\n",
    "\n",
    "    if exchange_distances:\n",
    "        features['avg_exchange_distance'] = sum(exchange_distances) / len(exchange_distances)\n",
    "        features['min_exchange_distance'] = min(exchange_distances)\n",
    "    else:\n",
    "        features['avg_exchange_distance'] = 0.0\n",
    "        features['min_exchange_distance'] = 0.0\n",
    "\n",
    "    # 3. Crystal field distortion (optional, just log one example distortion)\n",
    "    # NOTE: This can produce many features, we log just one for simplicity\n",
    "    distortion_list = []\n",
    "    for i in magnetic_sites:\n",
    "        neighbors = structure.get_neighbors(structure[i], 3.0)\n",
    "        if neighbors:\n",
    "            distances = [n[1] for n in neighbors]\n",
    "            avg_distance = sum(distances) / len(distances)\n",
    "            distortion = sum((d - avg_distance)**2 for d in distances) / len(distances)\n",
    "            distortion_list.append(distortion)\n",
    "\n",
    "    features['avg_coordination_distortion'] = (\n",
    "        sum(distortion_list) / len(distortion_list) if distortion_list else 0.0\n",
    "    )\n",
    "\n",
    "    # 4. Symmetry features\n",
    "    try:\n",
    "        analyzer = SpacegroupAnalyzer(structure)\n",
    "        spacegroup = analyzer.get_space_group_number()\n",
    "    except Exception:\n",
    "        spacegroup = 0  # fallback if symmetry detection fails\n",
    "\n",
    "    features['spacegroup'] = spacegroup\n",
    "\n",
    "    # 5. Time-reversal breaking (heuristic)\n",
    "    features['potential_time_reversal_breaking'] = 1 if magnetic_fraction > 0.1 else 0\n",
    "\n",
    "    return features\n",
    "\n",
    "# Apply feature extraction to all structures\n",
    "magnetic_features = []\n",
    "for struct in structures_list_mp:\n",
    "    magnetic_features.append(extract_magnetic_features(struct))\n",
    "\n",
    "# Convert to tensor (ensure values are numeric)\n",
    "magnetic_feature_tensor = torch.tensor([\n",
    "    [\n",
    "        float(f['magnetic_fraction']),\n",
    "        float(f['avg_exchange_distance']),\n",
    "        float(f['min_exchange_distance']),\n",
    "        int(f['spacegroup']),\n",
    "        int(f['potential_time_reversal_breaking'])\n",
    "    ]\n",
    "    for f in magnetic_features\n",
    "], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import e3nn.nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "class MagneticTopologicalClassifier(torch.nn.Module):\n",
    "    def __init__(self, atom_type_in, hidden_dim=128, model_kwargs=None):\n",
    "        super().__init__()\n",
    "        if model_kwargs is None:\n",
    "            model_kwargs = {}\n",
    "\n",
    "        # Atom embedding\n",
    "        self.atom_embedding = torch.nn.Linear(atom_type_in, hidden_dim)\n",
    "        \n",
    "        # Magnetic attention module\n",
    "        self.magnetic_attention = MagneticAttention(hidden_dim)\n",
    "        \n",
    "        # E3NN convolution layers (you must define GatedConvParityNetwork elsewhere)\n",
    "        self.model = e3nn.nn.Gate(**model_kwargs)\n",
    "       # self.model = GatedConvParityNetwork(**model_kwargs)\n",
    "        \n",
    "        # Magnetic ordering head\n",
    "        self.magnetic_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 3)  # NM, AFM, FM/FiM\n",
    "        )\n",
    "        \n",
    "        # Topological classification head\n",
    "        self.topological_head = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 4)  # None, Weak TI, Strong TI, HOTI\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch=None, n_norm=35):\n",
    "        # Initial embedding\n",
    "        x = self.atom_embedding(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Magnetic attention layer\n",
    "        x = self.magnetic_attention(x, edge_index, edge_attr)\n",
    "        \n",
    "        # E3NN-based processing\n",
    "        x = self.model(x, edge_index, edge_attr, n_norm=n_norm)\n",
    "        \n",
    "        # Global pooling\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        x_global = scatter_add(x, batch, dim=0)\n",
    "        \n",
    "        # Classification heads\n",
    "        magnetic_pred = self.magnetic_head(x_global)\n",
    "        topological_pred = self.topological_head(x_global)\n",
    "        \n",
    "        return magnetic_pred, topological_pred\n",
    "\n",
    "\n",
    "class MagneticAttention(MessagePassing):\n",
    "    \"\"\"\n",
    "    Attention mechanism for magnetic interactions\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__(aggr='add')  # Aggregation function\n",
    "        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.k_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.att_proj = nn.Linear(2 * hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        q = self.q_proj(x)\n",
    "        k = self.k_proj(x)\n",
    "        v = self.v_proj(x)\n",
    "        return self.propagate(edge_index, q=q, k=k, v=v, edge_attr=edge_attr)\n",
    "\n",
    "    def message(self, q_i, k_j, v_j, edge_attr):\n",
    "        attention_input = torch.cat([q_i, k_j], dim=-1)\n",
    "        alpha = F.leaky_relu(self.att_proj(attention_input).squeeze(-1))\n",
    "        alpha = torch.softmax(alpha, dim=0)\n",
    "        return alpha.unsqueeze(-1) * v_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def evaluate_multi_task(model, dataloader, device):\n",
    "    \"\"\"Evaluate model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    magnetic_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    topological_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    magnetic_loss_cumulative = 0.0\n",
    "    topological_loss_cumulative = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in dataloader:\n",
    "            d.to(device)\n",
    "            # Forward pass\n",
    "            magnetic_pred, topological_pred = model(d.x, d.edge_index, d.edge_attr, \n",
    "                                                  n_norm=True, batch=d.batch)\n",
    "            # Compute losses\n",
    "            magnetic_loss = magnetic_loss_fn(magnetic_pred, d.magnetic_y)\n",
    "            topological_loss = topological_loss_fn(topological_pred, d.topological_y)\n",
    "            \n",
    "            # Update cumulative losses\n",
    "            magnetic_loss_cumulative += magnetic_loss.detach().item()\n",
    "            topological_loss_cumulative += topological_loss.detach().item()\n",
    "    \n",
    "    # Compute average losses\n",
    "    magnetic_valid_loss = magnetic_loss_cumulative / len(dataloader)\n",
    "    topological_valid_loss = topological_loss_cumulative / len(dataloader)\n",
    "    \n",
    "    return magnetic_valid_loss, topological_valid_loss\n",
    "\n",
    "def multi_task_training(model, dataloader, dataloader_valid, max_iter=101, device=\"cpu\"):\n",
    "    # Define parameters\n",
    "    params = {\n",
    "        'adamw_lr': 0.001,  # Learning rate for AdamW optimizer\n",
    "        'adamw_wd': 0.01    # Weight decay for AdamW optimizer\n",
    "    }\n",
    "    \n",
    "    model.to(device)\n",
    "    # Loss functions\n",
    "    magnetic_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    topological_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=params['adamw_lr'], weight_decay=params['adamw_wd'])\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.78)\n",
    "    \n",
    "    # Training metrics\n",
    "    valid_loss_min = np.inf\n",
    "    \n",
    "    for step in range(max_iter):\n",
    "        model.train()\n",
    "        magnetic_loss_cumulative = 0.0\n",
    "        topological_loss_cumulative = 0.0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for j, d in enumerate(dataloader):\n",
    "            d.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            magnetic_pred, topological_pred = model(d.x, d.edge_index, d.edge_attr, \n",
    "                                                  n_norm=True, batch=d.batch)\n",
    "            \n",
    "            # Compute losses\n",
    "            magnetic_loss = magnetic_loss_fn(magnetic_pred, d.magnetic_y)\n",
    "            topological_loss = topological_loss_fn(topological_pred, d.topological_y)\n",
    "            \n",
    "            # Apply class weighting for imbalanced classes\n",
    "            #TODO: can change this\n",
    "            cost_multiplier = 1\n",
    "            if d.magnetic_y.item() == 2: # FM/FiM classes\n",
    "                magnetic_loss = cost_multiplier * magnetic_loss\n",
    "            \n",
    "            # Combine losses\n",
    "            combined_loss = magnetic_loss + topological_loss\n",
    "            \n",
    "            # Update cumulative losses\n",
    "            magnetic_loss_cumulative += magnetic_loss.detach().item()\n",
    "            topological_loss_cumulative += topological_loss.detach().item()\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            combined_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Compute average losses\n",
    "        magnetic_train_loss = magnetic_loss_cumulative / len(dataloader)\n",
    "        topological_train_loss = topological_loss_cumulative / len(dataloader)\n",
    "        \n",
    "        # Validation\n",
    "        magnetic_valid_loss, topological_valid_loss = evaluate_multi_task(model, dataloader_valid, device)\n",
    "        \n",
    "        # Log progress\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Step {step:4d}/{max_iter - 1:4d} \"\n",
    "                  f\"Magnetic Loss: {magnetic_train_loss:7.4f} \"\n",
    "                  f\"Topological Loss: {topological_train_loss:7.4f} \"\n",
    "                  f\"Valid Magnetic: {magnetic_valid_loss:7.4f} \"\n",
    "                  f\"Valid Topological: {topological_valid_loss:7.4f} \"\n",
    "                  f\"Time: {time.time() - start_time:.4f}\")\n",
    "        \n",
    "        # Save model if validation loss improves\n",
    "        valid_loss = magnetic_valid_loss + topological_valid_loss\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model...'.format(\n",
    "                valid_loss_min, valid_loss))\n",
    "            run_name = datetime.today().strftime('%Y-%m-%d_%H-%M')\n",
    "            torch.save(model.state_dict(), run_name + 'multi_task_model.pt')\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_symmetry_indicators(structure):\n",
    "    \"\"\"\n",
    "    Extract symmetry indicators relevant for topological classification\n",
    "    Based on Topological Quantum Chemistry principles\n",
    "    \"\"\"\n",
    "    indicators = {}\n",
    "    \n",
    "    # Get space group information\n",
    "    analyzer = SpacegroupAnalyzer(structure)\n",
    "    spacegroup_number = analyzer.get_space_group_number()\n",
    "    point_group = analyzer.get_point_group_symbol()\n",
    "    \n",
    "    indicators['spacegroup_number'] = spacegroup_number\n",
    "    \n",
    "    # Check for inversion symmetry (important for many topological materials)\n",
    "    indicators['has_inversion'] = 1 if analyzer.has_inversion() else 0\n",
    "    \n",
    "    # Time-reversal symmetry is crucial for topological classification\n",
    "    # In a real implementation, this would be more sophisticated\n",
    "    magnetic_elements = ['Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Gd', 'Dy', 'Ho', 'Er', 'Tm', 'Yb']\n",
    "    has_magnetic_elements = any(element in str(structure.composition) for element in magnetic_elements)\n",
    "    indicators['potential_time_reversal_breaking'] = 1 if has_magnetic_elements else 0\n",
    "    \n",
    "    # BCS symmetry indicators based on BCS 3.7 from the TQC database\n",
    "    # This is a simplified implementation\n",
    "    if spacegroup_number in [2, 10, 47, 83, 87, 199, 216, 227]:  # These are examples\n",
    "        indicators['compatible_with_bcs_3_7'] = 1\n",
    "    else:\n",
    "        indicators['compatible_with_bcs_3_7'] = 0\n",
    "    \n",
    "    # Add indicators for nonsymmorphic symmetries\n",
    "    indicators['has_nonsymmorphic'] = 1 if analyzer.is_nonsymmorphic() else 0\n",
    "    \n",
    "    # Add band connectivity indicators\n",
    "    # In real implementation, this would require electronic structure calculation\n",
    "    indicators['estimated_band_inversion'] = 0  # Placeholder\n",
    "    \n",
    "    return indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bcs_compatibility(structure, bcs_id=\"3.7\"):\n",
    "    \"\"\"\n",
    "    Check if a structure is compatible with a specific BCS classification\n",
    "    from the Topological Quantum Chemistry database\n",
    "    \"\"\"\n",
    "    # This would typically require calling the TQC API or using their methods\n",
    "    # For this example, we'll use a simplified approach\n",
    "    \n",
    "    analyzer = SpacegroupAnalyzer(structure)\n",
    "    spacegroup = analyzer.get_space_group_number()\n",
    "    \n",
    "    # BCS 3.7 compatibility rules (simplified)\n",
    "    # In reality, this would involve more detailed symmetry analysis\n",
    "    if bcs_id == \"3.7\":\n",
    "        # Example conditions for BCS 3.7 (these would be replaced with actual conditions)\n",
    "        if spacegroup in [2, 10, 47, 83, 87, 199, 216, 227]:\n",
    "            # Check additional conditions like orbital character, band inversion, etc.\n",
    "            composition = structure.composition\n",
    "            \n",
    "            # Check for elements commonly found in TIs with this BCS\n",
    "            has_heavy_elements = any(element in str(composition) for element in ['Bi', 'Sb', 'Te', 'Se'])\n",
    "            \n",
    "            # Check for inversion symmetry (important for many TIs)\n",
    "            has_inversion = analyzer.has_inversion()\n",
    "            \n",
    "            return has_heavy_elements and has_inversion\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: change this lol\n",
    "\n",
    "def predict_topological_class(struct, symmetry_indicators, is_bcs_compatible):\n",
    "    if not is_bcs_compatible:\n",
    "        return \"None\"\n",
    "    if symmetry_indicators.get(\"z4\", 0) == 1:\n",
    "        return \"Strong TI\"\n",
    "    return \"Weak TI\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mendeleev import element\n",
    "def get_en_pauling(symbol):\n",
    "    elem = element(str(symbol))\n",
    "    return elem.electronegativity('pauling')\n",
    "\n",
    "#print(get_en_pauling('O'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pymatgen.core import Element\n",
    "from pymatgen.analysis.magnetism.analyzer import CollinearMagneticStructureAnalyzer\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Dummy helper functions and dictionaries for demonstration.\n",
    "def get_en_pauling(symbol):\n",
    "    en_dict = {'Fe': 1.83, 'O': 3.44, 'Ru': 2.2, 'Rh': 2.28}  # Extend as needed\n",
    "    return en_dict.get(symbol, 0.0)\n",
    "\n",
    "def extract_magnetic_features(struct):\n",
    "    return {'dummy_magnetic': 1.0}\n",
    "\n",
    "def extract_symmetry_indicators(struct):\n",
    "    return {'dummy_symmetry': 1.0}\n",
    "\n",
    "def check_bcs_compatibility(struct, bcs_id):\n",
    "    return True\n",
    "\n",
    "def predict_topological_class(struct, symmetry_indicators, is_bcs_compatible):\n",
    "    return 'TI'\n",
    "\n",
    "order_encode = {'NM': 0, 'AFM': 1, 'FM': 2}  # Adjust as needed\n",
    "topo_encode = {'None': 0, 'TI': 1}            # Adjust as needed\n",
    "params = {'max_radius': 10.0}\n",
    "n_norm = 35\n",
    "\n",
    "\n",
    "class DataPeriodicNeighbors(Data):\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'edge_index':\n",
    "            return self.x.size(0)  # Use the number of rows in x\n",
    "        if key == 'cell_index':\n",
    "            return self.x.size(0)\n",
    "        return super().__inc__(key, value, *args, **kwargs)\n",
    "    \n",
    "    def __init__(self, x=None, pos=None, lattice=None, edge_index=None, r_max=None, \n",
    "                 magnetic_y=None, topological_y=None, magnetic_features=None, \n",
    "                 symmetry_features=None, bcs_compatible=None, n_norm=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.x = x                        # Node features (tensor of shape [num_nodes, feature_dim])\n",
    "        self.pos = pos                    # Node positions\n",
    "        self.lattice = lattice            # Lattice matrix\n",
    "        self.edge_index = edge_index      # Edge connectivity\n",
    "        self.r_max = r_max\n",
    "        self.magnetic_y = magnetic_y      # Magnetic ordering label\n",
    "        self.topological_y = topological_y  # Topological label\n",
    "        self.magnetic_features = magnetic_features\n",
    "        self.symmetry_features = symmetry_features\n",
    "        self.bcs_compatible = bcs_compatible\n",
    "        self.n_norm = n_norm\n",
    "        # Attach any extra fields passed via kwargs.\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "\n",
    "def preprocess_structures_with_tqc(structures, bcs_id=\"3.7\"):\n",
    "    \"\"\"\n",
    "    Enhanced preprocessing pipeline incorporating TQC data and BCS classification.\n",
    "    Returns a list of DataPeriodicNeighbors objects.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    len_element = 100  # Maximum number of element indices we support (e.g., Z < 100)\n",
    "    \n",
    "    for i, struct in enumerate(structures):\n",
    "        print(f\"Processing structure {i+1}/{len(structures)}\", end=\"\\r\", flush=True)\n",
    "        try:\n",
    "            num_sites = len(struct)\n",
    "            # Allocate features: 3 properties per element index\n",
    "            input_features = torch.zeros(num_sites, 3 * len_element)\n",
    "            \n",
    "            for j, site in enumerate(struct):\n",
    "                elem = str(site.specie)\n",
    "                atomic_num = Element(elem).Z\n",
    "                # Clip atomic number if it exceeds our fixed size\n",
    "                if atomic_num >= len_element:\n",
    "                    atomic_num = len_element - 1\n",
    "                \n",
    "                # Retrieve properties with defaults if not available.\n",
    "                atomic_radius = getattr(Element(elem), 'atomic_radius', 0.0) or 0.0\n",
    "                en_pauling = get_en_pauling(elem)\n",
    "                if en_pauling is None:\n",
    "                    en_pauling = 0.0\n",
    "                dipole_polarizability = getattr(Element(elem), 'dipole_polarizability', 0.0) or 0.0\n",
    "                \n",
    "                # Place properties in the feature tensor at positions based on atomic_num\n",
    "                input_features[j, atomic_num] = atomic_radius\n",
    "                input_features[j, len_element + atomic_num] = en_pauling\n",
    "                input_features[j, 2 * len_element + atomic_num] = dipole_polarizability\n",
    "\n",
    "                # Get atom positions\n",
    "            positions = torch.tensor(struct.cart_coords, dtype=torch.float)\n",
    "            \n",
    "            # Create edges based on distance cutoff - consider periodic boundaries\n",
    "            # This is simplified - you may need to use a library like PyMatGen for proper periodic distances\n",
    "            src_list = []\n",
    "            dst_list = []\n",
    "            edge_attr_list = []\n",
    "\n",
    "            for src_idx in range(num_sites):\n",
    "                for dst_idx in range(num_sites):\n",
    "                    # Skip self-loops if you don't want them\n",
    "                    if src_idx == dst_idx:\n",
    "                        continue\n",
    "                        \n",
    "                    # Calculate distance (simplified - doesn't account for periodicity)\n",
    "                    dist = torch.norm(positions[src_idx] - positions[dst_idx])\n",
    "                    \n",
    "                    if dist <= params['max_radius']:\n",
    "                        src_list.append(src_idx)\n",
    "                        dst_list.append(dst_idx)\n",
    "                        # Add distance or other edge features\n",
    "                        edge_attr_list.append([dist.item(), 0, 0])  # Example: [distance, 0, 0]\n",
    "\n",
    "            if src_list:  # If there are edges\n",
    "                edge_index = torch.tensor([src_list, dst_list], dtype=torch.long)\n",
    "                edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
    "            else:\n",
    "                # Fallback to self-loops if no edges found\n",
    "                edge_index = torch.stack([torch.arange(num_sites), torch.arange(num_sites)], dim=0)\n",
    "                edge_attr = torch.zeros((num_sites, 3), dtype=torch.float)\n",
    "        \n",
    "        \n",
    "            \n",
    "            # Create a self-loop edge_index: each node connected to itself.\n",
    "            # This yields an edge_index of shape [2, num_sites] with indices 0...num_sites-1.\n",
    "            #edge_index = torch.stack([torch.arange(num_sites), torch.arange(num_sites)], dim=0)\n",
    "            \n",
    "            # Extract additional features\n",
    "            magnetic_feats = extract_magnetic_features(struct)\n",
    "            symmetry_indicators = extract_symmetry_indicators(struct)\n",
    "            is_bcs_compatible = check_bcs_compatibility(struct, bcs_id=bcs_id)\n",
    "            \n",
    "            # Get magnetic ordering using pymatgen analyzer\n",
    "            analyzer = CollinearMagneticStructureAnalyzer(struct)\n",
    "            magnetic_order = analyzer.ordering.name  # e.g. 'AFM', 'NM', 'FM'\n",
    "            \n",
    "            # Predict topological class\n",
    "            topo_class = predict_topological_class(struct, symmetry_indicators, is_bcs_compatible)\n",
    "            \n",
    "            # Create the DataPeriodicNeighbors object with a valid edge_index\n",
    "            data_point = DataPeriodicNeighbors(\n",
    "                x=input_features,\n",
    "                pos=torch.tensor(struct.cart_coords, dtype=torch.float),\n",
    "                lattice=torch.tensor(struct.lattice.matrix, dtype=torch.float),\n",
    "                edge_index=edge_index,\n",
    "                edge_attr = edge_attr,\n",
    "                r_max=params['max_radius'],\n",
    "                magnetic_y=torch.tensor([order_encode[magnetic_order]], dtype=torch.long),\n",
    "                topological_y=torch.tensor([topo_encode[topo_class]], dtype=torch.long),\n",
    "                magnetic_features=torch.tensor(list(magnetic_feats.values()), dtype=torch.float),\n",
    "                symmetry_features=torch.tensor(list(symmetry_indicators.values()), dtype=torch.float),\n",
    "                bcs_compatible=torch.tensor([int(is_bcs_compatible)], dtype=torch.float),\n",
    "                n_norm=n_norm,\n",
    "            )\n",
    "            \n",
    "            processed_data.append(data_point)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing structure {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nProcessed {len(processed_data)} structures successfully.\")\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_magnetic_space_group(structure):\n",
    "    \"\"\"\n",
    "    Analyze the magnetic space group of a structure\n",
    "    Important for classifying magnetic topological materials\n",
    "    \"\"\"\n",
    "    # This is a placeholder for more sophisticated analysis\n",
    "    # In practice, you would use a library like ISOTROPY or Bilbao Crystallographic Server\n",
    "    \n",
    "    # Get standard space group\n",
    "    analyzer = SpacegroupAnalyzer(structure)\n",
    "    space_group = analyzer.get_space_group_number()\n",
    "    \n",
    "    # Analyze magnetic ordering\n",
    "    mag_analyzer = CollinearMagneticStructureAnalyzer(structure)\n",
    "    ordering = mag_analyzer.ordering.name\n",
    "    \n",
    "    # Simplified magnetic space group determination\n",
    "    # In reality, this requires detailed analysis of symmetry and magnetic moments\n",
    "    if ordering == \"NM\":\n",
    "        # Non-magnetic: equivalent to standard space group\n",
    "        mag_space_group = f\"{space_group}.0\"\n",
    "    elif ordering == \"FM\":\n",
    "        # Ferromagnetic: typically type III or IV MSG\n",
    "        if analyzer.has_inversion():\n",
    "            mag_space_group = f\"{space_group}.10\"  # Example type IV\n",
    "        else:\n",
    "            mag_space_group = f\"{space_group}.8\"   # Example type III\n",
    "    elif ordering == \"AFM\":\n",
    "        # Antiferromagnetic: typically type II or III MSG\n",
    "        if space_group % 2 == 0:  # Even space groups often become type II\n",
    "            mag_space_group = f\"{space_group}.7\"   # Example type II\n",
    "        else:\n",
    "            mag_space_group = f\"{space_group}.9\"   # Example type III\n",
    "    elif ordering in [\"FiM\"]:\n",
    "        # Ferromagnetic or ferrimagnetic: typically type III or IV MSG\n",
    "        if analyzer.has_inversion():\n",
    "            mag_space_group = f\"{space_group}.10\"  # Example type IV\n",
    "        else:\n",
    "            mag_space_group = f\"{space_group}.8\"   # Example type III\n",
    "    else:\n",
    "        mag_space_group = \"unknown\"\n",
    "    \n",
    "    # For BCS 3.7 compatibility\n",
    "    compatible_with_bcs37 = False\n",
    "    if mag_space_group in [\"2.4\", \"10.42\", \"47.252\", \"83.43\", \"87.78\", \"199.13\", \"216.77\", \"227.131\"]:\n",
    "        compatible_with_bcs37 = True\n",
    "    \n",
    "    return {\n",
    "        \"magnetic_space_group\": mag_space_group,\n",
    "        \"compatible_with_bcs37\": compatible_with_bcs37\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MagneticTopologicalTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, edge_attr_dim, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        self.attention_layers = nn.ModuleList([\n",
    "            GraphMultiHeadAttention(hidden_dim, num_heads, edge_attr_dim)\n",
    "            for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        self.ffn_layers = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "            ) for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        self.layer_norms1 = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim) for _ in range(3)\n",
    "        ])\n",
    "        self.layer_norms2 = nn.ModuleList([\n",
    "            nn.LayerNorm(hidden_dim) for _ in range(3)\n",
    "        ])\n",
    "        \n",
    "        self.magnetic_head = nn.Linear(hidden_dim, 3)      # NM, AFM, FM/FiM\n",
    "        self.topological_head = nn.Linear(hidden_dim, 2)   # Not TI, TI\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        for i in range(3):\n",
    "            attention_output = self.attention_layers[i](x, edge_index, edge_attr)\n",
    "            x = self.layer_norms1[i](x + attention_output)\n",
    "            ffn_output = self.ffn_layers[i](x)\n",
    "            x = self.layer_norms2[i](x + ffn_output)\n",
    "        \n",
    "        x = torch_scatter.scatter_mean(x, batch, dim=0)\n",
    "        \n",
    "        magnetic_pred = self.magnetic_head(x)\n",
    "        topological_pred = self.topological_head(x)\n",
    "        \n",
    "        return magnetic_pred, torch.sigmoid(topological_pred)\n",
    "\n",
    "\n",
    "class GraphMultiHeadAttention(MessagePassing):\n",
    "    def __init__(self, hidden_dim, num_heads, edge_attr_dim):\n",
    "        super().__init__(aggr='add')\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        \n",
    "        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.k_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.edge_proj = nn.Linear(edge_attr_dim, num_heads)\n",
    "        self.output_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "    # def forward(self, x, edge_index, edge_attr):\n",
    "    #     # Project inputs\n",
    "    #     q = self.q_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "    #     k = self.k_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "    #     v = self.v_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "        \n",
    "    #     # Process edge attributes\n",
    "    #     edge_weights = self.edge_proj(edge_attr).unsqueeze(-1)  # [E, num_heads, 1]\n",
    "        \n",
    "    #     # Propagate through edges\n",
    "    #     out = self.propagate(edge_index, q=q, k=k, v=v, edge_weights=edge_weights)\n",
    "        \n",
    "    #     # Project output\n",
    "    #     return self.output_proj(out.view(-1, self.hidden_dim))\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # If edge_index is None, create a self-loop edge index for each node.\n",
    "        if edge_index is None:\n",
    "            N = x.size(0)\n",
    "            # Create self-loops: each node connected to itself.\n",
    "            edge_index = torch.stack([torch.arange(N, device=x.device),\n",
    "                                    torch.arange(N, device=x.device)], dim=0)\n",
    "        \n",
    "        # If edge_attr is None, create a default tensor with zeros.\n",
    "        if edge_attr is None:\n",
    "            E = edge_index.size(1)  # number of edges\n",
    "            edge_attr = torch.zeros(E, self.edge_proj.in_features, device=x.device)\n",
    "        \n",
    "        # Project inputs\n",
    "        q = self.q_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "        k = self.k_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "        v = self.v_proj(x).view(-1, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Process edge attributes\n",
    "        edge_weights = self.edge_proj(edge_attr).unsqueeze(-1)  # [E, num_heads, 1]\n",
    "        \n",
    "        # Propagate through edges\n",
    "        out = self.propagate(edge_index, q=q, k=k, v=v, edge_weights=edge_weights)\n",
    "        \n",
    "        # Project output\n",
    "        return self.output_proj(out.view(-1, self.hidden_dim))\n",
    "\n",
    "\n",
    "    \n",
    "    def message(self, q_i, k_j, v_j, edge_weights):\n",
    "        attention = (q_i * k_j).sum(dim=-1) / math.sqrt(self.head_dim)  # [E, num_heads]\n",
    "        attention = attention.unsqueeze(-1) * edge_weights             # Apply edge weighting\n",
    "        attention = F.softmax(attention, dim=0)                        # Normalize over neighbors\n",
    "        return attention * v_j                                         # [E, num_heads, head_dim]\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCS37Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Specialized classifier for BCS 3.7 magnetic topological materials\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Symmetry analysis module\n",
    "        self.symmetry_module = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        \n",
    "        # Final classification heads\n",
    "        self.magnetic_head = nn.Linear(16, 3)  # NM, AFM, FM/FiM\n",
    "        self.bcs_compatibility_head = nn.Linear(16, 1)  # Sigmoid will be applied\n",
    "        \n",
    "    def forward(self, x, structure_features):\n",
    "        # Extract features\n",
    "        features = self.feature_extraction(x)\n",
    "        \n",
    "        # Add structure-level features like symmetry indicators\n",
    "        combined_features = features + structure_features\n",
    "        \n",
    "        # Analyze symmetry\n",
    "        symmetry_features = self.symmetry_module(combined_features)\n",
    "        \n",
    "        # Get predictions\n",
    "        magnetic_pred = self.magnetic_head(symmetry_features)\n",
    "        bcs_compatibility = torch.sigmoid(self.bcs_compatibility_head(symmetry_features))\n",
    "        \n",
    "        return magnetic_pred, bcs_compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "#TODO: change this to somenthing more suitable lol\n",
    "\n",
    "def compute_loss(magnetic_pred, topological_pred, batch):\n",
    "    \"\"\"\n",
    "    Compute the loss for both magnetic and topological predictions.\n",
    "\n",
    "    Arguments:\n",
    "    - magnetic_pred: Predictions for the magnetic ordering (output from the magnetic head)\n",
    "    - topological_pred: Predictions for the topological class (output from the topological head)\n",
    "    - batch: Batch of data containing the true labels for magnetic and topological classes\n",
    "\n",
    "    Returns:\n",
    "    - loss: Total loss (sum of magnetic and topological losses)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Magnetic prediction loss (Cross-Entropy Loss)\n",
    "    magnetic_true = batch.magnetic_y\n",
    "    magnetic_loss = F.cross_entropy(magnetic_pred, magnetic_true)\n",
    "    \n",
    "    # Topological prediction loss (Cross-Entropy Loss)\n",
    "    topological_true = batch.topological_y\n",
    "    topological_loss = F.cross_entropy(topological_pred, topological_true)\n",
    "    \n",
    "    # Total loss is the sum of both losses\n",
    "    total_loss = magnetic_loss + topological_loss\n",
    "    \n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.44\n"
     ]
    }
   ],
   "source": [
    "# from mendeleev import element\n",
    "\n",
    "# #TODO: think of this logic more\n",
    "\n",
    "# def get_en_pauling(symbol):\n",
    "#     try:\n",
    "#         elem = element(symbol)\n",
    "#         return elem.electronegativityl\n",
    "#     except KeyError:\n",
    "#         return None\n",
    "\n",
    "# symbol = 'Fe'  # Example element\n",
    "# en_pauling = get_en_pauling(symbol)\n",
    "# print(en_pauling)  # Should print the electronegativity value or None if not found\n",
    "\n",
    "\n",
    "from mendeleev import element\n",
    "# Access the element you want (e.g., Oxygen)\n",
    "# element = element('O')\n",
    "\n",
    "# # Get Paulling electronegativity\n",
    "# pauling_electronegativity = element.electronegativity('pauling')\n",
    "# print(f\"Pauling electronegativity of Oxygen: {pauling_electronegativity}\")\n",
    "\n",
    "# # Get Mulliken electronegativity\n",
    "# mulliken_electronegativity = element.electronegativity('mulliken')\n",
    "# print(f\"Mulliken electronegativity of Oxygen: {mulliken_electronegativity}\")\n",
    "\n",
    "def get_en_pauling(symbol):\n",
    "    elem = element(str(symbol))\n",
    "    return elem.electronegativity('pauling')\n",
    "\n",
    "print(get_en_pauling('O'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing structure 1/9\n",
      "Error processing structure 0: 'FiM'\n",
      "Processing structure 7/9\r"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Define the device (use CUDA if available, otherwise use CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define atom_types_dim based on your feature encoding\n",
    "# For example, if you use atomic radius, electronegativity, and dipole moment as features for each atom type\n",
    "atom_types_dim = 300  # For this case, you would need 3 features per atom type\n",
    "\n",
    "# Initialize the model\n",
    "model = MagneticTopologicalTransformer(\n",
    "    input_dim=atom_types_dim, \n",
    "    hidden_dim=128,\n",
    "    num_heads=4, \n",
    "    edge_attr_dim= 3\n",
    ").to(device)  # Make sure to move the model to the correct device\n",
    "\n",
    "# Preprocess data with TQC insights\n",
    "enhanced_data = preprocess_structures_with_tqc(structures_list_mp, bcs_id=\"3.7\")\n",
    "\n",
    "# Split data\n",
    "indices = np.arange(len(enhanced_data))\n",
    "np.random.shuffle(indices)\n",
    "index_tr, index_va, index_te = np.split(indices, [int(.8 * len(indices)), int(.9 * len(indices))])\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 4 # Increased batch size for transformer\n",
    "print(f\"Length of enhanced_data: {len(enhanced_data)}\")\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "print([type(g) for g in enhanced_data])\n",
    "\n",
    "# dataloader = DataLoader(\n",
    "#     [enhanced_data[i] for i in index_tr], \n",
    "#     batch_size=batch_size, \n",
    "#     shuffle=True\n",
    "# )\n",
    "# dataloader_valid = DataLoader(\n",
    "#     [enhanced_data[i] for i in index_va], \n",
    "#     batch_size=batch_size\n",
    "# )\n",
    "# Create DataLoader instances using the batched data\n",
    "dataloader = DataLoader(enhanced_data, batch_size=4, shuffle=True)\n",
    "dataloader_valid = DataLoader(enhanced_data, batch_size=4)\n",
    "\n",
    "# Initialize optimizer with learning rate warmup\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
    "\n",
    "# Learning rate scheduler (Cosine annealing with warmup)\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=100,  # First restart period\n",
    "    T_mult=2,  # Multiply restart period after each cycle\n",
    "    eta_min=0,  # Minimum learning rate\n",
    "    last_epoch=-1  # Start from epoch 0\n",
    ")\n",
    "\n",
    "# Training function placeholder (assuming you have defined it previously)\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "def validate_model(model, dataload, device): \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataload:\n",
    "            \n",
    "            batch = batch.to(device)  # Ensure validation batch is on the correct device\n",
    "            magnetic_pred, topological_pred = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            # Compute validation loss or any evaluation metric here\n",
    "            val_loss = compute_loss(magnetic_pred, topological_pred, batch)\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "def train_mag_topo_model(model, optimizer, scheduler, dataloader, dataloader_valid, max_epochs, device):\n",
    "    model.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Debug information\n",
    "            print(\"Batch x.shape:\", batch.x.shape)\n",
    "            print(\"Batch edge_index.shape:\", batch.edge_index.shape)\n",
    "            print(\"Batch batch:\", batch.batch)\n",
    "            \n",
    "            # Get the edge index from the batch\n",
    "            edge_index = batch.edge_index\n",
    "            \n",
    "            # IMPORTANT: When working with batched graphs in PyTorch Geometric,\n",
    "            # the batch.edge_index is already corrected for the batch, so no need\n",
    "            # to manually adjust the indices.\n",
    "            \n",
    "            # Forward pass\n",
    "            out = model(batch.x, edge_index, batch.edge_attr, batch.batch)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = F.mse_loss(out, batch.y)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.6f}\")\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = validate_model(model, dataloader_valid, device)\n",
    "        print(f\"Epoch: {epoch}, Train Loss: {epoch_loss / len(dataloader):.6f}, Val Loss: {val_loss:.6f}\")\n",
    "        \n",
    "# def train_mag_topo_model(model, optimizer, scheduler, dataloader, dataloader_valid, max_epochs, device):\n",
    "#     model.train()\n",
    "#     for epoch in range(max_epochs):\n",
    "#         for batch in dataloader:\n",
    "            \n",
    "#             nx_graph = to_networkx(batch, to_undirected=True)\n",
    "#             plt.figure(figsize=(8, 6))\n",
    "#             nx.draw(nx_graph, with_labels=True, node_size=300, font_size=10)\n",
    "#             plt.title(\"Batch Graph Visualization\")\n",
    "#             plt.show()\n",
    "\n",
    "#             batch = batch.to(device)  # Ensure the batch is on the correct device\n",
    "#             optimizer.zero_grad()\n",
    "#             magnetic_pred, topological_pred = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "#             # Define loss functions and backpropagate here\n",
    "#             loss = compute_loss(magnetic_pred, topological_pred, batch)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#         # Validation\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for batch in dataloader_valid:\n",
    "             \n",
    "               \n",
    "#                 batch = batch.to(device)  # Ensure validation batch is on the correct device\n",
    "#                 magnetic_pred, topological_pred = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "#                 # Compute validation loss or any evaluation metric here\n",
    "#                 val_loss = compute_loss(magnetic_pred, topological_pred, batch)\n",
    "        \n",
    "#         print(f\"Epoch {epoch+1}/{max_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "\n",
    "\n",
    "for i, data in enumerate(enhanced_data):\n",
    "    assert isinstance(data, DataPeriodicNeighbors)\n",
    "    # print(f\"Graph {i}:\")\n",
    "    # print(f\"  num_nodes: {data.num_nodes}\")\n",
    "    # print(f\"  edge_index max: {data.edge_index.max().item()}\")\n",
    "    # print(f\"  edge_index shape: {data.edge_index.shape}\")\n",
    "\n",
    "for i, g in enumerate(enhanced_data):\n",
    "    print(f\"Graph {i}: x.shape = {g.x.shape}, num_nodes = {g.num_nodes}\")\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(\"Batched x shape:\", batch.x.shape)\n",
    "    print(\"Batched edge_index max:\", batch.edge_index.max())\n",
    "    print(\"Batched num_nodes:\", batch.num_nodes)\n",
    "    break\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "batched_data = Batch.from_data_list(enhanced_data)\n",
    "print(\"Batched x shape:\", batched_data.x.shape)\n",
    "print(\"Batched edge_index shape:\", batched_data.edge_index.shape)\n",
    "print(\"Batched edge_index max:\", batched_data.edge_index.max().item(), \n",
    "      \"out of\", batched_data.x.size(0), \"nodes\")\n",
    "\n",
    "# Train the model\n",
    "train_mag_topo_model(\n",
    "    model, \n",
    "    optimizer, \n",
    "    scheduler,\n",
    "    dataloader, \n",
    "    dataloader_valid, \n",
    "    max_epochs=100, \n",
    "    device=device\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
